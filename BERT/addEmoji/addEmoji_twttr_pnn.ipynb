{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2616b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a84c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da5ece",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47471ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1478404</td>\n",
       "      <td>Tiek vērtēti trīs potenciālie airBaltic invest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1478695</td>\n",
       "      <td>Augulis: #airBaltic “potenciālie pircēji ir no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1478812</td>\n",
       "      <td>airBaltic uzsāks lidojumus uz diviem jauniem g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1479295</td>\n",
       "      <td>Ministrs: Sarunas turpinās ar trīs potenciālaj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1480097</td>\n",
       "      <td>@krisjaniskarins @Janis_Kazocins @EU2017EE Net...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            message  label\n",
       "0  1478404  Tiek vērtēti trīs potenciālie airBaltic invest...      0\n",
       "1  1478695  Augulis: #airBaltic “potenciālie pircēji ir no...      0\n",
       "2  1478812  airBaltic uzsāks lidojumus uz diviem jauniem g...      0\n",
       "3  1479295  Ministrs: Sarunas turpinās ar trīs potenciālaj...      0\n",
       "4  1480097  @krisjaniskarins @Janis_Kazocins @EU2017EE Net...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./../../labeledTweets/allLabeledTweets.csv')\n",
    "df = df[['id', 'message', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82da84e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    968\n",
       "2    647\n",
       "1    410\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78b2f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1478404</td>\n",
       "      <td>Tiek vērtēti trīs potenciālie airBaltic invest...</td>\n",
       "      <td>0</td>\n",
       "      <td>Tiek vērtēti trīs potenciālie airBaltic invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1478695</td>\n",
       "      <td>Augulis: #airBaltic “potenciālie pircēji ir no...</td>\n",
       "      <td>0</td>\n",
       "      <td>Augulis: airBaltic “potenciālie pircēji ir no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1478812</td>\n",
       "      <td>airBaltic uzsāks lidojumus uz diviem jauniem g...</td>\n",
       "      <td>0</td>\n",
       "      <td>airBaltic uzsāks lidojumus uz diviem jauniem g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1479295</td>\n",
       "      <td>Ministrs: Sarunas turpinās ar trīs potenciālaj...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ministrs: Sarunas turpinās ar trīs potenciālaj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1480097</td>\n",
       "      <td>@krisjaniskarins @Janis_Kazocins @EU2017EE Net...</td>\n",
       "      <td>0</td>\n",
       "      <td>MENTION MENTION MENTION Netrāpīs kādam AirBalt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            message  label  \\\n",
       "0  1478404  Tiek vērtēti trīs potenciālie airBaltic invest...      0   \n",
       "1  1478695  Augulis: #airBaltic “potenciālie pircēji ir no...      0   \n",
       "2  1478812  airBaltic uzsāks lidojumus uz diviem jauniem g...      0   \n",
       "3  1479295  Ministrs: Sarunas turpinās ar trīs potenciālaj...      0   \n",
       "4  1480097  @krisjaniskarins @Janis_Kazocins @EU2017EE Net...      0   \n",
       "\n",
       "                                       clean_message  \n",
       "0  Tiek vērtēti trīs potenciālie airBaltic invest...  \n",
       "1  Augulis: airBaltic “potenciālie pircēji ir no ...  \n",
       "2  airBaltic uzsāks lidojumus uz diviem jauniem g...  \n",
       "3  Ministrs: Sarunas turpinās ar trīs potenciālaj...  \n",
       "4  MENTION MENTION MENTION Netrāpīs kādam AirBalt...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newLine =\"\\\\n|\\\\r\"\n",
    "urls = '(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'\n",
    "numbers = '\\d+((\\.|\\-)\\d+)?'\n",
    "mentions = '\\B\\@([\\w\\-]+)'\n",
    "hashtag = '#'\n",
    "whitespaces = '\\s+'\n",
    "leadTrailWhitespace = '^\\s+|\\s+?$'\n",
    "\n",
    "df['clean_message'] = df['message']\n",
    "df['clean_message'] = df['clean_message'].str.replace(newLine,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(urls,' URL ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(mentions,' MENTION ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(numbers,' NMBR ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(hashtag,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(whitespaces,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(leadTrailWhitespace,'',regex=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc0d24",
   "metadata": {},
   "source": [
    "# Train, validate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b2abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051783f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>550</td>\n",
       "      <td>550</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  message  clean_message\n",
       "label data_type                             \n",
       "0     train      823      823            823\n",
       "      val        145      145            145\n",
       "1     train      348      348            348\n",
       "      val         62       62             62\n",
       "2     train      550      550            550\n",
       "      val         97       97             97"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "df.groupby(['label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6440d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1478404</td>\n",
       "      <td>Tiek vērtēti trīs potenciālie airBaltic invest...</td>\n",
       "      <td>0</td>\n",
       "      <td>Tiek vērtēti trīs potenciālie airBaltic invest...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1478695</td>\n",
       "      <td>Augulis: #airBaltic “potenciālie pircēji ir no...</td>\n",
       "      <td>0</td>\n",
       "      <td>Augulis: airBaltic “potenciālie pircēji ir no ...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1478812</td>\n",
       "      <td>airBaltic uzsāks lidojumus uz diviem jauniem g...</td>\n",
       "      <td>0</td>\n",
       "      <td>airBaltic uzsāks lidojumus uz diviem jauniem g...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1479295</td>\n",
       "      <td>Ministrs: Sarunas turpinās ar trīs potenciālaj...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ministrs: Sarunas turpinās ar trīs potenciālaj...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1480097</td>\n",
       "      <td>@krisjaniskarins @Janis_Kazocins @EU2017EE Net...</td>\n",
       "      <td>0</td>\n",
       "      <td>MENTION MENTION MENTION Netrāpīs kādam AirBalt...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            message  label  \\\n",
       "0  1478404  Tiek vērtēti trīs potenciālie airBaltic invest...      0   \n",
       "1  1478695  Augulis: #airBaltic “potenciālie pircēji ir no...      0   \n",
       "2  1478812  airBaltic uzsāks lidojumus uz diviem jauniem g...      0   \n",
       "3  1479295  Ministrs: Sarunas turpinās ar trīs potenciālaj...      0   \n",
       "4  1480097  @krisjaniskarins @Janis_Kazocins @EU2017EE Net...      0   \n",
       "\n",
       "                                       clean_message data_type  \n",
       "0  Tiek vērtēti trīs potenciālie airBaltic invest...     train  \n",
       "1  Augulis: airBaltic “potenciālie pircēji ir no ...       val  \n",
       "2  airBaltic uzsāks lidojumus uz diviem jauniem g...     train  \n",
       "3  Ministrs: Sarunas turpinās ar trīs potenciālaj...     train  \n",
       "4  MENTION MENTION MENTION Netrāpīs kādam AirBalt...     train  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d08134e",
   "metadata": {},
   "source": [
    "## Balance training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5287682c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    823\n",
       "2    550\n",
       "1    348\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.data_type=='train']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f63a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    348\n",
       "1    348\n",
       "2    348\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = [df[df.data_type=='train'].clean_message, df[df.data_type=='train'].label]\n",
    "df_train = pd.concat(df_train, axis=1, keys=[\"clean_message\", \"label\"])\n",
    "\n",
    "df_0 = df_train[df_train['label']==0]\n",
    "df_1 = df_train[df_train['label']==1]\n",
    "df_2 = df_train[df_train['label']==2]\n",
    "\n",
    "df_0_downsampled = df_0.sample(df_1.shape[0], random_state=42)\n",
    "df_2_downsampled = df_2.sample(df_1.shape[0], random_state=42)\n",
    "\n",
    "df_train = pd.concat([df_0_downsampled, df_2_downsampled, df_1])\n",
    "\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89eaf519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Šodien norisinās SEB MTB maratons. Finišs MENT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>MENTION Sveiks! Tas neattiecas uz mūsu ekspert...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>MENTION MENTION Starpcitu, Maxima tirgo labus ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>Taisnība ir uzvarējusi! Martins Dukurs kļūst p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>MENTION Спасибо за мнение.^el</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_message  label\n",
       "700   Šodien norisinās SEB MTB maratons. Finišs MENT...      0\n",
       "1911  MENTION Sveiks! Tas neattiecas uz mūsu ekspert...      1\n",
       "505   MENTION MENTION Starpcitu, Maxima tirgo labus ...      1\n",
       "1471  Taisnība ir uzvarējusi! Martins Dukurs kļūst p...      1\n",
       "1537                      MENTION Спасибо за мнение.^el      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle rows\n",
    "import sklearn\n",
    "\n",
    "df_train = sklearn.utils.shuffle(df_train, random_state=0)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843c4ae",
   "metadata": {},
   "source": [
    "# Tokenizer \"bert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43b43559",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bec309",
   "metadata": {},
   "source": [
    "## Add emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ade333fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "emoji_str = \"😀 😃 😄 😁 😆 😅 😂 🤣 😊 😇 🙂 🙃 😉 😌 😍 🥰 😘 😗 😙 😚 😋 😛 😝 😜 🤪 🤨 🧐 🤓 😎 🤩 🥳 😏 😒 😞 😔 😟 😕 🙁 ☹️ 😣 😖 😫 😩 🥺 😢 😭 😤 😠 😡 🤬 🤯 😳 🥵 🥶 😱 😨 😰 😥 😓 🤗 🤔 🤭 🤫 🤥 😶 😐 😑 😬 🙄 😯 😦 😧 😮 😲 🥱 😴 🤤 😪 😵 🤐 🥴 🤢 🤮 🤧 😷 🤒 🤕 😺 😸 😹 😻 😼 😽 🙀 😿 😾 💩 👋 🤚 🖐 ✋ 🖖 👌 🤏 ✌️ 🤞 🤟 🤘 🤙 👈 👉 👆 🖕 👇 ☝️ 👍 👎 ✊ 👊 🤛 🤜 👏 🙌 👐 🤲 🤝 🙏'👋🏻 🤚🏻 🖐🏻 ✋🏻 🖖🏻 👌🏻 🤏🏻 ✌🏻 🤞🏻 🤟🏻 🤘🏻 🤙🏻 👈🏻 👉🏻 👆🏻 🖕🏻 👇🏻 ☝🏻 👍🏻 👎🏻 ✊🏻 👊🏻 🤛🏻 🤜🏻 👏🏻 🙌🏻 👐🏻 🤲🏻 🙏🏻 👋🏼 🤚🏼 🖐🏼 ✋🏼 🖖🏼 👌🏼 🤏🏼 ✌🏼 🤞🏼 🤟🏼 🤘🏼 🤙🏼 👈🏼 👉🏼 👆🏼 🖕🏼 👇🏼 ☝🏼 👍🏼 👎🏼 ✊🏼 👊🏼 🤛🏼 🤜🏼 👏🏼 🙌🏼 👐🏼 🤲🏼 🙏🏼 👋🏽 🤚🏽 🖐🏽 ✋🏽 🖖🏽 👌🏽 🤏🏽 ✌🏽 🤞🏽 🤟🏽 🤘🏽 🤙🏽 👈🏽 👉🏽 👆🏽 🖕🏽 👇🏽 ☝🏽 👍🏽 👎🏽 ✊🏽 👊🏽 🤛🏽 🤜🏽 👏🏽 🙌🏽 👐🏽 🤲🏽 🙏👋🏾 🤚🏾 🖐🏾 ✋🏾 🖖🏾 👌🏾 🤏🏾 ✌🏾 🤞🏾 🤟🏾 🤘🏾 🤙🏾 👈🏾 👉🏾 👆🏾 🖕🏾 👇🏾 ☝🏾 👍🏾 👎🏾 ✊🏾 👊🏾 🤛🏾 🤜🏾 👏🏾 🙌🏾 👐🏾 🤲🏾 🙏 👋🏿 🤚🏿 🖐🏿 ✋🏿 🖖🏿 👌🏿 🤏🏿 ✌🏿 🤞🏿 🤟🏿 🤘🏿 🤙🏿 👈🏿 👉🏿 👆🏿 🖕🏿 👇🏿 ☝🏿 👍🏿 👎🏿 ✊🏿 👊🏿 🤛🏿 🤜🏿 👏🏿 🙌🏿 👐🏿 🤲🏿 🙏🏿 ❤️ 🧡 💛 💚 💙 💜 🖤 🤍 🤎 💔 ❣️ 💕 💞 💓 💗 💖 💘 💝 💟 💑🏻 💑🏼 💑🏽 💑🏾 💑🏿 💏🏻 💏🏼 💏🏽 💏🏾 💏🏿 👨🏻‍❤️‍👨🏻 👨🏻‍❤️‍👨🏼 👨🏻‍❤️‍👨🏽 👨🏻‍❤️‍👨🏾 👨🏻‍❤️‍👨🏿 👨🏼‍❤️‍👨🏻 👨🏼‍❤️‍👨🏼 👨🏼‍❤️‍👨🏽 👨🏼‍❤️‍👨🏾 👨🏼‍❤️‍👨🏿 👨🏽‍❤️‍👨🏻 👨🏽‍❤️‍👨🏼 👨🏽‍❤️‍👨🏽 👨🏽‍❤️‍👨🏾 👨🏽‍❤️‍👨🏿 👨🏾‍❤️‍👨🏻 👨🏾‍❤️‍👨🏼 👨🏾‍❤️‍👨🏽 👨🏾‍❤️‍👨🏾 👨🏾‍❤️‍👨🏿 👨🏿‍❤️‍👨🏻 👨🏿‍❤️‍👨🏼 👨🏿‍❤️‍👨🏽 👨🏿‍❤️‍👨🏾 👨🏿‍❤️‍👨🏿 👩🏻‍❤️‍👨🏻 👩🏻‍❤️‍👨🏼 👩🏻‍❤️‍👨🏽 👩🏻‍❤️‍👨🏾 👩🏻‍❤️‍👨🏿 👩🏻‍❤️‍👩🏻 👩🏻‍❤️‍👩🏼 👩🏻‍❤️‍👩🏽 👩🏻‍❤️‍👩🏾 👩🏻‍❤️‍👩🏿 👩🏼‍❤️‍👨🏻 👩🏼‍❤️‍👨🏼 👩🏼‍❤️‍👨🏽 👩🏼‍❤️‍👨🏾 👩🏼‍❤️‍👨🏿 👩🏼‍❤️‍👩🏻 👩🏼‍❤️‍👩🏼 👩🏼‍❤️‍👩🏽 👩🏼‍❤️‍👩🏾 👩🏼‍❤️‍👩🏿 👩🏽‍❤️‍👨🏻 👩🏽‍❤️‍👨🏼 👩🏽‍❤️‍👨🏽 👩🏽‍❤️‍👨🏾 👩🏽‍❤️‍👨🏿 👩🏽‍❤️‍👩🏻 👩🏽‍❤️‍👩🏼 👩🏽‍❤️‍👩🏽 👩🏽‍❤️‍👩🏾 👩🏽‍❤️‍👩🏿 👩🏾‍❤️‍👨🏻 👩🏾‍❤️‍👨🏼 👩🏾‍❤️‍👨🏽 👩🏾‍❤️‍👨🏾 👩🏾‍❤️‍👨🏿 👩🏾‍❤️‍👩🏻 👩🏾‍❤️‍👩🏼 👩🏾‍❤️‍👩🏽 👩🏾‍❤️‍👩🏾 👩🏾‍❤️‍👩🏿 👩🏿‍❤️‍👨🏻 👩🏿‍❤️‍👨🏼 👩🏿‍❤️‍👨🏽 👩🏿‍❤️‍👨🏾 👩🏿‍❤️‍👨🏿 👩🏿‍❤️‍👩🏻 👩🏿‍❤️‍👩🏼 👩🏿‍❤️‍👩🏽 👩🏿‍❤️‍👩🏾 👩🏿‍❤️‍👩🏿 🧑🏻‍❤️‍🧑🏼 🧑🏻‍❤️‍🧑🏽 🧑🏻‍❤️‍🧑🏾 🧑🏻‍❤️‍🧑🏿 🧑🏼‍❤️‍🧑🏻 🧑🏼‍❤️‍🧑🏽 🧑🏼‍❤️‍🧑🏾 🧑🏼‍❤️‍🧑🏿 🧑🏽‍❤️‍🧑🏻 🧑🏽‍❤️‍🧑🏼 🧑🏽‍❤️‍🧑🏾 🧑🏽‍❤️‍🧑🏿 🧑🏾‍❤️‍🧑🏻 🧑🏾‍❤️‍🧑🏼 🧑🏾‍❤️‍🧑🏽 🧑🏾‍❤️‍🧑🏿 🧑🏿‍❤️‍🧑🏻 🧑🏿‍❤️‍🧑🏼 🧑🏿‍❤️‍🧑🏽 🧑🏿‍❤️‍🧑🏾 👨🏻‍❤️‍💋‍👨🏻 👨🏻‍❤️‍💋‍👨🏼 👨🏻‍❤️‍💋‍👨🏽 👨🏻‍❤️‍💋‍👨🏾 👨🏻‍❤️‍💋‍👨🏿 👨🏼‍❤️‍💋‍👨🏻 👨🏼‍❤️‍💋‍👨🏼 👨🏼‍❤️‍💋‍👨🏽 👨🏼‍❤️‍💋‍👨🏾 👨🏼‍❤️‍💋‍👨🏿 👨🏽‍❤️‍💋‍👨🏻 👨🏽‍❤️‍💋‍👨🏼 👨🏽‍❤️‍💋‍👨🏽 👨🏽‍❤️‍💋‍👨🏾 👨🏽‍❤️‍💋‍👨🏿 👨🏾‍❤️‍💋‍👨🏻 👨🏾‍❤️‍💋‍👨🏼 👨🏾‍❤️‍💋‍👨🏽 👨🏾‍❤️‍💋‍👨🏾 👨🏾‍❤️‍💋‍👨🏿 👨🏿‍❤️‍💋‍👨🏻 👨🏿‍❤️‍💋‍👨🏼 👨🏿‍❤️‍💋‍👨🏽 👨🏿‍❤️‍💋‍👨🏾 👨🏿‍❤️‍💋‍👨🏿 👩🏻‍❤️‍💋‍👨🏻 👩🏻‍❤️‍💋‍👨🏼 👩🏻‍❤️‍💋‍👨🏽 👩🏻‍❤️‍💋‍👨🏾 👩🏻‍❤️‍💋‍👨🏿 👩🏻‍❤️‍💋‍👩🏻 👩🏻‍❤️‍💋‍👩🏼 👩🏻‍❤️‍💋‍👩🏽 👩🏻‍❤️‍💋‍👩🏾 👩🏻‍❤️‍💋‍👩🏿 👩🏼‍❤️‍💋‍👨🏻 👩🏼‍❤️‍💋‍👨🏼 👩🏼‍❤️‍💋‍👨🏽 👩🏼‍❤️‍💋‍👨🏾 👩🏼‍❤️‍💋‍👨🏿 👩🏼‍❤️‍💋‍👩🏻 👩🏼‍❤️‍💋‍👩🏼 👩🏼‍❤️‍💋‍👩🏽 👩🏼‍❤️‍💋‍👩🏾 👩🏼‍❤️‍💋‍👩🏿 👩🏽‍❤️‍💋‍👨🏻 👩🏽‍❤️‍💋‍👨🏼 👩🏽‍❤️‍💋‍👨🏽 👩🏽‍❤️‍💋‍👨🏾 👩🏽‍❤️‍💋‍👨🏿 👩🏽‍❤️‍💋‍👩🏻 👩🏽‍❤️‍💋‍👩🏼 👩🏽‍❤️‍💋‍👩🏽 👩🏽‍❤️‍💋‍👩🏾 👩🏽‍❤️‍💋‍👩🏿 👩🏾‍❤️‍💋‍👨🏻 👩🏾‍❤️‍💋‍👨🏼 👩🏾‍❤️‍💋‍👨🏽 👩🏾‍❤️‍💋‍👨🏾 👩🏾‍❤️‍💋‍👨🏿 👩🏾‍❤️‍💋‍👩🏻 👩🏾‍❤️‍💋‍👩🏼 👩🏾‍❤️‍💋‍👩🏽 👩🏾‍❤️‍💋‍👩🏾 👩🏾‍❤️‍💋‍👩🏿 👩🏿‍❤️‍💋‍👨🏻 👩🏿‍❤️‍💋‍👨🏼 👩🏿‍❤️‍💋‍👨🏽 👩🏿‍❤️‍💋‍👨🏾 👩🏿‍❤️‍💋‍👨🏿 👩🏿‍❤️‍💋‍👩🏻 👩🏿‍❤️‍💋‍👩🏼 👩🏿‍❤️‍💋‍👩🏽 👩🏿‍❤️‍💋‍👩🏾 👩🏿‍❤️‍💋‍👩🏿 🧑🏻‍❤️‍💋‍🧑🏼 🧑🏻‍❤️‍💋‍🧑🏽 🧑🏻‍❤️‍💋‍🧑🏾 🧑🏻‍❤️‍💋‍🧑🏿 🧑🏼‍❤️‍💋‍🧑🏻 🧑🏼‍❤️‍💋‍🧑🏽 🧑🏼‍❤️‍💋‍🧑🏾 🧑🏼‍❤️‍💋‍🧑🏿 🧑🏽‍❤️‍💋‍🧑🏻 🧑🏽‍❤️‍💋‍🧑🏼 🧑🏽‍❤️‍💋‍🧑🏾 🧑🏽‍❤️‍💋‍🧑🏿 🧑🏾‍❤️‍💋‍🧑🏻 🧑🏾‍❤️‍💋‍🧑🏼 🧑🏾‍❤️‍💋‍🧑🏽 🧑🏾‍❤️‍💋‍🧑🏿 🧑🏿‍❤️‍💋‍🧑🏻 🧑🏿‍❤️‍💋‍🧑🏼 🧑🏿‍❤️‍💋‍🧑🏽 🧑🏿‍❤️‍💋‍🧑🏾 👭 🧑‍🤝‍🧑 👬 👫 👩‍❤️‍👩 💑 👨‍❤️‍👨 👩‍❤️‍👨 👩‍❤️‍💋‍👩 💏 👨‍❤️‍💋‍👨 👩‍❤️‍💋‍👨 👪 👨‍👩‍👦 👨‍👩‍👧 👨‍👩‍👧‍👦 👨‍👩‍👦‍👦 👨‍👩‍👧‍👧 👨‍👨‍👦 👨‍👨‍👧 👨‍👨‍👧‍👦 👨‍👨‍👦‍👦 👨‍👨‍👧‍👧 👩‍👩‍👦 👩‍👩‍👧 👩‍👩‍👧‍👦 👩‍👩‍👦‍👦 👩‍👩‍👧‍👧 👨‍👦 👨‍👦‍👦 👨‍👧 👨‍👧‍👦 👨‍👧‍👧 👩‍👦 👩‍👦‍👦 👩‍👧 👩‍👧‍👦 👩‍ 👧‍👧 💋\"\n",
    "emoji_list = emoji_str.split(' ')\n",
    "emoji_regex = '|'.join(emoji_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7f3873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "all_emoji = []\n",
    "for message in df.clean_message:\n",
    "    foundEmoji = re.findall(emoji_regex, message)\n",
    "    for emoji in foundEmoji:\n",
    "        all_emoji.append(emoji)\n",
    "\n",
    "print(len(all_emoji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52dbef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('😂', 12), ('🤔', 9), ('😁', 9), ('👍', 7), ('👉', 6), ('🙄', 6), ('😀', 5), ('😉', 5), ('😎', 5), ('😊', 4), ('🤗', 3), ('😅', 3), ('👏', 3), ('❤️', 3), ('😥', 2), ('😵', 2), ('😍', 2), ('😆', 2), ('🤘', 2), ('🤬', 2), ('🙂', 2), ('😖', 1), ('🤥', 1), ('☝️', 1), ('🙁', 1), ('🤣', 1), ('😳', 1), ('🙌', 1), ('👌', 1), ('🤓', 1), ('😌', 1), ('🤢', 1), ('👇', 1), ('😜', 1)]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter=collections.Counter(all_emoji)\n",
    "print(counter.most_common(100))\n",
    "\n",
    "most_common_values= [word for word, word_count in counter.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7de43abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[('😂', 6968), ('😭', 4638), ('🤣', 2528), ('🙏', 1916), ('🥺', 1084), ('😩', 1058), ('🤔', 903), ('🥰', 899), ('🥴', 869), ('👏', 840), ('😍', 838), ('🙄', 775), ('🙌', 672), ('💙', 639), ('😅', 568), ('💜', 543), ('💕', 540), ('😊', 509), ('👍', 477), ('😘', 474), ('😔', 464), ('💔', 454), ('😒', 446), ('🙃', 425), ('😎', 398), ('😉', 388), ('😁', 365), ('😢', 359), ('😌', 355), ('🖤', 347), ('😆', 310), ('🤗', 307), ('😳', 298), ('🥳', 292), ('✊', 289), ('😤', 289), ('💛', 288), ('😬', 282), ('🤬', 281), ('👇', 271), ('😡', 266), ('👌', 265), ('🤩', 265), ('💖', 259), ('😫', 255), ('💋', 251), ('\\U0001f90d', 250), ('💚', 231), ('💗', 217), ('🙂', 212), ('😞', 206), ('😷', 202), ('🤯', 202), ('😀', 193), ('😴', 188), ('😋', 185), ('😏', 179), ('🤞', 174), ('😜', 174), ('👉', 168), ('🤘', 154), ('😪', 154), ('🤤', 154), ('😑', 152), ('🤪', 152), ('😐', 141), ('😱', 139), ('😄', 132), ('👊', 128), ('🤢', 122), ('🤨', 121), ('🧐', 120), ('🥶', 116), ('😕', 115), ('💩', 113), ('😇', 112), ('🤮', 109), ('🥵', 106), ('🤧', 104), ('👋', 103), ('👎', 99), ('😖', 97), ('🤓', 96), ('😃', 96), ('\\U0001f971', 94), ('💞', 93), ('😓', 91), ('🤝', 90), ('🧡', 89), ('😹', 86), ('🖕', 85), ('😝', 84), ('😣', 75), ('🤫', 71), ('😰', 71), ('😥', 70), ('🤭', 70), ('💓', 59), ('😠', 58), ('😮', 55)]\n",
    "most_common_values=[word for word, word_count in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acfb5dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119547"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1af3e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(most_common_values, special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a150d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119647"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504acea3",
   "metadata": {},
   "source": [
    "### Find max length for tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6b28671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_lens = []\n",
    "for txt in list(df.clean_message.values):\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "    \n",
    "sns.displot(token_lens)\n",
    "plt.xlim([0, 200])\n",
    "plt.xlabel('Token count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9e882ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6402cf",
   "metadata": {},
   "source": [
    "### Encode messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb945e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\aligo\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df_train[\"clean_message\"].values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].clean_message.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df_train.label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c13eef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1044, 304)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11af821",
   "metadata": {},
   "source": [
    "# Model \"bert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3a7ffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\",\n",
    "                                                      num_labels=3,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9a84b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(119647, 768)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c906d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16189453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61d95dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bf40782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to measure weighted F1\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5fc030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c05ccb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model. Returns average validation loss, predictions, true values\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader_val, desc='Validating', leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf1a223",
   "metadata": {},
   "source": [
    "# Evaluate model trained on PNN dataset on LV Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77d54fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('modelsEmoji-pnn/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e438870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "preds_flat = np.argmax(predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5ed7502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:\n",
      "0.3703206958497119\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.95      0.64       145\n",
      "           1       0.40      0.03      0.06        62\n",
      "           2       0.60      0.09      0.16        97\n",
      "\n",
      "    accuracy                           0.49       304\n",
      "   macro avg       0.50      0.36      0.29       304\n",
      "weighted avg       0.50      0.49      0.37       304\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">actual</th>\n",
       "      <th>neutral</th>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted                  \n",
       "                  neutral positive negative\n",
       "actual neutral        138        3        4\n",
       "       positive        58        2        2\n",
       "       negative        88        0        9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_f1 = f1_score_func(predictions, true_vals)\n",
    "print('F1:')\n",
    "print(val_f1)\n",
    "print(classification_report(true_vals, preds_flat))\n",
    "pd.DataFrame(confusion_matrix(true_vals, preds_flat),\n",
    "        index = [['actual', 'actual', 'actual'], ['neutral', 'positive', 'negative']],\n",
    "        columns = [['predicted', 'predicted', 'predicted'], ['neutral', 'positive', 'negative']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ef371",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81fe5ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ddd8bc56c946edb8ad546eb33d78f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 1.1191846529642742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.900631594657898\n",
      "F1 Score (Weighted): 0.6399500438904134\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       145\n",
      "           1       0.51      0.68      0.58        62\n",
      "           2       0.65      0.57      0.60        97\n",
      "\n",
      "    accuracy                           0.64       304\n",
      "   macro avg       0.62      0.64      0.63       304\n",
      "weighted avg       0.65      0.64      0.64       304\n",
      "\n",
      "Confusion matrix:\n",
      "                predicted                  \n",
      "                  neutral positive negative\n",
      "actual neutral         97       28       20\n",
      "       positive        10       42       10\n",
      "       negative        30       12       55\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.8604503364273997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8192062735557556\n",
      "F1 Score (Weighted): 0.6559622755135298\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       145\n",
      "           1       0.56      0.65      0.60        62\n",
      "           2       0.65      0.64      0.65        97\n",
      "\n",
      "    accuracy                           0.65       304\n",
      "   macro avg       0.64      0.65      0.64       304\n",
      "weighted avg       0.66      0.65      0.66       304\n",
      "\n",
      "Confusion matrix:\n",
      "                predicted                  \n",
      "                  neutral positive negative\n",
      "actual neutral         97       24       24\n",
      "       positive        13       40        9\n",
      "       negative        27        8       62\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.7635758483048641\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8163271546363831\n",
      "F1 Score (Weighted): 0.6560258340182796\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.61      0.67       145\n",
      "           1       0.55      0.68      0.60        62\n",
      "           2       0.64      0.71      0.67        97\n",
      "\n",
      "    accuracy                           0.65       304\n",
      "   macro avg       0.64      0.67      0.65       304\n",
      "weighted avg       0.67      0.65      0.66       304\n",
      "\n",
      "Confusion matrix:\n",
      "                predicted                  \n",
      "                  neutral positive negative\n",
      "actual neutral         88       27       30\n",
      "       positive        11       42        9\n",
      "       negative        20        8       69\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.7192385124437737\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8227700412273407\n",
      "F1 Score (Weighted): 0.6566465216907444\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67       145\n",
      "           1       0.54      0.69      0.61        62\n",
      "           2       0.64      0.70      0.67        97\n",
      "\n",
      "    accuracy                           0.65       304\n",
      "   macro avg       0.64      0.67      0.65       304\n",
      "weighted avg       0.67      0.65      0.66       304\n",
      "\n",
      "Confusion matrix:\n",
      "                predicted                  \n",
      "                  neutral positive negative\n",
      "actual neutral         88       28       29\n",
      "       positive         9       43       10\n",
      "       negative        20        9       68\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.6990855462623365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8227700412273407\n",
      "F1 Score (Weighted): 0.6566465216907444\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67       145\n",
      "           1       0.54      0.69      0.61        62\n",
      "           2       0.64      0.70      0.67        97\n",
      "\n",
      "    accuracy                           0.65       304\n",
      "   macro avg       0.64      0.67      0.65       304\n",
      "weighted avg       0.67      0.65      0.66       304\n",
      "\n",
      "Confusion matrix:\n",
      "                predicted                  \n",
      "                  neutral positive negative\n",
      "actual neutral         88       28       29\n",
      "       positive         9       43       10\n",
      "       negative        20        9       68\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'modelsEmojiTwttrPNN/finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    \n",
    "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    \n",
    "    print('Classification report:')\n",
    "    print(classification_report(true_vals, preds_flat))\n",
    "    print('Confusion matrix:')\n",
    "    print(pd.DataFrame(confusion_matrix(true_vals, preds_flat),\n",
    "            index = [['actual', 'actual', 'actual'], ['neutral', 'positive', 'negative']],\n",
    "            columns = [['predicted', 'predicted', 'predicted'], ['neutral', 'positive', 'negative']]))\n",
    "    print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c271f1a9",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b344990",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('modelsUNKTwttrPNN/finetuned_BERT_epoch_X.model', map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "preds_flat = np.argmax(predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_vals, preds_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(true_vals, preds_flat),\n",
    "        index = [['actual', 'actual', 'actual'], ['neutral', 'positive', 'negative']],\n",
    "        columns = [['predicted', 'predicted', 'predicted'], ['neutral', 'positive', 'negative']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38twttr",
   "language": "python",
   "name": "venv38twttr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
