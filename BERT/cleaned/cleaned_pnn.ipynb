{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2616b46",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f2616b46",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[K     |████████████████████████████████| 292 kB 14.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.22.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (9.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 19.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.22.2)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.47)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 38.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.1.18)\n",
      "Collecting tokenizers!=0.11.3,>=0.11.1\n",
      "  Downloading tokenizers-0.11.6-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 30.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.9)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.4.0 tokenizers-0.11.6 transformers-4.17.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a84c5b",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "66a84c5b",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da5ece",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "39da5ece",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47471ee1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "47471ee1",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message_lv_tilde</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>@pilsonenjeff @lauferlaw @donwinslows pa reize...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@foenixaew Es nojaušu, ka WWE lika viņam iznāk...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>Maksvels droši vien pačurās mājā pirms mūsu nā...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>@msamson56 Esmu pārsteigts. KĀ cilvēki var atb...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                   message_lv_tilde     label\n",
       "0  1.340000e+18  @pilsonenjeff @lauferlaw @donwinslows pa reize...  negative\n",
       "1  1.330000e+18  @tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...  negative\n",
       "2  1.330000e+18  @foenixaew Es nojaušu, ka WWE lika viņam iznāk...  negative\n",
       "3  1.320000e+18  Maksvels droši vien pačurās mājā pirms mūsu nā...  negative\n",
       "4  1.320000e+18  @msamson56 Esmu pārsteigts. KĀ cilvēki var atb...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./../../labeledTweets/p_n_n_tilde_lv.csv')\n",
    "df = df[['id', 'message_lv_tilde', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82da84e1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "82da84e1",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    77028\n",
       "1    51994\n",
       "2    45622\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {'neutral': 0, 'positive': 1, 'negative': 2}\n",
    "df['label'] = df.label.replace(label_dict) \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b78b2f8c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b78b2f8c",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message_lv_tilde</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>@pilsonenjeff @lauferlaw @donwinslows pa reize...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION MENTION MENTION pa reizei tādu nav bij...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION cilvēkiem ir aģentūra. Lins Vuds ir va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@foenixaew Es nojaušu, ka WWE lika viņam iznāk...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION Es nojaušu, ka WWE lika viņam iznākt a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>Maksvels droši vien pačurās mājā pirms mūsu nā...</td>\n",
       "      <td>2</td>\n",
       "      <td>Maksvels droši vien pačurās mājā pirms mūsu nā...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>@msamson56 Esmu pārsteigts. KĀ cilvēki var atb...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION Esmu pārsteigts. KĀ cilvēki var atbals...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                   message_lv_tilde  label  \\\n",
       "0  1.340000e+18  @pilsonenjeff @lauferlaw @donwinslows pa reize...      2   \n",
       "1  1.330000e+18  @tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...      2   \n",
       "2  1.330000e+18  @foenixaew Es nojaušu, ka WWE lika viņam iznāk...      2   \n",
       "3  1.320000e+18  Maksvels droši vien pačurās mājā pirms mūsu nā...      2   \n",
       "4  1.320000e+18  @msamson56 Esmu pārsteigts. KĀ cilvēki var atb...      2   \n",
       "\n",
       "                                       clean_message  \n",
       "0  MENTION MENTION MENTION pa reizei tādu nav bij...  \n",
       "1  MENTION cilvēkiem ir aģentūra. Lins Vuds ir va...  \n",
       "2  MENTION Es nojaušu, ka WWE lika viņam iznākt a...  \n",
       "3  Maksvels droši vien pačurās mājā pirms mūsu nā...  \n",
       "4  MENTION Esmu pārsteigts. KĀ cilvēki var atbals...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newLine =\"\\\\n|\\\\r\"\n",
    "urls = '(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'\n",
    "numbers = '\\d+((\\.|\\-)\\d+)?'\n",
    "mentions = '\\B\\@([\\w\\-]+)'\n",
    "hashtag = '#'\n",
    "whitespaces = '\\s+'\n",
    "leadTrailWhitespace = '^\\s+|\\s+?$'\n",
    "\n",
    "df['clean_message'] = df['message_lv_tilde']\n",
    "df['clean_message'] = df['clean_message'].str.replace(newLine,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(urls,' URL ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(mentions,' MENTION ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(numbers,' NMBR ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(hashtag,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(whitespaces,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(leadTrailWhitespace,'',regex=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc0d24",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "1abc0d24",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "source": [
    "# Train, validate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b2abc1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c1b2abc1",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "051783f5",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "051783f5",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message_lv_tilde</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>65474</td>\n",
       "      <td>65474</td>\n",
       "      <td>65474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>38778</td>\n",
       "      <td>38778</td>\n",
       "      <td>38778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>6844</td>\n",
       "      <td>6844</td>\n",
       "      <td>6844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  message_lv_tilde  clean_message\n",
       "label data_type                                        \n",
       "0     train      65474             65474          65474\n",
       "      val        11554             11554          11554\n",
       "1     train      44195             44195          44195\n",
       "      val         7799              7799           7799\n",
       "2     train      38778             38778          38778\n",
       "      val         6844              6844           6844"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "df.groupby(['label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6440d50",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a6440d50",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message_lv_tilde</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>@pilsonenjeff @lauferlaw @donwinslows pa reize...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION MENTION MENTION pa reizei tādu nav bij...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION cilvēkiem ir aģentūra. Lins Vuds ir va...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@foenixaew Es nojaušu, ka WWE lika viņam iznāk...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION Es nojaušu, ka WWE lika viņam iznākt a...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>Maksvels droši vien pačurās mājā pirms mūsu nā...</td>\n",
       "      <td>2</td>\n",
       "      <td>Maksvels droši vien pačurās mājā pirms mūsu nā...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>@msamson56 Esmu pārsteigts. KĀ cilvēki var atb...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION Esmu pārsteigts. KĀ cilvēki var atbals...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                   message_lv_tilde  label  \\\n",
       "0  1.340000e+18  @pilsonenjeff @lauferlaw @donwinslows pa reize...      2   \n",
       "1  1.330000e+18  @tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...      2   \n",
       "2  1.330000e+18  @foenixaew Es nojaušu, ka WWE lika viņam iznāk...      2   \n",
       "3  1.320000e+18  Maksvels droši vien pačurās mājā pirms mūsu nā...      2   \n",
       "4  1.320000e+18  @msamson56 Esmu pārsteigts. KĀ cilvēki var atb...      2   \n",
       "\n",
       "                                       clean_message data_type  \n",
       "0  MENTION MENTION MENTION pa reizei tādu nav bij...     train  \n",
       "1  MENTION cilvēkiem ir aģentūra. Lins Vuds ir va...     train  \n",
       "2  MENTION Es nojaušu, ka WWE lika viņam iznākt a...     train  \n",
       "3  Maksvels droši vien pačurās mājā pirms mūsu nā...     train  \n",
       "4  MENTION Esmu pārsteigts. KĀ cilvēki var atbals...       val  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aaa8f7",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "97aaa8f7",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "source": [
    "## Balance training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6200f02",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b6200f02",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    65474\n",
       "1    44195\n",
       "2    38778\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.data_type=='train']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45b30934",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "45b30934",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    38778\n",
       "1    38778\n",
       "2    38778\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = [df[df.data_type=='train'].clean_message, df[df.data_type=='train'].label]\n",
    "df_train = pd.concat(df_train, axis=1, keys=[\"clean_message\", \"label\"])\n",
    "\n",
    "df_0 = df_train[df_train['label']==0]\n",
    "df_1 = df_train[df_train['label']==1]\n",
    "df_2 = df_train[df_train['label']==2]\n",
    "\n",
    "df_0_downsampled = df_0.sample(df_2.shape[0], random_state=42)\n",
    "df_1_downsampled = df_1.sample(df_2.shape[0], random_state=42)\n",
    "\n",
    "df_train = pd.concat([df_0_downsampled, df_1_downsampled, df_2])\n",
    "\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52587bce",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "52587bce",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173549</th>\n",
       "      <td>Negadījums. divas labās joslas bloķētas TriSta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13774</th>\n",
       "      <td>labākais, ko ab ir pilnībā ielenkusi tukši dzī...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86302</th>\n",
       "      <td>Piemērojot to visu šajā nākamajā nodaļā, uzspi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77847</th>\n",
       "      <td>MENTION Es cerēju, ka jūs galu galā izdarīsiet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14670</th>\n",
       "      <td>MENTION MENTION MENTION MENTION MENTION Jā, mē...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_message  label\n",
       "173549  Negadījums. divas labās joslas bloķētas TriSta...      0\n",
       "13774   labākais, ko ab ir pilnībā ielenkusi tukši dzī...      2\n",
       "86302   Piemērojot to visu šajā nākamajā nodaļā, uzspi...      1\n",
       "77847   MENTION Es cerēju, ka jūs galu galā izdarīsiet...      1\n",
       "14670   MENTION MENTION MENTION MENTION MENTION Jā, mē...      2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle rows\n",
    "import sklearn\n",
    "\n",
    "df_train = sklearn.utils.shuffle(df_train, random_state=0)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843c4ae",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a843c4ae",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "source": [
    "# Tokenizer \"bert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b43559",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "43b43559",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504acea3",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "504acea3",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "source": [
    "### Find max length for tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6b28671",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e6b28671",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_lens = []\n",
    "for txt in list(df.clean_message.values):\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "    \n",
    "sns.displot(token_lens)\n",
    "plt.xlim([0, 200])\n",
    "plt.xlabel('Token count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9e882ae",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b9e882ae",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "max_length = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6402cf",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6c6402cf",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "source": [
    "### Encode messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb945e60",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "bb945e60",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\aligo\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df_train[\"clean_message\"].values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].clean_message.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df_train.label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c13eef0",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9c13eef0",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116334, 26197)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b69f3",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "582b69f3",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(dataset_train, './datasetsLowercase/dataset_train.pt')\n",
    "# torch.save(dataset_val, './datasetsLowercase/dataset_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062b659f",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "062b659f",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_train = torch.load('./datasetsLowercase/dataset_train.pt')\n",
    "# dataset_val = torch.load('./datasetsLowercase/dataset_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bfadfb",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f2bfadfb",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "# len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11af821",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e11af821",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "source": [
    "# Model \"bert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3a7ffbe",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d3a7ffbe",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\",\n",
    "                                                      num_labels=3,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c906d1bd",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c906d1bd",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16189453",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "16189453",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d95dfa",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "61d95dfa",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf40782",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9bf40782",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "# Function to measure weighted F1\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5fc030b",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b5fc030b",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c05ccb3d",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c05ccb3d",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "# Function to evaluate model. Returns average validation loss, predictions, true values\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader_val, desc='Validating', leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ef371",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ea0ef371",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe5ae8",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "81fe5ae8",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8853f342acd45169a1ad98b0fae4d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 1.0689003232753638\n",
      "Validation loss: 0.959876549243927\n",
      "F1 Score (Weighted): 0.5869284549912482\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67       145\n",
      "           1       0.51      0.32      0.40        62\n",
      "           2       0.50      0.71      0.59        97\n",
      "\n",
      "    accuracy                           0.59       304\n",
      "   macro avg       0.58      0.55      0.55       304\n",
      "weighted avg       0.60      0.59      0.59       304\n",
      "\n",
      "Confusion matrix:\n",
      "                predicted                  \n",
      "                  neutral positive negative\n",
      "actual neutral         91        8       46\n",
      "       positive        20       20       22\n",
      "       negative        17       11       69\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.9396250681443648\n",
      "Validation loss: 0.8772644817829132\n",
      "F1 Score (Weighted): 0.6100656953450839\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68       145\n",
      "           1       0.46      0.53      0.49        62\n",
      "           2       0.55      0.61      0.58        97\n",
      "\n",
      "    accuracy                           0.61       304\n",
      "   macro avg       0.58      0.59      0.58       304\n",
      "weighted avg       0.62      0.61      0.61       304\n",
      "\n",
      "Confusion matrix:\n",
      "                predicted                  \n",
      "                  neutral positive negative\n",
      "actual neutral         92       20       33\n",
      "       positive        14       33       15\n",
      "       negative        19       19       59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.8610624580672293\n",
      "Validation loss: 0.9123697340488434\n",
      "F1 Score (Weighted): 0.5821079881667387\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.52      0.63       145\n",
      "           1       0.37      0.66      0.47        62\n",
      "           2       0.58      0.58      0.58        97\n",
      "\n",
      "    accuracy                           0.57       304\n",
      "   macro avg       0.58      0.59      0.56       304\n",
      "weighted avg       0.64      0.57      0.58       304\n",
      "\n",
      "Confusion matrix:\n",
      "                predicted                  \n",
      "                  neutral positive negative\n",
      "actual neutral         76       41       28\n",
      "       positive         9       41       12\n",
      "       negative        11       30       56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.7909825245539347\n",
      "Validation loss: 0.8510800540447235\n",
      "F1 Score (Weighted): 0.6238110607747336\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70       145\n",
      "           1       0.44      0.61      0.51        62\n",
      "           2       0.61      0.55      0.58        97\n",
      "\n",
      "    accuracy                           0.62       304\n",
      "   macro avg       0.60      0.61      0.60       304\n",
      "weighted avg       0.64      0.62      0.62       304\n",
      "\n",
      "Confusion matrix:\n",
      "                predicted                  \n",
      "                  neutral positive negative\n",
      "actual neutral         97       26       22\n",
      "       positive        12       38       12\n",
      "       negative        22       22       53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.7568148826107834\n",
      "Validation loss: 0.8377163052558899\n",
      "F1 Score (Weighted): 0.6191092978075229\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69       145\n",
      "           1       0.48      0.63      0.54        62\n",
      "           2       0.58      0.56      0.57        97\n",
      "\n",
      "    accuracy                           0.62       304\n",
      "   macro avg       0.59      0.61      0.60       304\n",
      "weighted avg       0.63      0.62      0.62       304\n",
      "\n",
      "Confusion matrix:\n",
      "                predicted                  \n",
      "                  neutral positive negative\n",
      "actual neutral         94       24       27\n",
      "       positive        11       39       12\n",
      "       negative        24       19       54\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'modelsCleaned/finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    \n",
    "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    \n",
    "    print('Classification report:')\n",
    "    print(classification_report(true_vals, preds_flat))\n",
    "    print('Confusion matrix:')\n",
    "    print(pd.DataFrame(confusion_matrix(true_vals, preds_flat),\n",
    "            index = [['actual', 'actual', 'actual'], ['neutral', 'positive', 'negative']],\n",
    "            columns = [['predicted', 'predicted', 'predicted'], ['neutral', 'positive', 'negative']]))\n",
    "    print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c271f1a9",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c271f1a9",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b344990",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "1b344990",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('modelsCleaned-pnn/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "preds_flat = np.argmax(predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9212b3ba",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9212b3ba",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.82     11554\n",
      "           1       0.76      0.77      0.77      7799\n",
      "           2       0.74      0.86      0.80      6844\n",
      "\n",
      "    accuracy                           0.80     26197\n",
      "   macro avg       0.79      0.80      0.79     26197\n",
      "weighted avg       0.80      0.80      0.80     26197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_vals, preds_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fd2f0b6",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9fd2f0b6",
     "kernelId": "af7e4707-efa6-4db5-96d3-83d04dc3e155"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">actual</th>\n",
       "      <th>neutral</th>\n",
       "      <td>8934</td>\n",
       "      <td>1403</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>945</td>\n",
       "      <td>6006</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>488</td>\n",
       "      <td>452</td>\n",
       "      <td>5904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted                  \n",
       "                  neutral positive negative\n",
       "actual neutral       8934     1403     1217\n",
       "       positive       945     6006      848\n",
       "       negative       488      452     5904"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(true_vals, preds_flat),\n",
    "        index = [['actual', 'actual', 'actual'], ['neutral', 'positive', 'negative']],\n",
    "        columns = [['predicted', 'predicted', 'predicted'], ['neutral', 'positive', 'negative']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unkTokens = [('️', 6950), ('😂', 6584), ('😭', 4354), ('…', 3449), ('🤣', 2423), ('❤', 2236), ('🏾', 2207), ('🏽', 1932), ('🙏', 1883), ('🔥', 1249), ('🏻', 1242), ('✨', 1213), ('🏼', 1209), ('🤷', 1165), ('–', 1057), ('🤦', 1025), ('🥺', 1018), ('😩', 993), ('🥰', 869), ('🤔', 846), ('🥴', 823), ('👏', 820), ('💯', 816), ('😍', 789), ('🙄', 718), ('🇺', 670), ('🙌', 664), ('💙', 623), ('🇸', 612), ('“Es', 596), ('💀', 573), ('👀', 561), ('—', 556), ('“', 539), ('😅', 530), ('💜', 527), ('💕', 519), ('😊', 482), ('👍', 455), ('💪', 454), ('😘', 445), ('😔', 428), ('💔', 422), ('😒', 417), ('🚨', 412), ('🙃', 403), ('🏿', 390), ('🚀', 387), ('😎', 377), ('‼', 375), ('😉', 361), ('🎄', 356), ('😁', 351), ('🖤', 335), ('😌', 332), ('😢', 328), ('🎶', 317), ('🎉', 307), ('🤗', 300), ('😆', 295), ('✊', 282), ('✌', 280), ('💛', 279), ('🥳', 278), ('😤', 276), ('😳', 275), ('🌟', 274), ('🤬', 267), ('👌', 261), ('👇', 261), ('🤩', 257), ('😬', 256), ('💖', 253), ('😡', 249), ('☺', 245), ('💋', 244), ('🌹', 244), ('⠀', 243), ('🤍', 242), ('🗣', 240), ('😫', 238), ('💚', 226), ('❄', 219), ('💗', 207), ('😈', 204), ('🙂', 197), ('😞', 195), ('😂,', 190), ('”', 190), ('😷', 188), ('🇷', 188), ('🤯', 188), ('😀', 185), ('“vai', 181), ('⃣', 181), ('💰', 177), ('😭,', 176), ('😴', 175), ('😏', 172), ('🤞', 171)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
