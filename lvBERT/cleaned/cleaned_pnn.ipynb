{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2616b46",
   "metadata": {
    "collapsed": true,
    "gradient": {
     "editing": false,
     "id": "f2616b46",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-7.7.0-py2.py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 15.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.1.0-py3-none-any.whl (245 kB)\n",
      "\u001b[K     |████████████████████████████████| 245 kB 28.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (8.0.1)\n",
      "Collecting widgetsnbextension~=3.6.0\n",
      "  Downloading widgetsnbextension-3.6.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 22.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.9.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.4)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: black in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (22.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.26)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (59.5.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (18.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.9.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (4.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (0.4.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (8.0.3)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=4.0.0->ipywidgets) (0.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.11)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-7.7.0 jupyterlab-widgets-1.1.0 widgetsnbextension-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434da95-b8a4-452a-9ee9-ae26ddd62f97",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "d434da95-b8a4-452a-9ee9-ae26ddd62f97",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[K     |████████████████████████████████| 292 kB 15.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.22.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (9.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a473e36e-a63e-4ee8-a3b2-1f0f6834640c",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "a473e36e-a63e-4ee8-a3b2-1f0f6834640c",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 19.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.22.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.1.18)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 37.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
      "  Downloading tokenizers-0.11.6-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 15.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.4.0 tokenizers-0.11.6 transformers-4.17.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2750e-00fd-4996-b90c-d218b614da04",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "09b2750e-00fd-4996-b90c-d218b614da04",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a84c5b",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "66a84c5b",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da5ece",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "39da5ece",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47471ee1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "47471ee1",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message_lv_tilde</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>@pilsonenjeff @lauferlaw @donwinslows pa reize...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@foenixaew Es nojaušu, ka WWE lika viņam iznāk...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>Maksvels droši vien pačurās mājā pirms mūsu nā...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>@msamson56 Esmu pārsteigts. KĀ cilvēki var atb...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                   message_lv_tilde  label\n",
       "0  1.340000e+18  @pilsonenjeff @lauferlaw @donwinslows pa reize...      2\n",
       "1  1.330000e+18  @tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...      2\n",
       "2  1.330000e+18  @foenixaew Es nojaušu, ka WWE lika viņam iznāk...      2\n",
       "3  1.320000e+18  Maksvels droši vien pačurās mājā pirms mūsu nā...      2\n",
       "4  1.320000e+18  @msamson56 Esmu pārsteigts. KĀ cilvēki var atb...      2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./p_n_n_tilde_lv.csv')\n",
    "df = df[['id', 'message_lv_tilde', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da84e1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "82da84e1",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    77028\n",
       "1    51994\n",
       "2    45622\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {'neutral': 0, 'positive': 1, 'negative': 2}\n",
    "df['label'] = df.label.replace(label_dict) \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b2f8c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b78b2f8c",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message_lv_tilde</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>@pilsonenjeff @lauferlaw @donwinslows pa reize...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION MENTION MENTION pa reizei tādu nav bij...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION cilvēkiem ir aģentūra. Lins Vuds ir va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@foenixaew Es nojaušu, ka WWE lika viņam iznāk...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION Es nojaušu, ka WWE lika viņam iznākt a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>Maksvels droši vien pačurās mājā pirms mūsu nā...</td>\n",
       "      <td>2</td>\n",
       "      <td>Maksvels droši vien pačurās mājā pirms mūsu nā...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>@msamson56 Esmu pārsteigts. KĀ cilvēki var atb...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION Esmu pārsteigts. KĀ cilvēki var atbals...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                   message_lv_tilde  label  \\\n",
       "0  1.340000e+18  @pilsonenjeff @lauferlaw @donwinslows pa reize...      2   \n",
       "1  1.330000e+18  @tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...      2   \n",
       "2  1.330000e+18  @foenixaew Es nojaušu, ka WWE lika viņam iznāk...      2   \n",
       "3  1.320000e+18  Maksvels droši vien pačurās mājā pirms mūsu nā...      2   \n",
       "4  1.320000e+18  @msamson56 Esmu pārsteigts. KĀ cilvēki var atb...      2   \n",
       "\n",
       "                                       clean_message  \n",
       "0  MENTION MENTION MENTION pa reizei tādu nav bij...  \n",
       "1  MENTION cilvēkiem ir aģentūra. Lins Vuds ir va...  \n",
       "2  MENTION Es nojaušu, ka WWE lika viņam iznākt a...  \n",
       "3  Maksvels droši vien pačurās mājā pirms mūsu nā...  \n",
       "4  MENTION Esmu pārsteigts. KĀ cilvēki var atbals...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newLine =\"\\\\n|\\\\r\"\n",
    "urls = '(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'\n",
    "numbers = '\\d+((\\.|\\-)\\d+)?'\n",
    "mentions = '\\B\\@([\\w\\-]+)'\n",
    "hashtag = '#'\n",
    "whitespaces = '\\s+'\n",
    "leadTrailWhitespace = '^\\s+|\\s+?$'\n",
    "\n",
    "df['clean_message'] = df['message_lv_tilde']\n",
    "df['clean_message'] = df['clean_message'].str.replace(newLine,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(urls,' URL ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(mentions,' MENTION ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(numbers,' NMBR ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(hashtag,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(whitespaces,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(leadTrailWhitespace,'',regex=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc0d24",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "1abc0d24",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "source": [
    "# Train, validate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2abc1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c1b2abc1",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051783f5",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "051783f5",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message_lv_tilde</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>65474</td>\n",
       "      <td>65474</td>\n",
       "      <td>65474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>38778</td>\n",
       "      <td>38778</td>\n",
       "      <td>38778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>6844</td>\n",
       "      <td>6844</td>\n",
       "      <td>6844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  message_lv_tilde  clean_message\n",
       "label data_type                                        \n",
       "0     train      65474             65474          65474\n",
       "      val        11554             11554          11554\n",
       "1     train      44195             44195          44195\n",
       "      val         7799              7799           7799\n",
       "2     train      38778             38778          38778\n",
       "      val         6844              6844           6844"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "df.groupby(['label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6440d50",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a6440d50",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message_lv_tilde</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>@pilsonenjeff @lauferlaw @donwinslows pa reize...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION MENTION MENTION pa reizei tādu nav bij...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION cilvēkiem ir aģentūra. Lins Vuds ir va...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>@foenixaew Es nojaušu, ka WWE lika viņam iznāk...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION Es nojaušu, ka WWE lika viņam iznākt a...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>Maksvels droši vien pačurās mājā pirms mūsu nā...</td>\n",
       "      <td>2</td>\n",
       "      <td>Maksvels droši vien pačurās mājā pirms mūsu nā...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.320000e+18</td>\n",
       "      <td>@msamson56 Esmu pārsteigts. KĀ cilvēki var atb...</td>\n",
       "      <td>2</td>\n",
       "      <td>MENTION Esmu pārsteigts. KĀ cilvēki var atbals...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                   message_lv_tilde  label  \\\n",
       "0  1.340000e+18  @pilsonenjeff @lauferlaw @donwinslows pa reize...      2   \n",
       "1  1.330000e+18  @tkdylan cilvēkiem ir aģentūra. Lins Vuds ir v...      2   \n",
       "2  1.330000e+18  @foenixaew Es nojaušu, ka WWE lika viņam iznāk...      2   \n",
       "3  1.320000e+18  Maksvels droši vien pačurās mājā pirms mūsu nā...      2   \n",
       "4  1.320000e+18  @msamson56 Esmu pārsteigts. KĀ cilvēki var atb...      2   \n",
       "\n",
       "                                       clean_message data_type  \n",
       "0  MENTION MENTION MENTION pa reizei tādu nav bij...     train  \n",
       "1  MENTION cilvēkiem ir aģentūra. Lins Vuds ir va...     train  \n",
       "2  MENTION Es nojaušu, ka WWE lika viņam iznākt a...     train  \n",
       "3  Maksvels droši vien pačurās mājā pirms mūsu nā...     train  \n",
       "4  MENTION Esmu pārsteigts. KĀ cilvēki var atbals...       val  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aaa8f7",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "97aaa8f7",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "source": [
    "## Balance training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6200f02",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b6200f02",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    65474\n",
       "1    44195\n",
       "2    38778\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.data_type=='train']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b30934",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "45b30934",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    38778\n",
       "1    38778\n",
       "2    38778\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = [df[df.data_type=='train'].clean_message, df[df.data_type=='train'].label]\n",
    "df_train = pd.concat(df_train, axis=1, keys=[\"clean_message\", \"label\"])\n",
    "\n",
    "df_0 = df_train[df_train['label']==0]\n",
    "df_1 = df_train[df_train['label']==1]\n",
    "df_2 = df_train[df_train['label']==2]\n",
    "\n",
    "df_0_downsampled = df_0.sample(df_2.shape[0], random_state=42)\n",
    "df_1_downsampled = df_1.sample(df_2.shape[0], random_state=42)\n",
    "\n",
    "df_train = pd.concat([df_0_downsampled, df_1_downsampled, df_2])\n",
    "\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52587bce",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "52587bce",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173549</th>\n",
       "      <td>Negadījums. divas labās joslas bloķētas TriSta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13774</th>\n",
       "      <td>labākais, ko ab ir pilnībā ielenkusi tukši dzī...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86302</th>\n",
       "      <td>Piemērojot to visu šajā nākamajā nodaļā, uzspi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77847</th>\n",
       "      <td>MENTION Es cerēju, ka jūs galu galā izdarīsiet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14670</th>\n",
       "      <td>MENTION MENTION MENTION MENTION MENTION Jā, mē...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_message  label\n",
       "173549  Negadījums. divas labās joslas bloķētas TriSta...      0\n",
       "13774   labākais, ko ab ir pilnībā ielenkusi tukši dzī...      2\n",
       "86302   Piemērojot to visu šajā nākamajā nodaļā, uzspi...      1\n",
       "77847   MENTION Es cerēju, ka jūs galu galā izdarīsiet...      1\n",
       "14670   MENTION MENTION MENTION MENTION MENTION Jā, mē...      2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle rows\n",
    "import sklearn\n",
    "\n",
    "df_train = sklearn.utils.shuffle(df_train, random_state=0)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843c4ae",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a843c4ae",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "source": [
    "# Tokenizer \"bert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b43559",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 18,
     "id": "43b43559",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./lvbert_pytorch/', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504acea3",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "504acea3",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "source": [
    "### Find max length for tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b28671",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 19,
     "id": "e6b28671",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_lens = []\n",
    "for txt in list(df.clean_message.values):\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "    \n",
    "sns.displot(token_lens)\n",
    "plt.xlim([0, 200])\n",
    "plt.xlabel('Token count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e882ae",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 20,
     "id": "b9e882ae",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "max_length = 140"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6402cf",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6c6402cf",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "source": [
    "### Encode messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb945e60",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 21,
     "id": "bb945e60",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df_train[\"clean_message\"].values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].clean_message.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df_train.label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13eef0",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 22,
     "id": "9c13eef0",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116334, 26197)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b69f3",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "582b69f3",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(dataset_train, './datasetsLowercase/dataset_train.pt')\n",
    "# torch.save(dataset_val, './datasetsLowercase/dataset_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062b659f",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "062b659f",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_train = torch.load('./datasetsLowercase/dataset_train.pt')\n",
    "# dataset_val = torch.load('./datasetsLowercase/dataset_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bfadfb",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f2bfadfb",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "# len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11af821",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e11af821",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "source": [
    "# Model \"bert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a7ffbe",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 23,
     "id": "d3a7ffbe",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdde2f5a1f434e418360eaa21a26ad46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6e256275ed4a049819c79c93e60552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\",\n",
    "                                                      num_labels=3,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74e89a-fa6b-4d1e-bd55-44bf7b2f7a04",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 24,
     "id": "ae74e89a-fa6b-4d1e-bd55-44bf7b2f7a04",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906d1bd",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 25,
     "id": "c906d1bd",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16189453",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 26,
     "id": "16189453",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d95dfa",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 27,
     "id": "61d95dfa",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf40782",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 28,
     "id": "9bf40782",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "# Function to measure weighted F1\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc030b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 29,
     "id": "b5fc030b",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ccb3d",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 30,
     "id": "c05ccb3d",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "# Function to evaluate model. Returns average validation loss, predictions, true values\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader_val, desc='Validating', leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ef371",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ea0ef371",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe5ae8",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 31,
     "id": "81fe5ae8",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/3636 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:   0%|          | 0/3636 [00:02<?, ?it/s, training_loss=0.373]\u001b[A\n",
      "Epoch 1:   0%|          | 1/3636 [00:02<2:15:42,  2.24s/it, training_loss=0.373]\u001b[A\n",
      "Epoch 1:   0%|          | 1/3636 [00:03<2:15:42,  2.24s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 1:   0%|          | 2/3636 [00:03<1:57:14,  1.94s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 1:   0%|          | 2/3636 [00:05<1:57:14,  1.94s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   0%|          | 3/3636 [00:05<1:51:20,  1.84s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   0%|          | 3/3636 [00:07<1:51:20,  1.84s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 1:   0%|          | 4/3636 [00:07<1:48:31,  1.79s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 1:   0%|          | 4/3636 [00:09<1:48:31,  1.79s/it, training_loss=0.390]\u001b[A\n",
      "Epoch 1:   0%|          | 5/3636 [00:09<1:47:01,  1.77s/it, training_loss=0.390]\u001b[A\n",
      "Epoch 1:   0%|          | 5/3636 [00:10<1:47:01,  1.77s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:   0%|          | 6/3636 [00:10<1:46:05,  1.75s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:   0%|          | 6/3636 [00:12<1:46:05,  1.75s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   0%|          | 7/3636 [00:12<1:45:24,  1.74s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   0%|          | 7/3636 [00:14<1:45:24,  1.74s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:   0%|          | 8/3636 [00:14<1:45:04,  1.74s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:   0%|          | 8/3636 [00:16<1:45:04,  1.74s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   0%|          | 9/3636 [00:16<1:44:48,  1.73s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   0%|          | 9/3636 [00:17<1:44:48,  1.73s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 1:   0%|          | 10/3636 [00:17<1:44:36,  1.73s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 1:   0%|          | 10/3636 [00:19<1:44:36,  1.73s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   0%|          | 11/3636 [00:19<1:44:29,  1.73s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   0%|          | 11/3636 [00:21<1:44:29,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:   0%|          | 12/3636 [00:21<1:44:24,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:   0%|          | 12/3636 [00:22<1:44:24,  1.73s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:   0%|          | 13/3636 [00:22<1:44:22,  1.73s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:   0%|          | 13/3636 [00:24<1:44:22,  1.73s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:   0%|          | 14/3636 [00:24<1:44:20,  1.73s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:   0%|          | 14/3636 [00:26<1:44:20,  1.73s/it, training_loss=0.373]\u001b[A\n",
      "Epoch 1:   0%|          | 15/3636 [00:26<1:44:16,  1.73s/it, training_loss=0.373]\u001b[A\n",
      "Epoch 1:   0%|          | 15/3636 [00:28<1:44:16,  1.73s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 1:   0%|          | 16/3636 [00:28<1:44:11,  1.73s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 1:   0%|          | 16/3636 [00:29<1:44:11,  1.73s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:   0%|          | 17/3636 [00:29<1:44:07,  1.73s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:   0%|          | 17/3636 [00:31<1:44:07,  1.73s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   0%|          | 18/3636 [00:31<1:44:04,  1.73s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   0%|          | 18/3636 [00:33<1:44:04,  1.73s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:   1%|          | 19/3636 [00:33<1:44:03,  1.73s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:   1%|          | 19/3636 [00:35<1:44:03,  1.73s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:   1%|          | 20/3636 [00:35<1:44:02,  1.73s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:   1%|          | 20/3636 [00:36<1:44:02,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:   1%|          | 21/3636 [00:36<1:43:59,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:   1%|          | 21/3636 [00:38<1:43:59,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:   1%|          | 22/3636 [00:38<1:43:58,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:   1%|          | 22/3636 [00:40<1:43:58,  1.73s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   1%|          | 23/3636 [00:40<1:43:55,  1.73s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   1%|          | 23/3636 [00:41<1:43:55,  1.73s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:   1%|          | 24/3636 [00:41<1:43:57,  1.73s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:   1%|          | 24/3636 [00:43<1:43:57,  1.73s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   1%|          | 25/3636 [00:43<1:43:54,  1.73s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   1%|          | 25/3636 [00:45<1:43:54,  1.73s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:   1%|          | 26/3636 [00:45<1:43:52,  1.73s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:   1%|          | 26/3636 [00:47<1:43:52,  1.73s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:   1%|          | 27/3636 [00:47<1:43:50,  1.73s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:   1%|          | 27/3636 [00:48<1:43:50,  1.73s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   1%|          | 28/3636 [00:48<1:43:41,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   1%|          | 28/3636 [00:50<1:43:41,  1.72s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   1%|          | 29/3636 [00:50<1:43:32,  1.72s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   1%|          | 29/3636 [00:52<1:43:32,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:   1%|          | 30/3636 [00:52<1:43:28,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:   1%|          | 30/3636 [00:53<1:43:28,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   1%|          | 31/3636 [00:53<1:43:21,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   1%|          | 31/3636 [00:55<1:43:21,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   1%|          | 32/3636 [00:55<1:43:15,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   1%|          | 32/3636 [00:57<1:43:15,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:   1%|          | 33/3636 [00:57<1:43:11,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:   1%|          | 33/3636 [00:59<1:43:11,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   1%|          | 34/3636 [00:59<1:43:09,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   1%|          | 34/3636 [01:00<1:43:09,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   1%|          | 35/3636 [01:00<1:43:24,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   1%|          | 35/3636 [01:02<1:43:24,  1.72s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:   1%|          | 36/3636 [01:02<1:43:16,  1.72s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:   1%|          | 36/3636 [01:04<1:43:16,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:   1%|          | 37/3636 [01:04<1:43:09,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:   1%|          | 37/3636 [01:06<1:43:09,  1.72s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   1%|          | 38/3636 [01:06<1:43:05,  1.72s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   1%|          | 38/3636 [01:07<1:43:05,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:   1%|          | 39/3636 [01:07<1:42:58,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:   1%|          | 39/3636 [01:09<1:42:58,  1.72s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:   1%|          | 40/3636 [01:09<1:42:55,  1.72s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:   1%|          | 40/3636 [01:11<1:42:55,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:   1%|          | 41/3636 [01:11<1:42:53,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:   1%|          | 41/3636 [01:12<1:42:53,  1.72s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:   1%|          | 42/3636 [01:12<1:42:51,  1.72s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:   1%|          | 42/3636 [01:14<1:42:51,  1.72s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:   1%|          | 43/3636 [01:14<1:42:51,  1.72s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:   1%|          | 43/3636 [01:16<1:42:51,  1.72s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:   1%|          | 44/3636 [01:16<1:42:51,  1.72s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:   1%|          | 44/3636 [01:18<1:42:51,  1.72s/it, training_loss=0.390]\u001b[A\n",
      "Epoch 1:   1%|          | 45/3636 [01:18<1:42:47,  1.72s/it, training_loss=0.390]\u001b[A\n",
      "Epoch 1:   1%|          | 45/3636 [01:19<1:42:47,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   1%|▏         | 46/3636 [01:19<1:42:47,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   1%|▏         | 46/3636 [01:21<1:42:47,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   1%|▏         | 47/3636 [01:21<1:42:47,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   1%|▏         | 47/3636 [01:23<1:42:47,  1.72s/it, training_loss=0.349]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 48/3636 [01:23<1:42:44,  1.72s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:   1%|▏         | 48/3636 [01:24<1:42:44,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:   1%|▏         | 49/3636 [01:24<1:42:40,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:   1%|▏         | 49/3636 [01:26<1:42:40,  1.72s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:   1%|▏         | 50/3636 [01:26<1:42:40,  1.72s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:   1%|▏         | 50/3636 [01:28<1:42:40,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:   1%|▏         | 51/3636 [01:28<1:42:38,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:   1%|▏         | 51/3636 [01:30<1:42:38,  1.72s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:   1%|▏         | 52/3636 [01:30<1:42:37,  1.72s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:   1%|▏         | 52/3636 [01:31<1:42:37,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   1%|▏         | 53/3636 [01:31<1:42:37,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   1%|▏         | 53/3636 [01:33<1:42:37,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   1%|▏         | 54/3636 [01:33<1:42:35,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   1%|▏         | 54/3636 [01:35<1:42:35,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   2%|▏         | 55/3636 [01:35<1:42:35,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   2%|▏         | 55/3636 [01:36<1:42:35,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   2%|▏         | 56/3636 [01:36<1:42:32,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   2%|▏         | 56/3636 [01:38<1:42:32,  1.72s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 1:   2%|▏         | 57/3636 [01:38<1:42:28,  1.72s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 1:   2%|▏         | 57/3636 [01:40<1:42:28,  1.72s/it, training_loss=0.373]\u001b[A\n",
      "Epoch 1:   2%|▏         | 58/3636 [01:40<1:42:27,  1.72s/it, training_loss=0.373]\u001b[A\n",
      "Epoch 1:   2%|▏         | 58/3636 [01:42<1:42:27,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   2%|▏         | 59/3636 [01:42<1:42:27,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   2%|▏         | 59/3636 [01:43<1:42:27,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:   2%|▏         | 60/3636 [01:43<1:42:25,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:   2%|▏         | 60/3636 [01:45<1:42:25,  1.72s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 1:   2%|▏         | 61/3636 [01:45<1:42:23,  1.72s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 1:   2%|▏         | 61/3636 [01:47<1:42:23,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:   2%|▏         | 62/3636 [01:47<1:42:20,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:   2%|▏         | 62/3636 [01:48<1:42:20,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:   2%|▏         | 63/3636 [01:48<1:42:17,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:   2%|▏         | 63/3636 [01:50<1:42:17,  1.72s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:   2%|▏         | 64/3636 [01:50<1:42:19,  1.72s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:   2%|▏         | 64/3636 [01:52<1:42:19,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   2%|▏         | 65/3636 [01:52<1:42:18,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   2%|▏         | 65/3636 [01:54<1:42:18,  1.72s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 1:   2%|▏         | 66/3636 [01:54<1:42:15,  1.72s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 1:   2%|▏         | 66/3636 [01:55<1:42:15,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:   2%|▏         | 67/3636 [01:55<1:42:13,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:   2%|▏         | 67/3636 [01:57<1:42:13,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:   2%|▏         | 68/3636 [01:57<1:42:16,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:   2%|▏         | 68/3636 [01:59<1:42:16,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:   2%|▏         | 69/3636 [01:59<1:42:19,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:   2%|▏         | 69/3636 [02:01<1:42:19,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   2%|▏         | 70/3636 [02:01<1:42:22,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   2%|▏         | 70/3636 [02:02<1:42:22,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   2%|▏         | 71/3636 [02:02<1:42:24,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   2%|▏         | 71/3636 [02:04<1:42:24,  1.72s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:   2%|▏         | 72/3636 [02:04<1:42:23,  1.72s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:   2%|▏         | 72/3636 [02:06<1:42:23,  1.72s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   2%|▏         | 73/3636 [02:06<1:42:25,  1.72s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   2%|▏         | 73/3636 [02:07<1:42:25,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   2%|▏         | 74/3636 [02:07<1:42:24,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   2%|▏         | 74/3636 [02:09<1:42:24,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   2%|▏         | 75/3636 [02:09<1:42:21,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   2%|▏         | 75/3636 [02:11<1:42:21,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   2%|▏         | 76/3636 [02:11<1:42:19,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   2%|▏         | 76/3636 [02:13<1:42:19,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:   2%|▏         | 77/3636 [02:13<1:42:16,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:   2%|▏         | 77/3636 [02:14<1:42:16,  1.72s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:   2%|▏         | 78/3636 [02:14<1:42:12,  1.72s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:   2%|▏         | 78/3636 [02:16<1:42:12,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   2%|▏         | 79/3636 [02:16<1:42:13,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   2%|▏         | 79/3636 [02:18<1:42:13,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   2%|▏         | 80/3636 [02:18<1:42:13,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   2%|▏         | 80/3636 [02:19<1:42:13,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   2%|▏         | 81/3636 [02:19<1:42:11,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   2%|▏         | 81/3636 [02:21<1:42:11,  1.72s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:   2%|▏         | 82/3636 [02:21<1:42:10,  1.72s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:   2%|▏         | 82/3636 [02:23<1:42:10,  1.72s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:   2%|▏         | 83/3636 [02:23<1:42:09,  1.73s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:   2%|▏         | 83/3636 [02:25<1:42:09,  1.73s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   2%|▏         | 84/3636 [02:25<1:42:08,  1.73s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   2%|▏         | 84/3636 [02:26<1:42:08,  1.73s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:   2%|▏         | 85/3636 [02:26<1:42:07,  1.73s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:   2%|▏         | 85/3636 [02:28<1:42:07,  1.73s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:   2%|▏         | 86/3636 [02:28<1:42:06,  1.73s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:   2%|▏         | 86/3636 [02:30<1:42:06,  1.73s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   2%|▏         | 87/3636 [02:30<1:42:05,  1.73s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   2%|▏         | 87/3636 [02:32<1:42:05,  1.73s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:   2%|▏         | 88/3636 [02:32<1:42:04,  1.73s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:   2%|▏         | 88/3636 [02:33<1:42:04,  1.73s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   2%|▏         | 89/3636 [02:33<1:42:01,  1.73s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   2%|▏         | 89/3636 [02:35<1:42:01,  1.73s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:   2%|▏         | 90/3636 [02:35<1:41:58,  1.73s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:   2%|▏         | 90/3636 [02:37<1:41:58,  1.73s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:   3%|▎         | 91/3636 [02:37<1:41:58,  1.73s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:   3%|▎         | 91/3636 [02:38<1:41:58,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:   3%|▎         | 92/3636 [02:38<1:41:54,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:   3%|▎         | 92/3636 [02:40<1:41:54,  1.73s/it, training_loss=0.375]\u001b[A\n",
      "Epoch 1:   3%|▎         | 93/3636 [02:40<1:41:50,  1.72s/it, training_loss=0.375]\u001b[A\n",
      "Epoch 1:   3%|▎         | 93/3636 [02:42<1:41:50,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   3%|▎         | 94/3636 [02:42<1:41:48,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   3%|▎         | 94/3636 [02:44<1:41:48,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:   3%|▎         | 95/3636 [02:44<1:41:45,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:   3%|▎         | 95/3636 [02:45<1:41:45,  1.72s/it, training_loss=0.335]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 96/3636 [02:45<1:41:42,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:   3%|▎         | 96/3636 [02:47<1:41:42,  1.72s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 1:   3%|▎         | 97/3636 [02:47<1:41:44,  1.73s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 1:   3%|▎         | 97/3636 [02:49<1:41:44,  1.73s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:   3%|▎         | 98/3636 [02:49<1:41:41,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:   3%|▎         | 98/3636 [02:51<1:41:41,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:   3%|▎         | 99/3636 [02:51<1:41:39,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:   3%|▎         | 99/3636 [02:52<1:41:39,  1.72s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:   3%|▎         | 100/3636 [02:52<1:41:39,  1.72s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:   3%|▎         | 100/3636 [02:54<1:41:39,  1.72s/it, training_loss=0.403]\u001b[A\n",
      "Epoch 1:   3%|▎         | 101/3636 [02:54<1:41:36,  1.72s/it, training_loss=0.403]\u001b[A\n",
      "Epoch 1:   3%|▎         | 101/3636 [02:56<1:41:36,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   3%|▎         | 102/3636 [02:56<1:41:32,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   3%|▎         | 102/3636 [02:57<1:41:32,  1.72s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   3%|▎         | 103/3636 [02:57<1:41:31,  1.72s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   3%|▎         | 103/3636 [02:59<1:41:31,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:   3%|▎         | 104/3636 [02:59<1:41:30,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:   3%|▎         | 104/3636 [03:01<1:41:30,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   3%|▎         | 105/3636 [03:01<1:41:28,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   3%|▎         | 105/3636 [03:03<1:41:28,  1.72s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 1:   3%|▎         | 106/3636 [03:03<1:41:27,  1.72s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 1:   3%|▎         | 106/3636 [03:04<1:41:27,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:   3%|▎         | 107/3636 [03:04<1:41:24,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:   3%|▎         | 107/3636 [03:06<1:41:24,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:   3%|▎         | 108/3636 [03:06<1:41:23,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:   3%|▎         | 108/3636 [03:08<1:41:23,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:   3%|▎         | 109/3636 [03:08<1:41:20,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:   3%|▎         | 109/3636 [03:10<1:41:20,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   3%|▎         | 110/3636 [03:10<1:41:19,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   3%|▎         | 110/3636 [03:11<1:41:19,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:   3%|▎         | 111/3636 [03:11<1:41:15,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:   3%|▎         | 111/3636 [03:13<1:41:15,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   3%|▎         | 112/3636 [03:13<1:41:12,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   3%|▎         | 112/3636 [03:15<1:41:12,  1.72s/it, training_loss=0.401]\u001b[A\n",
      "Epoch 1:   3%|▎         | 113/3636 [03:15<1:41:11,  1.72s/it, training_loss=0.401]\u001b[A\n",
      "Epoch 1:   3%|▎         | 113/3636 [03:16<1:41:11,  1.72s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 1:   3%|▎         | 114/3636 [03:16<1:41:09,  1.72s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 1:   3%|▎         | 114/3636 [03:18<1:41:09,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:   3%|▎         | 115/3636 [03:18<1:41:05,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:   3%|▎         | 115/3636 [03:20<1:41:05,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:   3%|▎         | 116/3636 [03:20<1:41:02,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:   3%|▎         | 116/3636 [03:22<1:41:02,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   3%|▎         | 117/3636 [03:22<1:41:01,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   3%|▎         | 117/3636 [03:23<1:41:01,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:   3%|▎         | 118/3636 [03:23<1:40:58,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:   3%|▎         | 118/3636 [03:25<1:40:58,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:   3%|▎         | 119/3636 [03:25<1:40:55,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:   3%|▎         | 119/3636 [03:27<1:40:55,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   3%|▎         | 120/3636 [03:27<1:40:53,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   3%|▎         | 120/3636 [03:28<1:40:53,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   3%|▎         | 121/3636 [03:28<1:40:51,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   3%|▎         | 121/3636 [03:30<1:40:51,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   3%|▎         | 122/3636 [03:30<1:40:53,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   3%|▎         | 122/3636 [03:32<1:40:53,  1.72s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   3%|▎         | 123/3636 [03:32<1:40:48,  1.72s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   3%|▎         | 123/3636 [03:34<1:40:48,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   3%|▎         | 124/3636 [03:34<1:40:47,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   3%|▎         | 124/3636 [03:35<1:40:47,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:   3%|▎         | 125/3636 [03:35<1:40:45,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:   3%|▎         | 125/3636 [03:37<1:40:45,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   3%|▎         | 126/3636 [03:37<1:40:40,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   3%|▎         | 126/3636 [03:39<1:40:40,  1.72s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 1:   3%|▎         | 127/3636 [03:39<1:40:37,  1.72s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 1:   3%|▎         | 127/3636 [03:40<1:40:37,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   4%|▎         | 128/3636 [03:40<1:40:35,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   4%|▎         | 128/3636 [03:42<1:40:35,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:   4%|▎         | 129/3636 [03:42<1:40:32,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:   4%|▎         | 129/3636 [03:44<1:40:32,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   4%|▎         | 130/3636 [03:44<1:40:29,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   4%|▎         | 130/3636 [03:46<1:40:29,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   4%|▎         | 131/3636 [03:46<1:40:30,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   4%|▎         | 131/3636 [03:47<1:40:30,  1.72s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:   4%|▎         | 132/3636 [03:47<1:40:29,  1.72s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:   4%|▎         | 132/3636 [03:49<1:40:29,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:   4%|▎         | 133/3636 [03:49<1:40:27,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:   4%|▎         | 133/3636 [03:51<1:40:27,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   4%|▎         | 134/3636 [03:51<1:40:25,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   4%|▎         | 134/3636 [03:53<1:40:25,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:   4%|▎         | 135/3636 [03:53<1:40:22,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:   4%|▎         | 135/3636 [03:54<1:40:22,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:   4%|▎         | 136/3636 [03:54<1:40:21,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:   4%|▎         | 136/3636 [03:56<1:40:21,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:   4%|▍         | 137/3636 [03:56<1:40:18,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:   4%|▍         | 137/3636 [03:58<1:40:18,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   4%|▍         | 138/3636 [03:58<1:40:17,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   4%|▍         | 138/3636 [03:59<1:40:17,  1.72s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:   4%|▍         | 139/3636 [03:59<1:40:13,  1.72s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:   4%|▍         | 139/3636 [04:01<1:40:13,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   4%|▍         | 140/3636 [04:01<1:40:11,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   4%|▍         | 140/3636 [04:03<1:40:11,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   4%|▍         | 141/3636 [04:03<1:40:11,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   4%|▍         | 141/3636 [04:05<1:40:11,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   4%|▍         | 142/3636 [04:05<1:40:08,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   4%|▍         | 142/3636 [04:06<1:40:08,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:   4%|▍         | 143/3636 [04:06<1:40:04,  1.72s/it, training_loss=0.310]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 143/3636 [04:08<1:40:04,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   4%|▍         | 144/3636 [04:08<1:40:01,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   4%|▍         | 144/3636 [04:10<1:40:01,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   4%|▍         | 145/3636 [04:10<1:39:57,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   4%|▍         | 145/3636 [04:11<1:39:57,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   4%|▍         | 146/3636 [04:11<1:39:57,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   4%|▍         | 146/3636 [04:13<1:39:57,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:   4%|▍         | 147/3636 [04:13<1:39:54,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:   4%|▍         | 147/3636 [04:15<1:39:54,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   4%|▍         | 148/3636 [04:15<1:39:51,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   4%|▍         | 148/3636 [04:17<1:39:51,  1.72s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   4%|▍         | 149/3636 [04:17<1:39:49,  1.72s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   4%|▍         | 149/3636 [04:18<1:39:49,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   4%|▍         | 150/3636 [04:18<1:39:48,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   4%|▍         | 150/3636 [04:20<1:39:48,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   4%|▍         | 151/3636 [04:20<1:39:44,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   4%|▍         | 151/3636 [04:22<1:39:44,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   4%|▍         | 152/3636 [04:22<1:39:43,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   4%|▍         | 152/3636 [04:23<1:39:43,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   4%|▍         | 153/3636 [04:23<1:39:41,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   4%|▍         | 153/3636 [04:25<1:39:41,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   4%|▍         | 154/3636 [04:25<1:39:38,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   4%|▍         | 154/3636 [04:27<1:39:38,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   4%|▍         | 155/3636 [04:27<1:39:36,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   4%|▍         | 155/3636 [04:29<1:39:36,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:   4%|▍         | 156/3636 [04:29<1:39:35,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:   4%|▍         | 156/3636 [04:30<1:39:35,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:   4%|▍         | 157/3636 [04:30<1:39:33,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:   4%|▍         | 157/3636 [04:32<1:39:33,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:   4%|▍         | 158/3636 [04:32<1:39:30,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:   4%|▍         | 158/3636 [04:34<1:39:30,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:   4%|▍         | 159/3636 [04:34<1:39:30,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:   4%|▍         | 159/3636 [04:35<1:39:30,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   4%|▍         | 160/3636 [04:35<1:39:29,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   4%|▍         | 160/3636 [04:37<1:39:29,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:   4%|▍         | 161/3636 [04:37<1:39:28,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:   4%|▍         | 161/3636 [04:39<1:39:28,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:   4%|▍         | 162/3636 [04:39<1:39:29,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:   4%|▍         | 162/3636 [04:41<1:39:29,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   4%|▍         | 163/3636 [04:41<1:39:29,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   4%|▍         | 163/3636 [04:42<1:39:29,  1.72s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:   5%|▍         | 164/3636 [04:42<1:39:24,  1.72s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:   5%|▍         | 164/3636 [04:44<1:39:24,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:   5%|▍         | 165/3636 [04:44<1:39:20,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:   5%|▍         | 165/3636 [04:46<1:39:20,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   5%|▍         | 166/3636 [04:46<1:39:22,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   5%|▍         | 166/3636 [04:48<1:39:22,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:   5%|▍         | 167/3636 [04:48<1:39:21,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:   5%|▍         | 167/3636 [04:49<1:39:21,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   5%|▍         | 168/3636 [04:49<1:39:18,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   5%|▍         | 168/3636 [04:51<1:39:18,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:   5%|▍         | 169/3636 [04:51<1:39:14,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:   5%|▍         | 169/3636 [04:53<1:39:14,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   5%|▍         | 170/3636 [04:53<1:39:14,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   5%|▍         | 170/3636 [04:54<1:39:14,  1.72s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:   5%|▍         | 171/3636 [04:54<1:39:13,  1.72s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:   5%|▍         | 171/3636 [04:56<1:39:13,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   5%|▍         | 172/3636 [04:56<1:39:10,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   5%|▍         | 172/3636 [04:58<1:39:10,  1.72s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   5%|▍         | 173/3636 [04:58<1:39:06,  1.72s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   5%|▍         | 173/3636 [05:00<1:39:06,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   5%|▍         | 174/3636 [05:00<1:39:04,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   5%|▍         | 174/3636 [05:01<1:39:04,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:   5%|▍         | 175/3636 [05:01<1:39:02,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:   5%|▍         | 175/3636 [05:03<1:39:02,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   5%|▍         | 176/3636 [05:03<1:39:00,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   5%|▍         | 176/3636 [05:05<1:39:00,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   5%|▍         | 177/3636 [05:05<1:39:00,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   5%|▍         | 177/3636 [05:06<1:39:00,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   5%|▍         | 178/3636 [05:06<1:38:58,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   5%|▍         | 178/3636 [05:08<1:38:58,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:   5%|▍         | 179/3636 [05:08<1:38:56,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:   5%|▍         | 179/3636 [05:10<1:38:56,  1.72s/it, training_loss=0.389]\u001b[A\n",
      "Epoch 1:   5%|▍         | 180/3636 [05:10<1:38:53,  1.72s/it, training_loss=0.389]\u001b[A\n",
      "Epoch 1:   5%|▍         | 180/3636 [05:12<1:38:53,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:   5%|▍         | 181/3636 [05:12<1:38:50,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:   5%|▍         | 181/3636 [05:13<1:38:50,  1.72s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   5%|▌         | 182/3636 [05:13<1:38:50,  1.72s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   5%|▌         | 182/3636 [05:15<1:38:50,  1.72s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:   5%|▌         | 183/3636 [05:15<1:38:48,  1.72s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:   5%|▌         | 183/3636 [05:17<1:38:48,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   5%|▌         | 184/3636 [05:17<1:38:48,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   5%|▌         | 184/3636 [05:18<1:38:48,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:   5%|▌         | 185/3636 [05:18<1:38:44,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:   5%|▌         | 185/3636 [05:20<1:38:44,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:   5%|▌         | 186/3636 [05:20<1:38:41,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:   5%|▌         | 186/3636 [05:22<1:38:41,  1.72s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:   5%|▌         | 187/3636 [05:22<1:38:39,  1.72s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:   5%|▌         | 187/3636 [05:24<1:38:39,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:   5%|▌         | 188/3636 [05:24<1:38:39,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:   5%|▌         | 188/3636 [05:25<1:38:39,  1.72s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:   5%|▌         | 189/3636 [05:25<1:38:36,  1.72s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:   5%|▌         | 189/3636 [05:27<1:38:36,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   5%|▌         | 190/3636 [05:27<1:38:32,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   5%|▌         | 190/3636 [05:29<1:38:32,  1.72s/it, training_loss=0.360]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 191/3636 [05:29<1:38:31,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   5%|▌         | 191/3636 [05:30<1:38:31,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:   5%|▌         | 192/3636 [05:30<1:38:29,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:   5%|▌         | 192/3636 [05:32<1:38:29,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:   5%|▌         | 193/3636 [05:32<1:38:28,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:   5%|▌         | 193/3636 [05:34<1:38:28,  1.72s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:   5%|▌         | 194/3636 [05:34<1:38:28,  1.72s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:   5%|▌         | 194/3636 [05:36<1:38:28,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   5%|▌         | 195/3636 [05:36<1:38:26,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   5%|▌         | 195/3636 [05:37<1:38:26,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   5%|▌         | 196/3636 [05:37<1:38:27,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   5%|▌         | 196/3636 [05:39<1:38:27,  1.72s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 1:   5%|▌         | 197/3636 [05:39<1:38:25,  1.72s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 1:   5%|▌         | 197/3636 [05:41<1:38:25,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   5%|▌         | 198/3636 [05:41<1:38:24,  1.72s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:   5%|▌         | 198/3636 [05:42<1:38:24,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   5%|▌         | 199/3636 [05:42<1:38:22,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   5%|▌         | 199/3636 [05:44<1:38:22,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   6%|▌         | 200/3636 [05:44<1:38:19,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   6%|▌         | 200/3636 [05:46<1:38:19,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:   6%|▌         | 201/3636 [05:46<1:38:16,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:   6%|▌         | 201/3636 [05:48<1:38:16,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   6%|▌         | 202/3636 [05:48<1:38:16,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   6%|▌         | 202/3636 [05:49<1:38:16,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   6%|▌         | 203/3636 [05:49<1:38:15,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   6%|▌         | 203/3636 [05:51<1:38:15,  1.72s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:   6%|▌         | 204/3636 [05:51<1:38:15,  1.72s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:   6%|▌         | 204/3636 [05:53<1:38:15,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   6%|▌         | 205/3636 [05:53<1:38:14,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   6%|▌         | 205/3636 [05:54<1:38:14,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   6%|▌         | 206/3636 [05:54<1:38:14,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   6%|▌         | 206/3636 [05:56<1:38:14,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:   6%|▌         | 207/3636 [05:56<1:38:12,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:   6%|▌         | 207/3636 [05:58<1:38:12,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:   6%|▌         | 208/3636 [05:58<1:38:11,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:   6%|▌         | 208/3636 [06:00<1:38:11,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   6%|▌         | 209/3636 [06:00<1:38:09,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   6%|▌         | 209/3636 [06:01<1:38:09,  1.72s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:   6%|▌         | 210/3636 [06:01<1:38:06,  1.72s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:   6%|▌         | 210/3636 [06:03<1:38:06,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:   6%|▌         | 211/3636 [06:03<1:38:04,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:   6%|▌         | 211/3636 [06:05<1:38:04,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   6%|▌         | 212/3636 [06:05<1:38:02,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:   6%|▌         | 212/3636 [06:07<1:38:02,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:   6%|▌         | 213/3636 [06:07<1:37:59,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:   6%|▌         | 213/3636 [06:08<1:37:59,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:   6%|▌         | 214/3636 [06:08<1:37:57,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:   6%|▌         | 214/3636 [06:10<1:37:57,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   6%|▌         | 215/3636 [06:10<1:37:54,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   6%|▌         | 215/3636 [06:12<1:37:54,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   6%|▌         | 216/3636 [06:12<1:37:53,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   6%|▌         | 216/3636 [06:13<1:37:53,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:   6%|▌         | 217/3636 [06:13<1:37:53,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:   6%|▌         | 217/3636 [06:15<1:37:53,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:   6%|▌         | 218/3636 [06:15<1:37:53,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:   6%|▌         | 218/3636 [06:17<1:37:53,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:   6%|▌         | 219/3636 [06:17<1:37:52,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:   6%|▌         | 219/3636 [06:19<1:37:52,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   6%|▌         | 220/3636 [06:19<1:37:53,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   6%|▌         | 220/3636 [06:20<1:37:53,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   6%|▌         | 221/3636 [06:20<1:37:49,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   6%|▌         | 221/3636 [06:22<1:37:49,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   6%|▌         | 222/3636 [06:22<1:37:50,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   6%|▌         | 222/3636 [06:24<1:37:50,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:   6%|▌         | 223/3636 [06:24<1:37:49,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:   6%|▌         | 223/3636 [06:25<1:37:49,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:   6%|▌         | 224/3636 [06:25<1:37:48,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:   6%|▌         | 224/3636 [06:27<1:37:48,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:   6%|▌         | 225/3636 [06:27<1:37:42,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:   6%|▌         | 225/3636 [06:29<1:37:42,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   6%|▌         | 226/3636 [06:29<1:37:42,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   6%|▌         | 226/3636 [06:31<1:37:42,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:   6%|▌         | 227/3636 [06:31<1:37:38,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:   6%|▌         | 227/3636 [06:32<1:37:38,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:   6%|▋         | 228/3636 [06:32<1:37:38,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:   6%|▋         | 228/3636 [06:34<1:37:38,  1.72s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:   6%|▋         | 229/3636 [06:34<1:37:36,  1.72s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:   6%|▋         | 229/3636 [06:36<1:37:36,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:   6%|▋         | 230/3636 [06:36<1:37:36,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:   6%|▋         | 230/3636 [06:37<1:37:36,  1.72s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 1:   6%|▋         | 231/3636 [06:37<1:37:31,  1.72s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 1:   6%|▋         | 231/3636 [06:39<1:37:31,  1.72s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 1:   6%|▋         | 232/3636 [06:39<1:37:31,  1.72s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 1:   6%|▋         | 232/3636 [06:41<1:37:31,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:   6%|▋         | 233/3636 [06:41<1:37:29,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:   6%|▋         | 233/3636 [06:43<1:37:29,  1.72s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:   6%|▋         | 234/3636 [06:43<1:37:28,  1.72s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:   6%|▋         | 234/3636 [06:44<1:37:28,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:   6%|▋         | 235/3636 [06:44<1:37:26,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:   6%|▋         | 235/3636 [06:46<1:37:26,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:   6%|▋         | 236/3636 [06:46<1:37:26,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:   6%|▋         | 236/3636 [06:48<1:37:26,  1.72s/it, training_loss=0.377]\u001b[A\n",
      "Epoch 1:   7%|▋         | 237/3636 [06:48<1:37:26,  1.72s/it, training_loss=0.377]\u001b[A\n",
      "Epoch 1:   7%|▋         | 237/3636 [06:49<1:37:26,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   7%|▋         | 238/3636 [06:49<1:37:25,  1.72s/it, training_loss=0.345]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|▋         | 238/3636 [06:51<1:37:25,  1.72s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:   7%|▋         | 239/3636 [06:51<1:37:22,  1.72s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:   7%|▋         | 239/3636 [06:53<1:37:22,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   7%|▋         | 240/3636 [06:53<1:37:21,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   7%|▋         | 240/3636 [06:55<1:37:21,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:   7%|▋         | 241/3636 [06:55<1:37:21,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:   7%|▋         | 241/3636 [06:56<1:37:21,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   7%|▋         | 242/3636 [06:56<1:37:19,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   7%|▋         | 242/3636 [06:58<1:37:19,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:   7%|▋         | 243/3636 [06:58<1:37:15,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:   7%|▋         | 243/3636 [07:00<1:37:15,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:   7%|▋         | 244/3636 [07:00<1:37:14,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:   7%|▋         | 244/3636 [07:02<1:37:14,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:   7%|▋         | 245/3636 [07:02<1:37:13,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:   7%|▋         | 245/3636 [07:03<1:37:13,  1.72s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   7%|▋         | 246/3636 [07:03<1:37:12,  1.72s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   7%|▋         | 246/3636 [07:05<1:37:12,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:   7%|▋         | 247/3636 [07:05<1:37:11,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:   7%|▋         | 247/3636 [07:07<1:37:11,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:   7%|▋         | 248/3636 [07:07<1:37:09,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:   7%|▋         | 248/3636 [07:08<1:37:09,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:   7%|▋         | 249/3636 [07:08<1:37:08,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:   7%|▋         | 249/3636 [07:10<1:37:08,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   7%|▋         | 250/3636 [07:10<1:37:03,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   7%|▋         | 250/3636 [07:12<1:37:03,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:   7%|▋         | 251/3636 [07:12<1:37:00,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:   7%|▋         | 251/3636 [07:14<1:37:00,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   7%|▋         | 252/3636 [07:14<1:37:00,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   7%|▋         | 252/3636 [07:15<1:37:00,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   7%|▋         | 253/3636 [07:15<1:36:57,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   7%|▋         | 253/3636 [07:17<1:36:57,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:   7%|▋         | 254/3636 [07:17<1:36:54,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:   7%|▋         | 254/3636 [07:19<1:36:54,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   7%|▋         | 255/3636 [07:19<1:36:52,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   7%|▋         | 255/3636 [07:20<1:36:52,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   7%|▋         | 256/3636 [07:20<1:36:49,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   7%|▋         | 256/3636 [07:22<1:36:49,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:   7%|▋         | 257/3636 [07:22<1:36:47,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:   7%|▋         | 257/3636 [07:24<1:36:47,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   7%|▋         | 258/3636 [07:24<1:36:48,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   7%|▋         | 258/3636 [07:26<1:36:48,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   7%|▋         | 259/3636 [07:26<1:36:46,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:   7%|▋         | 259/3636 [07:27<1:36:46,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:   7%|▋         | 260/3636 [07:27<1:36:42,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:   7%|▋         | 260/3636 [07:29<1:36:42,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   7%|▋         | 261/3636 [07:29<1:36:43,  1.72s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:   7%|▋         | 261/3636 [07:31<1:36:43,  1.72s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:   7%|▋         | 262/3636 [07:31<1:36:43,  1.72s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:   7%|▋         | 262/3636 [07:32<1:36:43,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:   7%|▋         | 263/3636 [07:32<1:36:40,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:   7%|▋         | 263/3636 [07:34<1:36:40,  1.72s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:   7%|▋         | 264/3636 [07:34<1:36:37,  1.72s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:   7%|▋         | 264/3636 [07:36<1:36:37,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:   7%|▋         | 265/3636 [07:36<1:36:34,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:   7%|▋         | 265/3636 [07:38<1:36:34,  1.72s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:   7%|▋         | 266/3636 [07:38<1:36:31,  1.72s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:   7%|▋         | 266/3636 [07:39<1:36:31,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:   7%|▋         | 267/3636 [07:39<1:36:29,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:   7%|▋         | 267/3636 [07:41<1:36:29,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   7%|▋         | 268/3636 [07:41<1:36:29,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:   7%|▋         | 268/3636 [07:43<1:36:29,  1.72s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:   7%|▋         | 269/3636 [07:43<1:36:28,  1.72s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:   7%|▋         | 269/3636 [07:45<1:36:28,  1.72s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   7%|▋         | 270/3636 [07:45<1:36:27,  1.72s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   7%|▋         | 270/3636 [07:46<1:36:27,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:   7%|▋         | 271/3636 [07:46<1:36:28,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:   7%|▋         | 271/3636 [07:48<1:36:28,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   7%|▋         | 272/3636 [07:48<1:36:26,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   7%|▋         | 272/3636 [07:50<1:36:26,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   8%|▊         | 273/3636 [07:50<1:36:26,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   8%|▊         | 273/3636 [07:51<1:36:26,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:   8%|▊         | 274/3636 [07:51<1:36:23,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:   8%|▊         | 274/3636 [07:53<1:36:23,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   8%|▊         | 275/3636 [07:53<1:36:20,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   8%|▊         | 275/3636 [07:55<1:36:20,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:   8%|▊         | 276/3636 [07:55<1:36:17,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:   8%|▊         | 276/3636 [07:57<1:36:17,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:   8%|▊         | 277/3636 [07:57<1:36:12,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:   8%|▊         | 277/3636 [07:58<1:36:12,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   8%|▊         | 278/3636 [07:58<1:36:16,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   8%|▊         | 278/3636 [08:00<1:36:16,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   8%|▊         | 279/3636 [08:00<1:36:19,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   8%|▊         | 279/3636 [08:02<1:36:19,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:   8%|▊         | 280/3636 [08:02<1:36:16,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:   8%|▊         | 280/3636 [08:03<1:36:16,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   8%|▊         | 281/3636 [08:03<1:36:14,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   8%|▊         | 281/3636 [08:05<1:36:14,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:   8%|▊         | 282/3636 [08:05<1:36:12,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:   8%|▊         | 282/3636 [08:07<1:36:12,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:   8%|▊         | 283/3636 [08:07<1:36:10,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:   8%|▊         | 283/3636 [08:09<1:36:10,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:   8%|▊         | 284/3636 [08:09<1:36:08,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:   8%|▊         | 284/3636 [08:10<1:36:08,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:   8%|▊         | 285/3636 [08:10<1:36:06,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:   8%|▊         | 285/3636 [08:12<1:36:06,  1.72s/it, training_loss=0.326]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 286/3636 [08:12<1:36:04,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:   8%|▊         | 286/3636 [08:14<1:36:04,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:   8%|▊         | 287/3636 [08:14<1:36:03,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:   8%|▊         | 287/3636 [08:15<1:36:03,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   8%|▊         | 288/3636 [08:15<1:36:02,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   8%|▊         | 288/3636 [08:17<1:36:02,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   8%|▊         | 289/3636 [08:17<1:36:01,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   8%|▊         | 289/3636 [08:19<1:36:01,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:   8%|▊         | 290/3636 [08:19<1:35:58,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:   8%|▊         | 290/3636 [08:21<1:35:58,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:   8%|▊         | 291/3636 [08:21<1:35:57,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:   8%|▊         | 291/3636 [08:22<1:35:57,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   8%|▊         | 292/3636 [08:22<1:35:54,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:   8%|▊         | 292/3636 [08:24<1:35:54,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:   8%|▊         | 293/3636 [08:24<1:35:54,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:   8%|▊         | 293/3636 [08:26<1:35:54,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   8%|▊         | 294/3636 [08:26<1:35:53,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   8%|▊         | 294/3636 [08:28<1:35:53,  1.72s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 1:   8%|▊         | 295/3636 [08:28<1:35:53,  1.72s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 1:   8%|▊         | 295/3636 [08:29<1:35:53,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:   8%|▊         | 296/3636 [08:29<1:35:55,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:   8%|▊         | 296/3636 [08:31<1:35:55,  1.72s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:   8%|▊         | 297/3636 [08:31<1:35:51,  1.72s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:   8%|▊         | 297/3636 [08:33<1:35:51,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:   8%|▊         | 298/3636 [08:33<1:35:46,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:   8%|▊         | 298/3636 [08:34<1:35:46,  1.72s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 1:   8%|▊         | 299/3636 [08:34<1:35:46,  1.72s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 1:   8%|▊         | 299/3636 [08:36<1:35:46,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:   8%|▊         | 300/3636 [08:36<1:35:48,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:   8%|▊         | 300/3636 [08:38<1:35:48,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:   8%|▊         | 301/3636 [08:38<1:35:45,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:   8%|▊         | 301/3636 [08:40<1:35:45,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   8%|▊         | 302/3636 [08:40<1:35:44,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   8%|▊         | 302/3636 [08:41<1:35:44,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   8%|▊         | 303/3636 [08:41<1:35:40,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   8%|▊         | 303/3636 [08:43<1:35:40,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:   8%|▊         | 304/3636 [08:43<1:35:38,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:   8%|▊         | 304/3636 [08:45<1:35:38,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   8%|▊         | 305/3636 [08:45<1:35:38,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:   8%|▊         | 305/3636 [08:46<1:35:38,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:   8%|▊         | 306/3636 [08:46<1:35:36,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:   8%|▊         | 306/3636 [08:48<1:35:36,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:   8%|▊         | 307/3636 [08:48<1:35:32,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:   8%|▊         | 307/3636 [08:50<1:35:32,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:   8%|▊         | 308/3636 [08:50<1:35:31,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:   8%|▊         | 308/3636 [08:52<1:35:31,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:   8%|▊         | 309/3636 [08:52<1:35:29,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:   8%|▊         | 309/3636 [08:53<1:35:29,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   9%|▊         | 310/3636 [08:53<1:35:29,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   9%|▊         | 310/3636 [08:55<1:35:29,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:   9%|▊         | 311/3636 [08:55<1:35:29,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:   9%|▊         | 311/3636 [08:57<1:35:29,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:   9%|▊         | 312/3636 [08:57<1:35:27,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:   9%|▊         | 312/3636 [08:59<1:35:27,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   9%|▊         | 313/3636 [08:59<1:35:24,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:   9%|▊         | 313/3636 [09:00<1:35:24,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   9%|▊         | 314/3636 [09:00<1:35:25,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   9%|▊         | 314/3636 [09:02<1:35:25,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   9%|▊         | 315/3636 [09:02<1:35:23,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:   9%|▊         | 315/3636 [09:04<1:35:23,  1.72s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 1:   9%|▊         | 316/3636 [09:04<1:35:21,  1.72s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 1:   9%|▊         | 316/3636 [09:05<1:35:21,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   9%|▊         | 317/3636 [09:05<1:35:21,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:   9%|▊         | 317/3636 [09:07<1:35:21,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:   9%|▊         | 318/3636 [09:07<1:35:19,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:   9%|▊         | 318/3636 [09:09<1:35:19,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:   9%|▉         | 319/3636 [09:09<1:35:17,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:   9%|▉         | 319/3636 [09:11<1:35:17,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:   9%|▉         | 320/3636 [09:11<1:35:14,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:   9%|▉         | 320/3636 [09:12<1:35:14,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:   9%|▉         | 321/3636 [09:12<1:35:17,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:   9%|▉         | 321/3636 [09:14<1:35:17,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:   9%|▉         | 322/3636 [09:14<1:35:18,  1.73s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:   9%|▉         | 322/3636 [09:16<1:35:18,  1.73s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   9%|▉         | 323/3636 [09:16<1:35:13,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   9%|▉         | 323/3636 [09:18<1:35:13,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:   9%|▉         | 324/3636 [09:18<1:35:09,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:   9%|▉         | 324/3636 [09:19<1:35:09,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   9%|▉         | 325/3636 [09:19<1:35:06,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:   9%|▉         | 325/3636 [09:21<1:35:06,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   9%|▉         | 326/3636 [09:21<1:35:06,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:   9%|▉         | 326/3636 [09:23<1:35:06,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   9%|▉         | 327/3636 [09:23<1:35:05,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   9%|▉         | 327/3636 [09:24<1:35:05,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:   9%|▉         | 328/3636 [09:24<1:35:05,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:   9%|▉         | 328/3636 [09:26<1:35:05,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:   9%|▉         | 329/3636 [09:26<1:35:06,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:   9%|▉         | 329/3636 [09:28<1:35:06,  1.73s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:   9%|▉         | 330/3636 [09:28<1:35:06,  1.73s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:   9%|▉         | 330/3636 [09:30<1:35:06,  1.73s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:   9%|▉         | 331/3636 [09:30<1:35:06,  1.73s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:   9%|▉         | 331/3636 [09:31<1:35:06,  1.73s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:   9%|▉         | 332/3636 [09:31<1:35:04,  1.73s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:   9%|▉         | 332/3636 [09:33<1:35:04,  1.73s/it, training_loss=0.403]\u001b[A\n",
      "Epoch 1:   9%|▉         | 333/3636 [09:33<1:35:04,  1.73s/it, training_loss=0.403]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▉         | 333/3636 [09:35<1:35:04,  1.73s/it, training_loss=0.393]\u001b[A\n",
      "Epoch 1:   9%|▉         | 334/3636 [09:35<1:35:03,  1.73s/it, training_loss=0.393]\u001b[A\n",
      "Epoch 1:   9%|▉         | 334/3636 [09:36<1:35:03,  1.73s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:   9%|▉         | 335/3636 [09:37<1:34:59,  1.73s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:   9%|▉         | 335/3636 [09:38<1:34:59,  1.73s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:   9%|▉         | 336/3636 [09:38<1:34:57,  1.73s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:   9%|▉         | 336/3636 [09:40<1:34:57,  1.73s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:   9%|▉         | 337/3636 [09:40<1:34:56,  1.73s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:   9%|▉         | 337/3636 [09:42<1:34:56,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   9%|▉         | 338/3636 [09:42<1:34:53,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:   9%|▉         | 338/3636 [09:43<1:34:53,  1.73s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:   9%|▉         | 339/3636 [09:43<1:34:54,  1.73s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:   9%|▉         | 339/3636 [09:45<1:34:54,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:   9%|▉         | 340/3636 [09:45<1:34:54,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:   9%|▉         | 340/3636 [09:47<1:34:54,  1.73s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:   9%|▉         | 341/3636 [09:47<1:34:55,  1.73s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:   9%|▉         | 341/3636 [09:49<1:34:55,  1.73s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:   9%|▉         | 342/3636 [09:49<1:34:52,  1.73s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:   9%|▉         | 342/3636 [09:50<1:34:52,  1.73s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:   9%|▉         | 343/3636 [09:50<1:34:49,  1.73s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:   9%|▉         | 343/3636 [09:52<1:34:49,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:   9%|▉         | 344/3636 [09:52<1:34:48,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:   9%|▉         | 344/3636 [09:54<1:34:48,  1.73s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   9%|▉         | 345/3636 [09:54<1:34:48,  1.73s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   9%|▉         | 345/3636 [09:56<1:34:48,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  10%|▉         | 346/3636 [09:56<1:34:43,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  10%|▉         | 346/3636 [09:57<1:34:43,  1.73s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  10%|▉         | 347/3636 [09:57<1:34:41,  1.73s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  10%|▉         | 347/3636 [09:59<1:34:41,  1.73s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  10%|▉         | 348/3636 [09:59<1:34:37,  1.73s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  10%|▉         | 348/3636 [10:01<1:34:37,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  10%|▉         | 349/3636 [10:01<1:34:36,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  10%|▉         | 349/3636 [10:02<1:34:36,  1.73s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  10%|▉         | 350/3636 [10:02<1:34:37,  1.73s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  10%|▉         | 350/3636 [10:04<1:34:37,  1.73s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  10%|▉         | 351/3636 [10:04<1:34:37,  1.73s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  10%|▉         | 351/3636 [10:06<1:34:37,  1.73s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  10%|▉         | 352/3636 [10:06<1:34:35,  1.73s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  10%|▉         | 352/3636 [10:08<1:34:35,  1.73s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  10%|▉         | 353/3636 [10:08<1:34:34,  1.73s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  10%|▉         | 353/3636 [10:09<1:34:34,  1.73s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  10%|▉         | 354/3636 [10:09<1:34:31,  1.73s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  10%|▉         | 354/3636 [10:11<1:34:31,  1.73s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  10%|▉         | 355/3636 [10:11<1:34:28,  1.73s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  10%|▉         | 355/3636 [10:13<1:34:28,  1.73s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  10%|▉         | 356/3636 [10:13<1:34:28,  1.73s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  10%|▉         | 356/3636 [10:15<1:34:28,  1.73s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  10%|▉         | 357/3636 [10:15<1:34:27,  1.73s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  10%|▉         | 357/3636 [10:16<1:34:27,  1.73s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  10%|▉         | 358/3636 [10:16<1:34:27,  1.73s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  10%|▉         | 358/3636 [10:18<1:34:27,  1.73s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  10%|▉         | 359/3636 [10:18<1:34:26,  1.73s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  10%|▉         | 359/3636 [10:20<1:34:26,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  10%|▉         | 360/3636 [10:20<1:34:27,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  10%|▉         | 360/3636 [10:21<1:34:27,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  10%|▉         | 361/3636 [10:21<1:34:26,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  10%|▉         | 361/3636 [10:23<1:34:26,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  10%|▉         | 362/3636 [10:23<1:34:21,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  10%|▉         | 362/3636 [10:25<1:34:21,  1.73s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  10%|▉         | 363/3636 [10:25<1:34:18,  1.73s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  10%|▉         | 363/3636 [10:27<1:34:18,  1.73s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  10%|█         | 364/3636 [10:27<1:34:15,  1.73s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  10%|█         | 364/3636 [10:28<1:34:15,  1.73s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  10%|█         | 365/3636 [10:28<1:34:16,  1.73s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  10%|█         | 365/3636 [10:30<1:34:16,  1.73s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  10%|█         | 366/3636 [10:30<1:34:15,  1.73s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  10%|█         | 366/3636 [10:32<1:34:15,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  10%|█         | 367/3636 [10:32<1:34:13,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  10%|█         | 367/3636 [10:34<1:34:13,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  10%|█         | 368/3636 [10:34<1:34:09,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  10%|█         | 368/3636 [10:35<1:34:09,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  10%|█         | 369/3636 [10:35<1:34:06,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  10%|█         | 369/3636 [10:37<1:34:06,  1.73s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:  10%|█         | 370/3636 [10:37<1:34:07,  1.73s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:  10%|█         | 370/3636 [10:39<1:34:07,  1.73s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  10%|█         | 371/3636 [10:39<1:34:02,  1.73s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  10%|█         | 371/3636 [10:40<1:34:02,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  10%|█         | 372/3636 [10:40<1:34:01,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  10%|█         | 372/3636 [10:42<1:34:01,  1.73s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  10%|█         | 373/3636 [10:42<1:34:00,  1.73s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  10%|█         | 373/3636 [10:44<1:34:00,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  10%|█         | 374/3636 [10:44<1:33:58,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  10%|█         | 374/3636 [10:46<1:33:58,  1.73s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  10%|█         | 375/3636 [10:46<1:33:57,  1.73s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  10%|█         | 375/3636 [10:47<1:33:57,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  10%|█         | 376/3636 [10:47<1:33:55,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  10%|█         | 376/3636 [10:49<1:33:55,  1.73s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  10%|█         | 377/3636 [10:49<1:33:54,  1.73s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  10%|█         | 377/3636 [10:51<1:33:54,  1.73s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  10%|█         | 378/3636 [10:51<1:33:53,  1.73s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  10%|█         | 378/3636 [10:53<1:33:53,  1.73s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  10%|█         | 379/3636 [10:53<1:33:50,  1.73s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  10%|█         | 379/3636 [10:54<1:33:50,  1.73s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  10%|█         | 380/3636 [10:54<1:33:50,  1.73s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  10%|█         | 380/3636 [10:56<1:33:50,  1.73s/it, training_loss=0.335]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|█         | 381/3636 [10:56<1:33:47,  1.73s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  10%|█         | 381/3636 [10:58<1:33:47,  1.73s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  11%|█         | 382/3636 [10:58<1:33:46,  1.73s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  11%|█         | 382/3636 [10:59<1:33:46,  1.73s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  11%|█         | 383/3636 [10:59<1:33:44,  1.73s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  11%|█         | 383/3636 [11:01<1:33:44,  1.73s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  11%|█         | 384/3636 [11:01<1:33:44,  1.73s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  11%|█         | 384/3636 [11:03<1:33:44,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  11%|█         | 385/3636 [11:03<1:33:41,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  11%|█         | 385/3636 [11:05<1:33:41,  1.73s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  11%|█         | 386/3636 [11:05<1:33:42,  1.73s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  11%|█         | 386/3636 [11:06<1:33:42,  1.73s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  11%|█         | 387/3636 [11:06<1:33:40,  1.73s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  11%|█         | 387/3636 [11:08<1:33:40,  1.73s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  11%|█         | 388/3636 [11:08<1:33:39,  1.73s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  11%|█         | 388/3636 [11:10<1:33:39,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  11%|█         | 389/3636 [11:10<1:33:40,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  11%|█         | 389/3636 [11:12<1:33:40,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  11%|█         | 390/3636 [11:12<1:33:40,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  11%|█         | 390/3636 [11:13<1:33:40,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  11%|█         | 391/3636 [11:13<1:33:38,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  11%|█         | 391/3636 [11:15<1:33:38,  1.73s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  11%|█         | 392/3636 [11:15<1:33:36,  1.73s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  11%|█         | 392/3636 [11:17<1:33:36,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  11%|█         | 393/3636 [11:17<1:33:35,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  11%|█         | 393/3636 [11:19<1:33:35,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  11%|█         | 394/3636 [11:19<1:33:34,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  11%|█         | 394/3636 [11:20<1:33:34,  1.73s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  11%|█         | 395/3636 [11:20<1:33:31,  1.73s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  11%|█         | 395/3636 [11:22<1:33:31,  1.73s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  11%|█         | 396/3636 [11:22<1:33:28,  1.73s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  11%|█         | 396/3636 [11:24<1:33:28,  1.73s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  11%|█         | 397/3636 [11:24<1:33:25,  1.73s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  11%|█         | 397/3636 [11:25<1:33:25,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  11%|█         | 398/3636 [11:25<1:33:24,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  11%|█         | 398/3636 [11:27<1:33:24,  1.73s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  11%|█         | 399/3636 [11:27<1:33:23,  1.73s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  11%|█         | 399/3636 [11:29<1:33:23,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  11%|█         | 400/3636 [11:29<1:33:19,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  11%|█         | 400/3636 [11:31<1:33:19,  1.73s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  11%|█         | 401/3636 [11:31<1:33:17,  1.73s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  11%|█         | 401/3636 [11:32<1:33:17,  1.73s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  11%|█         | 402/3636 [11:32<1:33:17,  1.73s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  11%|█         | 402/3636 [11:34<1:33:17,  1.73s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  11%|█         | 403/3636 [11:34<1:33:16,  1.73s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  11%|█         | 403/3636 [11:36<1:33:16,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  11%|█         | 404/3636 [11:36<1:33:13,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  11%|█         | 404/3636 [11:38<1:33:13,  1.73s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  11%|█         | 405/3636 [11:38<1:33:12,  1.73s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  11%|█         | 405/3636 [11:39<1:33:12,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  11%|█         | 406/3636 [11:39<1:33:07,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  11%|█         | 406/3636 [11:41<1:33:07,  1.73s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  11%|█         | 407/3636 [11:41<1:33:05,  1.73s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  11%|█         | 407/3636 [11:43<1:33:05,  1.73s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:  11%|█         | 408/3636 [11:43<1:33:08,  1.73s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:  11%|█         | 408/3636 [11:44<1:33:08,  1.73s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  11%|█         | 409/3636 [11:44<1:33:08,  1.73s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  11%|█         | 409/3636 [11:46<1:33:08,  1.73s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 410/3636 [11:46<1:33:04,  1.73s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 410/3636 [11:48<1:33:04,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 411/3636 [11:48<1:33:01,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 411/3636 [11:50<1:33:01,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 412/3636 [11:50<1:32:58,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 412/3636 [11:51<1:32:58,  1.73s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 413/3636 [11:51<1:32:56,  1.73s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 413/3636 [11:53<1:32:56,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 414/3636 [11:53<1:32:54,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 414/3636 [11:55<1:32:54,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 415/3636 [11:55<1:32:55,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 415/3636 [11:57<1:32:55,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 416/3636 [11:57<1:32:53,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 416/3636 [11:58<1:32:53,  1.73s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 417/3636 [11:58<1:32:51,  1.73s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 417/3636 [12:00<1:32:51,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 418/3636 [12:00<1:32:50,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 418/3636 [12:02<1:32:50,  1.73s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 419/3636 [12:02<1:32:46,  1.73s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 419/3636 [12:04<1:32:46,  1.73s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 420/3636 [12:04<1:32:45,  1.73s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 420/3636 [12:05<1:32:45,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 421/3636 [12:05<1:32:44,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 421/3636 [12:07<1:32:44,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 422/3636 [12:07<1:32:42,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 422/3636 [12:09<1:32:42,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 423/3636 [12:09<1:32:42,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 423/3636 [12:10<1:32:42,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 424/3636 [12:10<1:32:41,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 424/3636 [12:12<1:32:41,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 425/3636 [12:12<1:32:40,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 425/3636 [12:14<1:32:40,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 426/3636 [12:14<1:32:38,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 426/3636 [12:16<1:32:38,  1.73s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 427/3636 [12:16<1:32:35,  1.73s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 427/3636 [12:17<1:32:35,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 428/3636 [12:17<1:32:30,  1.73s/it, training_loss=0.293]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 428/3636 [12:19<1:32:30,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 429/3636 [12:19<1:32:26,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 429/3636 [12:21<1:32:26,  1.73s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 430/3636 [12:21<1:32:21,  1.73s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 430/3636 [12:23<1:32:21,  1.73s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 431/3636 [12:23<1:32:20,  1.73s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 431/3636 [12:24<1:32:20,  1.73s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 432/3636 [12:24<1:32:20,  1.73s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 432/3636 [12:26<1:32:20,  1.73s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 433/3636 [12:26<1:32:21,  1.73s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 433/3636 [12:28<1:32:21,  1.73s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 434/3636 [12:28<1:32:19,  1.73s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 434/3636 [12:29<1:32:19,  1.73s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 435/3636 [12:29<1:32:19,  1.73s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 435/3636 [12:31<1:32:19,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 436/3636 [12:31<1:32:18,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 436/3636 [12:33<1:32:18,  1.73s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 437/3636 [12:33<1:32:16,  1.73s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 437/3636 [12:35<1:32:16,  1.73s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 438/3636 [12:35<1:32:13,  1.73s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 438/3636 [12:36<1:32:13,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 439/3636 [12:36<1:32:12,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 439/3636 [12:38<1:32:12,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 440/3636 [12:38<1:32:11,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 440/3636 [12:40<1:32:11,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 441/3636 [12:40<1:32:08,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 441/3636 [12:42<1:32:08,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 442/3636 [12:42<1:32:07,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 442/3636 [12:43<1:32:07,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 443/3636 [12:43<1:32:04,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 443/3636 [12:45<1:32:04,  1.73s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 444/3636 [12:45<1:32:04,  1.73s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 444/3636 [12:47<1:32:04,  1.73s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 445/3636 [12:47<1:32:03,  1.73s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 445/3636 [12:48<1:32:03,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 446/3636 [12:49<1:32:01,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 446/3636 [12:50<1:32:01,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 447/3636 [12:50<1:31:58,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 447/3636 [12:52<1:31:58,  1.73s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 448/3636 [12:52<1:31:58,  1.73s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 448/3636 [12:54<1:31:58,  1.73s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 449/3636 [12:54<1:31:57,  1.73s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 449/3636 [12:55<1:31:57,  1.73s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 450/3636 [12:55<1:31:56,  1.73s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 450/3636 [12:57<1:31:56,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 451/3636 [12:57<1:31:54,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 451/3636 [12:59<1:31:54,  1.73s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 452/3636 [12:59<1:31:50,  1.73s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 452/3636 [13:01<1:31:50,  1.73s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 453/3636 [13:01<1:31:45,  1.73s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 453/3636 [13:02<1:31:45,  1.73s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 454/3636 [13:02<1:31:43,  1.73s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 454/3636 [13:04<1:31:43,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 455/3636 [13:04<1:31:42,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 455/3636 [13:06<1:31:42,  1.73s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 456/3636 [13:06<1:31:42,  1.73s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 456/3636 [13:08<1:31:42,  1.73s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 457/3636 [13:08<1:31:39,  1.73s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 457/3636 [13:09<1:31:39,  1.73s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 458/3636 [13:09<1:31:38,  1.73s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 458/3636 [13:11<1:31:38,  1.73s/it, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 459/3636 [13:11<1:31:35,  1.73s/it, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 459/3636 [13:13<1:31:35,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 460/3636 [13:13<1:31:31,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 460/3636 [13:14<1:31:31,  1.73s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 461/3636 [13:14<1:31:28,  1.73s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 461/3636 [13:16<1:31:28,  1.73s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 462/3636 [13:16<1:31:26,  1.73s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 462/3636 [13:18<1:31:26,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 463/3636 [13:18<1:31:24,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 463/3636 [13:20<1:31:24,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 464/3636 [13:20<1:31:23,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 464/3636 [13:21<1:31:23,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 465/3636 [13:21<1:31:22,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 465/3636 [13:23<1:31:22,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 466/3636 [13:23<1:31:23,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 466/3636 [13:25<1:31:23,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 467/3636 [13:25<1:31:19,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 467/3636 [13:27<1:31:19,  1.73s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 468/3636 [13:27<1:31:17,  1.73s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 468/3636 [13:28<1:31:17,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 469/3636 [13:28<1:31:14,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 469/3636 [13:30<1:31:14,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 470/3636 [13:30<1:31:09,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 470/3636 [13:32<1:31:09,  1.73s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 471/3636 [13:32<1:31:10,  1.73s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 471/3636 [13:33<1:31:10,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 472/3636 [13:33<1:31:08,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 472/3636 [13:35<1:31:08,  1.73s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 473/3636 [13:35<1:31:04,  1.73s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 473/3636 [13:37<1:31:04,  1.73s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 474/3636 [13:37<1:31:00,  1.73s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 474/3636 [13:39<1:31:00,  1.73s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 475/3636 [13:39<1:30:58,  1.73s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 475/3636 [13:40<1:30:58,  1.73s/it, training_loss=0.314]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█▎        | 476/3636 [13:40<1:30:56,  1.73s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 476/3636 [13:42<1:30:56,  1.73s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 477/3636 [13:42<1:30:55,  1.73s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 477/3636 [13:44<1:30:55,  1.73s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 478/3636 [13:44<1:30:53,  1.73s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 478/3636 [13:46<1:30:53,  1.73s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 479/3636 [13:46<1:30:50,  1.73s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 479/3636 [13:47<1:30:50,  1.73s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 480/3636 [13:47<1:30:48,  1.73s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 480/3636 [13:49<1:30:48,  1.73s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 481/3636 [13:49<1:30:47,  1.73s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 481/3636 [13:51<1:30:47,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 482/3636 [13:51<1:30:44,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 482/3636 [13:52<1:30:44,  1.73s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 483/3636 [13:52<1:30:41,  1.73s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 483/3636 [13:54<1:30:41,  1.73s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 484/3636 [13:54<1:30:38,  1.73s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 484/3636 [13:56<1:30:38,  1.73s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 485/3636 [13:56<1:30:35,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 485/3636 [13:58<1:30:35,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 486/3636 [13:58<1:30:32,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 486/3636 [13:59<1:30:32,  1.72s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 487/3636 [13:59<1:30:30,  1.72s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 487/3636 [14:01<1:30:30,  1.72s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 488/3636 [14:01<1:30:30,  1.73s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 488/3636 [14:03<1:30:30,  1.73s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 489/3636 [14:03<1:30:36,  1.73s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 489/3636 [14:05<1:30:36,  1.73s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 490/3636 [14:05<1:30:32,  1.73s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 490/3636 [14:06<1:30:32,  1.73s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 491/3636 [14:06<1:30:26,  1.73s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 491/3636 [14:08<1:30:26,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 492/3636 [14:08<1:30:21,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 492/3636 [14:10<1:30:21,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 493/3636 [14:10<1:30:19,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 493/3636 [14:11<1:30:19,  1.72s/it, training_loss=0.377]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 494/3636 [14:11<1:30:22,  1.73s/it, training_loss=0.377]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 494/3636 [14:13<1:30:22,  1.73s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 495/3636 [14:13<1:30:21,  1.73s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 495/3636 [14:15<1:30:21,  1.73s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 496/3636 [14:15<1:30:20,  1.73s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 496/3636 [14:17<1:30:20,  1.73s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 497/3636 [14:17<1:30:14,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 497/3636 [14:18<1:30:14,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 498/3636 [14:18<1:30:12,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 498/3636 [14:20<1:30:12,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 499/3636 [14:20<1:30:10,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 499/3636 [14:22<1:30:10,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 500/3636 [14:22<1:30:10,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 500/3636 [14:24<1:30:10,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 501/3636 [14:24<1:30:06,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 501/3636 [14:25<1:30:06,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 502/3636 [14:25<1:30:05,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 502/3636 [14:27<1:30:05,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 503/3636 [14:27<1:30:00,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 503/3636 [14:29<1:30:00,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 504/3636 [14:29<1:29:56,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 504/3636 [14:30<1:29:56,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 505/3636 [14:30<1:29:56,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 505/3636 [14:32<1:29:56,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 506/3636 [14:32<1:29:52,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 506/3636 [14:34<1:29:52,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 507/3636 [14:34<1:29:49,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 507/3636 [14:36<1:29:49,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 508/3636 [14:36<1:29:47,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 508/3636 [14:37<1:29:47,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 509/3636 [14:37<1:29:42,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 509/3636 [14:39<1:29:42,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 510/3636 [14:39<1:29:41,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 510/3636 [14:41<1:29:41,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 511/3636 [14:41<1:29:40,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 511/3636 [14:42<1:29:40,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 512/3636 [14:42<1:29:37,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 512/3636 [14:44<1:29:37,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 513/3636 [14:44<1:29:33,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 513/3636 [14:46<1:29:33,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 514/3636 [14:46<1:29:30,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 514/3636 [14:48<1:29:30,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 515/3636 [14:48<1:29:30,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 515/3636 [14:49<1:29:30,  1.72s/it, training_loss=0.393]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 516/3636 [14:49<1:29:28,  1.72s/it, training_loss=0.393]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 516/3636 [14:51<1:29:28,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 517/3636 [14:51<1:29:24,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 517/3636 [14:53<1:29:24,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 518/3636 [14:53<1:29:22,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 518/3636 [14:54<1:29:22,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 519/3636 [14:54<1:29:22,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 519/3636 [14:56<1:29:22,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 520/3636 [14:56<1:29:19,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 520/3636 [14:58<1:29:19,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 521/3636 [14:58<1:29:16,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 521/3636 [15:00<1:29:16,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 522/3636 [15:00<1:29:18,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 522/3636 [15:01<1:29:18,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 523/3636 [15:01<1:29:16,  1.72s/it, training_loss=0.307]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  14%|█▍        | 523/3636 [15:03<1:29:16,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 524/3636 [15:03<1:29:13,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 524/3636 [15:05<1:29:13,  1.72s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 525/3636 [15:05<1:29:10,  1.72s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 525/3636 [15:07<1:29:10,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 526/3636 [15:07<1:29:06,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 526/3636 [15:08<1:29:06,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 527/3636 [15:08<1:29:03,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 527/3636 [15:10<1:29:03,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 528/3636 [15:10<1:29:00,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 528/3636 [15:12<1:29:00,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 529/3636 [15:12<1:28:58,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 529/3636 [15:13<1:28:58,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 530/3636 [15:13<1:28:55,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 530/3636 [15:15<1:28:55,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 531/3636 [15:15<1:28:52,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 531/3636 [15:17<1:28:52,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 532/3636 [15:17<1:28:49,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 532/3636 [15:19<1:28:49,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 533/3636 [15:19<1:28:50,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 533/3636 [15:20<1:28:50,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 534/3636 [15:20<1:28:50,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 534/3636 [15:22<1:28:50,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 535/3636 [15:22<1:28:47,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 535/3636 [15:24<1:28:47,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 536/3636 [15:24<1:28:46,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 536/3636 [15:25<1:28:46,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 537/3636 [15:25<1:28:43,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 537/3636 [15:27<1:28:43,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 538/3636 [15:27<1:28:40,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 538/3636 [15:29<1:28:40,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 539/3636 [15:29<1:28:39,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 539/3636 [15:31<1:28:39,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 540/3636 [15:31<1:28:35,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 540/3636 [15:32<1:28:35,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 541/3636 [15:32<1:28:33,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 541/3636 [15:34<1:28:33,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 542/3636 [15:34<1:28:33,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 542/3636 [15:36<1:28:33,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 543/3636 [15:36<1:28:30,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 543/3636 [15:37<1:28:30,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 544/3636 [15:37<1:28:28,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 544/3636 [15:39<1:28:28,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 545/3636 [15:39<1:28:30,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 545/3636 [15:41<1:28:30,  1.72s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 546/3636 [15:41<1:28:25,  1.72s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 546/3636 [15:43<1:28:25,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 547/3636 [15:43<1:28:23,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 547/3636 [15:44<1:28:23,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 548/3636 [15:44<1:28:23,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 548/3636 [15:46<1:28:23,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 549/3636 [15:46<1:28:21,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 549/3636 [15:48<1:28:21,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 550/3636 [15:48<1:28:19,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 550/3636 [15:49<1:28:19,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 551/3636 [15:49<1:28:16,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 551/3636 [15:51<1:28:16,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 552/3636 [15:51<1:28:14,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 552/3636 [15:53<1:28:14,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 553/3636 [15:53<1:28:10,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 553/3636 [15:55<1:28:10,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 554/3636 [15:55<1:28:07,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 554/3636 [15:56<1:28:07,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 555/3636 [15:56<1:28:05,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 555/3636 [15:58<1:28:05,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 556/3636 [15:58<1:28:05,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 556/3636 [16:00<1:28:05,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 557/3636 [16:00<1:28:04,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 557/3636 [16:01<1:28:04,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 558/3636 [16:01<1:28:04,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 558/3636 [16:03<1:28:04,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 559/3636 [16:03<1:28:05,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 559/3636 [16:05<1:28:05,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 560/3636 [16:05<1:28:03,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 560/3636 [16:07<1:28:03,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 561/3636 [16:07<1:27:59,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 561/3636 [16:08<1:27:59,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 562/3636 [16:08<1:27:58,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 562/3636 [16:10<1:27:58,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 563/3636 [16:10<1:27:56,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 563/3636 [16:12<1:27:56,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 564/3636 [16:12<1:27:55,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 564/3636 [16:13<1:27:55,  1.72s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 565/3636 [16:13<1:27:53,  1.72s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 565/3636 [16:15<1:27:53,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 566/3636 [16:15<1:27:50,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 566/3636 [16:17<1:27:50,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 567/3636 [16:17<1:27:47,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 567/3636 [16:19<1:27:47,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 568/3636 [16:19<1:27:43,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 568/3636 [16:20<1:27:43,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 569/3636 [16:20<1:27:40,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 569/3636 [16:22<1:27:40,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 570/3636 [16:22<1:27:38,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 570/3636 [16:24<1:27:38,  1.72s/it, training_loss=0.340]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  16%|█▌        | 571/3636 [16:24<1:27:38,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 571/3636 [16:26<1:27:38,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 572/3636 [16:26<1:27:39,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 572/3636 [16:27<1:27:39,  1.72s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 573/3636 [16:27<1:27:38,  1.72s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 573/3636 [16:29<1:27:38,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 574/3636 [16:29<1:27:38,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 574/3636 [16:31<1:27:38,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 575/3636 [16:31<1:27:37,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 575/3636 [16:32<1:27:37,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 576/3636 [16:32<1:27:38,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 576/3636 [16:34<1:27:38,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 577/3636 [16:34<1:27:35,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 577/3636 [16:36<1:27:35,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 578/3636 [16:36<1:27:33,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 578/3636 [16:38<1:27:33,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 579/3636 [16:38<1:27:32,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 579/3636 [16:39<1:27:32,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 580/3636 [16:39<1:27:31,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 580/3636 [16:41<1:27:31,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 581/3636 [16:41<1:27:29,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 581/3636 [16:43<1:27:29,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 582/3636 [16:43<1:27:29,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 582/3636 [16:44<1:27:29,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 583/3636 [16:44<1:27:27,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 583/3636 [16:46<1:27:27,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 584/3636 [16:46<1:27:24,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 584/3636 [16:48<1:27:24,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 585/3636 [16:48<1:27:23,  1.72s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 585/3636 [16:50<1:27:23,  1.72s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 586/3636 [16:50<1:27:19,  1.72s/it, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 586/3636 [16:51<1:27:19,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 587/3636 [16:51<1:27:19,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 587/3636 [16:53<1:27:19,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 588/3636 [16:53<1:27:16,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 588/3636 [16:55<1:27:16,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 589/3636 [16:55<1:27:16,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 589/3636 [16:56<1:27:16,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 590/3636 [16:56<1:27:14,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 590/3636 [16:58<1:27:14,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 591/3636 [16:58<1:27:12,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 591/3636 [17:00<1:27:12,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 592/3636 [17:00<1:27:10,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 592/3636 [17:02<1:27:10,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 593/3636 [17:02<1:27:08,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 593/3636 [17:03<1:27:08,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 594/3636 [17:03<1:27:09,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 594/3636 [17:05<1:27:09,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 595/3636 [17:05<1:27:06,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 595/3636 [17:07<1:27:06,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 596/3636 [17:07<1:27:06,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 596/3636 [17:08<1:27:06,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 597/3636 [17:08<1:27:03,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 597/3636 [17:10<1:27:03,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 598/3636 [17:10<1:27:01,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 598/3636 [17:12<1:27:01,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 599/3636 [17:12<1:27:00,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 599/3636 [17:14<1:27:00,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 600/3636 [17:14<1:27:00,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 600/3636 [17:15<1:27:00,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 601/3636 [17:15<1:26:59,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 601/3636 [17:17<1:26:59,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 602/3636 [17:17<1:26:59,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 602/3636 [17:19<1:26:59,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 603/3636 [17:19<1:26:55,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 603/3636 [17:21<1:26:55,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 604/3636 [17:21<1:26:55,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 604/3636 [17:22<1:26:55,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 605/3636 [17:22<1:26:53,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 605/3636 [17:24<1:26:53,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 606/3636 [17:24<1:26:50,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 606/3636 [17:26<1:26:50,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 607/3636 [17:26<1:26:49,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 607/3636 [17:27<1:26:49,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 608/3636 [17:27<1:26:48,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 608/3636 [17:29<1:26:48,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 609/3636 [17:29<1:26:48,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 609/3636 [17:31<1:26:48,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 610/3636 [17:31<1:26:47,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 610/3636 [17:33<1:26:47,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 611/3636 [17:33<1:26:47,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 611/3636 [17:34<1:26:47,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 612/3636 [17:34<1:26:44,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 612/3636 [17:36<1:26:44,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 613/3636 [17:36<1:26:44,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 613/3636 [17:38<1:26:44,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 614/3636 [17:38<1:26:41,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 614/3636 [17:39<1:26:41,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 615/3636 [17:39<1:26:41,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 615/3636 [17:41<1:26:41,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 616/3636 [17:41<1:26:40,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 616/3636 [17:43<1:26:40,  1.72s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 617/3636 [17:43<1:26:36,  1.72s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 617/3636 [17:45<1:26:36,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 618/3636 [17:45<1:26:36,  1.72s/it, training_loss=0.286]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  17%|█▋        | 618/3636 [17:46<1:26:36,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 619/3636 [17:46<1:26:34,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 619/3636 [17:48<1:26:34,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 620/3636 [17:48<1:26:33,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 620/3636 [17:50<1:26:33,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 621/3636 [17:50<1:26:31,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 621/3636 [17:51<1:26:31,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 622/3636 [17:51<1:26:31,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 622/3636 [17:53<1:26:31,  1.72s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 623/3636 [17:53<1:26:29,  1.72s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 623/3636 [17:55<1:26:29,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 624/3636 [17:55<1:26:25,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 624/3636 [17:57<1:26:25,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 625/3636 [17:57<1:26:25,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 625/3636 [17:58<1:26:25,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 626/3636 [17:58<1:26:21,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 626/3636 [18:00<1:26:21,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 627/3636 [18:00<1:26:19,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 627/3636 [18:02<1:26:19,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 628/3636 [18:02<1:26:18,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 628/3636 [18:04<1:26:18,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 629/3636 [18:04<1:26:17,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 629/3636 [18:05<1:26:17,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 630/3636 [18:05<1:26:16,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 630/3636 [18:07<1:26:16,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 631/3636 [18:07<1:26:12,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 631/3636 [18:09<1:26:12,  1.72s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 632/3636 [18:09<1:26:13,  1.72s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 632/3636 [18:10<1:26:13,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 633/3636 [18:10<1:26:14,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 633/3636 [18:12<1:26:14,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 634/3636 [18:12<1:26:14,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 634/3636 [18:14<1:26:14,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 635/3636 [18:14<1:26:12,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 635/3636 [18:16<1:26:12,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 636/3636 [18:16<1:26:09,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 636/3636 [18:17<1:26:09,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 637/3636 [18:17<1:26:06,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 637/3636 [18:19<1:26:06,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 638/3636 [18:19<1:26:04,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 638/3636 [18:21<1:26:04,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 639/3636 [18:21<1:26:00,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 639/3636 [18:22<1:26:00,  1.72s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 640/3636 [18:22<1:25:59,  1.72s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 640/3636 [18:24<1:25:59,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 641/3636 [18:24<1:25:56,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 641/3636 [18:26<1:25:56,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 642/3636 [18:26<1:25:54,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 642/3636 [18:28<1:25:54,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 643/3636 [18:28<1:25:52,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 643/3636 [18:29<1:25:52,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 644/3636 [18:29<1:25:51,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 644/3636 [18:31<1:25:51,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 645/3636 [18:31<1:25:49,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 645/3636 [18:33<1:25:49,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 646/3636 [18:33<1:25:47,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 646/3636 [18:35<1:25:47,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 647/3636 [18:35<1:25:45,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 647/3636 [18:36<1:25:45,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 648/3636 [18:36<1:25:43,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 648/3636 [18:38<1:25:43,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 649/3636 [18:38<1:25:41,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 649/3636 [18:40<1:25:41,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 650/3636 [18:40<1:25:39,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 650/3636 [18:41<1:25:39,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 651/3636 [18:41<1:25:37,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 651/3636 [18:43<1:25:37,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 652/3636 [18:43<1:25:33,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 652/3636 [18:45<1:25:33,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 653/3636 [18:45<1:25:30,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 653/3636 [18:47<1:25:30,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 654/3636 [18:47<1:25:45,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 654/3636 [18:48<1:25:45,  1.73s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 655/3636 [18:48<1:25:38,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 655/3636 [18:50<1:25:38,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 656/3636 [18:50<1:25:35,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 656/3636 [18:52<1:25:35,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 657/3636 [18:52<1:25:28,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 657/3636 [18:53<1:25:28,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 658/3636 [18:53<1:25:24,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 658/3636 [18:55<1:25:24,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 659/3636 [18:55<1:25:20,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 659/3636 [18:57<1:25:20,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 660/3636 [18:57<1:25:16,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 660/3636 [18:59<1:25:16,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 661/3636 [18:59<1:25:18,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 661/3636 [19:00<1:25:18,  1.72s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 662/3636 [19:00<1:25:19,  1.72s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 662/3636 [19:02<1:25:19,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 663/3636 [19:02<1:25:13,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 663/3636 [19:04<1:25:13,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 664/3636 [19:04<1:25:08,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 664/3636 [19:06<1:25:08,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 665/3636 [19:06<1:25:05,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 665/3636 [19:07<1:25:05,  1.72s/it, training_loss=0.283]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  18%|█▊        | 666/3636 [19:07<1:25:04,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 666/3636 [19:09<1:25:04,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 667/3636 [19:09<1:25:01,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 667/3636 [19:11<1:25:01,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 668/3636 [19:11<1:25:00,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 668/3636 [19:12<1:25:00,  1.72s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 669/3636 [19:12<1:25:00,  1.72s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 669/3636 [19:14<1:25:00,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 670/3636 [19:14<1:24:57,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 670/3636 [19:16<1:24:57,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 671/3636 [19:16<1:24:53,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 671/3636 [19:18<1:24:53,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 672/3636 [19:18<1:24:50,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 672/3636 [19:19<1:24:50,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 673/3636 [19:19<1:24:48,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 673/3636 [19:21<1:24:48,  1.72s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 674/3636 [19:21<1:24:45,  1.72s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 674/3636 [19:23<1:24:45,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 675/3636 [19:23<1:24:41,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 675/3636 [19:24<1:24:41,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 676/3636 [19:24<1:24:41,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 676/3636 [19:26<1:24:41,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 677/3636 [19:26<1:24:38,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 677/3636 [19:28<1:24:38,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 678/3636 [19:28<1:24:38,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 678/3636 [19:30<1:24:38,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 679/3636 [19:30<1:24:36,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 679/3636 [19:31<1:24:36,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 680/3636 [19:31<1:24:33,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 680/3636 [19:33<1:24:33,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 681/3636 [19:33<1:24:29,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 681/3636 [19:35<1:24:29,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 682/3636 [19:35<1:24:28,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 682/3636 [19:36<1:24:28,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 683/3636 [19:36<1:24:27,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 683/3636 [19:38<1:24:27,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 684/3636 [19:38<1:24:27,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 684/3636 [19:40<1:24:27,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 685/3636 [19:40<1:24:26,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 685/3636 [19:42<1:24:26,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 686/3636 [19:42<1:24:29,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 686/3636 [19:43<1:24:29,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 687/3636 [19:43<1:24:26,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 687/3636 [19:45<1:24:26,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 688/3636 [19:45<1:24:23,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 688/3636 [19:47<1:24:23,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 689/3636 [19:47<1:24:19,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 689/3636 [19:48<1:24:19,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 690/3636 [19:48<1:24:16,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 690/3636 [19:50<1:24:16,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 691/3636 [19:50<1:24:14,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 691/3636 [19:52<1:24:14,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 692/3636 [19:52<1:24:12,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 692/3636 [19:54<1:24:12,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 693/3636 [19:54<1:24:08,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 693/3636 [19:55<1:24:08,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 694/3636 [19:55<1:24:07,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 694/3636 [19:57<1:24:07,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 695/3636 [19:57<1:24:04,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 695/3636 [19:59<1:24:04,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 696/3636 [19:59<1:24:03,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 696/3636 [20:00<1:24:03,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 697/3636 [20:00<1:24:01,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 697/3636 [20:02<1:24:01,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 698/3636 [20:02<1:23:58,  1.72s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 698/3636 [20:04<1:23:58,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 699/3636 [20:04<1:23:57,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 699/3636 [20:06<1:23:57,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 700/3636 [20:06<1:23:56,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 700/3636 [20:07<1:23:56,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 701/3636 [20:07<1:23:54,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 701/3636 [20:09<1:23:54,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 702/3636 [20:09<1:23:54,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 702/3636 [20:11<1:23:54,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 703/3636 [20:11<1:23:51,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 703/3636 [20:12<1:23:51,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 704/3636 [20:12<1:23:49,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 704/3636 [20:14<1:23:49,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 705/3636 [20:14<1:23:48,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 705/3636 [20:16<1:23:48,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 706/3636 [20:16<1:23:50,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 706/3636 [20:18<1:23:50,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 707/3636 [20:18<1:23:50,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 707/3636 [20:19<1:23:50,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 708/3636 [20:19<1:23:46,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 708/3636 [20:21<1:23:46,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 709/3636 [20:21<1:23:45,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 709/3636 [20:23<1:23:45,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 710/3636 [20:23<1:23:44,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 710/3636 [20:24<1:23:44,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 711/3636 [20:24<1:23:45,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 711/3636 [20:26<1:23:45,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 712/3636 [20:26<1:23:42,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 712/3636 [20:28<1:23:42,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 713/3636 [20:28<1:23:40,  1.72s/it, training_loss=0.253]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  20%|█▉        | 713/3636 [20:30<1:23:40,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 714/3636 [20:30<1:23:37,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 714/3636 [20:31<1:23:37,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 715/3636 [20:31<1:23:40,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 715/3636 [20:33<1:23:40,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 716/3636 [20:33<1:23:36,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 716/3636 [20:35<1:23:36,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 717/3636 [20:35<1:23:36,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 717/3636 [20:37<1:23:36,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 718/3636 [20:37<1:23:34,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 718/3636 [20:38<1:23:34,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 719/3636 [20:38<1:23:31,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 719/3636 [20:40<1:23:31,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 720/3636 [20:40<1:23:30,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 720/3636 [20:42<1:23:30,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 721/3636 [20:42<1:23:28,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 721/3636 [20:43<1:23:28,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 722/3636 [20:43<1:23:28,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 722/3636 [20:45<1:23:28,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 723/3636 [20:45<1:23:27,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 723/3636 [20:47<1:23:27,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 724/3636 [20:47<1:23:26,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 724/3636 [20:49<1:23:26,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 725/3636 [20:49<1:23:24,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 725/3636 [20:50<1:23:24,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 726/3636 [20:50<1:23:23,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 726/3636 [20:52<1:23:23,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 727/3636 [20:52<1:23:23,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 727/3636 [20:54<1:23:23,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  20%|██        | 728/3636 [20:54<1:23:23,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  20%|██        | 728/3636 [20:55<1:23:23,  1.72s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  20%|██        | 729/3636 [20:55<1:23:21,  1.72s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  20%|██        | 729/3636 [20:57<1:23:21,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  20%|██        | 730/3636 [20:57<1:23:19,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  20%|██        | 730/3636 [20:59<1:23:19,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  20%|██        | 731/3636 [20:59<1:23:18,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  20%|██        | 731/3636 [21:01<1:23:18,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  20%|██        | 732/3636 [21:01<1:23:17,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  20%|██        | 732/3636 [21:02<1:23:17,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  20%|██        | 733/3636 [21:02<1:23:15,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  20%|██        | 733/3636 [21:04<1:23:15,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  20%|██        | 734/3636 [21:04<1:23:13,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  20%|██        | 734/3636 [21:06<1:23:13,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  20%|██        | 735/3636 [21:06<1:23:12,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  20%|██        | 735/3636 [21:07<1:23:12,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  20%|██        | 736/3636 [21:07<1:23:11,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  20%|██        | 736/3636 [21:09<1:23:11,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  20%|██        | 737/3636 [21:09<1:23:09,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  20%|██        | 737/3636 [21:11<1:23:09,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  20%|██        | 738/3636 [21:11<1:23:08,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  20%|██        | 738/3636 [21:13<1:23:08,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  20%|██        | 739/3636 [21:13<1:23:10,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  20%|██        | 739/3636 [21:14<1:23:10,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  20%|██        | 740/3636 [21:14<1:23:06,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  20%|██        | 740/3636 [21:16<1:23:06,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  20%|██        | 741/3636 [21:16<1:23:04,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  20%|██        | 741/3636 [21:18<1:23:04,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  20%|██        | 742/3636 [21:18<1:23:00,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  20%|██        | 742/3636 [21:20<1:23:00,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  20%|██        | 743/3636 [21:20<1:22:59,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  20%|██        | 743/3636 [21:21<1:22:59,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  20%|██        | 744/3636 [21:21<1:22:57,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  20%|██        | 744/3636 [21:23<1:22:57,  1.72s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  20%|██        | 745/3636 [21:23<1:22:55,  1.72s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  20%|██        | 745/3636 [21:25<1:22:55,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  21%|██        | 746/3636 [21:25<1:22:55,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  21%|██        | 746/3636 [21:26<1:22:55,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  21%|██        | 747/3636 [21:26<1:22:54,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  21%|██        | 747/3636 [21:28<1:22:54,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  21%|██        | 748/3636 [21:28<1:22:55,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  21%|██        | 748/3636 [21:30<1:22:55,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  21%|██        | 749/3636 [21:30<1:22:53,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  21%|██        | 749/3636 [21:32<1:22:53,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  21%|██        | 750/3636 [21:32<1:22:54,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  21%|██        | 750/3636 [21:33<1:22:54,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  21%|██        | 751/3636 [21:33<1:22:52,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  21%|██        | 751/3636 [21:35<1:22:52,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  21%|██        | 752/3636 [21:35<1:22:49,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  21%|██        | 752/3636 [21:37<1:22:49,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  21%|██        | 753/3636 [21:37<1:22:45,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  21%|██        | 753/3636 [21:38<1:22:45,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  21%|██        | 754/3636 [21:38<1:22:44,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  21%|██        | 754/3636 [21:40<1:22:44,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  21%|██        | 755/3636 [21:40<1:22:42,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  21%|██        | 755/3636 [21:42<1:22:42,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  21%|██        | 756/3636 [21:42<1:22:40,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  21%|██        | 756/3636 [21:44<1:22:40,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  21%|██        | 757/3636 [21:44<1:22:39,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  21%|██        | 757/3636 [21:45<1:22:39,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  21%|██        | 758/3636 [21:45<1:22:38,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  21%|██        | 758/3636 [21:47<1:22:38,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  21%|██        | 759/3636 [21:47<1:22:37,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  21%|██        | 759/3636 [21:49<1:22:37,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  21%|██        | 760/3636 [21:49<1:22:34,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  21%|██        | 760/3636 [21:51<1:22:34,  1.72s/it, training_loss=0.329]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  21%|██        | 761/3636 [21:51<1:22:32,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  21%|██        | 761/3636 [21:52<1:22:32,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  21%|██        | 762/3636 [21:52<1:22:31,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  21%|██        | 762/3636 [21:54<1:22:31,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  21%|██        | 763/3636 [21:54<1:22:32,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  21%|██        | 763/3636 [21:56<1:22:32,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  21%|██        | 764/3636 [21:56<1:22:29,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  21%|██        | 764/3636 [21:57<1:22:29,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  21%|██        | 765/3636 [21:57<1:22:27,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  21%|██        | 765/3636 [21:59<1:22:27,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  21%|██        | 766/3636 [21:59<1:22:26,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  21%|██        | 766/3636 [22:01<1:22:26,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  21%|██        | 767/3636 [22:01<1:22:25,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  21%|██        | 767/3636 [22:03<1:22:25,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  21%|██        | 768/3636 [22:03<1:22:23,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  21%|██        | 768/3636 [22:04<1:22:23,  1.72s/it, training_loss=0.373]\u001b[A\n",
      "Epoch 1:  21%|██        | 769/3636 [22:04<1:22:21,  1.72s/it, training_loss=0.373]\u001b[A\n",
      "Epoch 1:  21%|██        | 769/3636 [22:06<1:22:21,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  21%|██        | 770/3636 [22:06<1:22:18,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  21%|██        | 770/3636 [22:08<1:22:18,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  21%|██        | 771/3636 [22:08<1:22:15,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  21%|██        | 771/3636 [22:09<1:22:15,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  21%|██        | 772/3636 [22:09<1:22:15,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  21%|██        | 772/3636 [22:11<1:22:15,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 773/3636 [22:11<1:22:15,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 773/3636 [22:13<1:22:15,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 774/3636 [22:13<1:22:13,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 774/3636 [22:15<1:22:13,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 775/3636 [22:15<1:22:14,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 775/3636 [22:16<1:22:14,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 776/3636 [22:16<1:22:12,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 776/3636 [22:18<1:22:12,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 777/3636 [22:18<1:22:10,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 777/3636 [22:20<1:22:10,  1.72s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 778/3636 [22:20<1:22:08,  1.72s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 778/3636 [22:22<1:22:08,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 779/3636 [22:22<1:22:08,  1.73s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 779/3636 [22:23<1:22:08,  1.73s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 780/3636 [22:23<1:22:05,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 780/3636 [22:25<1:22:05,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 781/3636 [22:25<1:22:03,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 781/3636 [22:27<1:22:03,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 782/3636 [22:27<1:22:04,  1.73s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 782/3636 [22:28<1:22:04,  1.73s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 783/3636 [22:28<1:22:02,  1.73s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 783/3636 [22:30<1:22:02,  1.73s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 784/3636 [22:30<1:22:00,  1.73s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 784/3636 [22:32<1:22:00,  1.73s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 785/3636 [22:32<1:22:01,  1.73s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 785/3636 [22:34<1:22:01,  1.73s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 786/3636 [22:34<1:21:58,  1.73s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 786/3636 [22:35<1:21:58,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 787/3636 [22:35<1:21:53,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 787/3636 [22:37<1:21:53,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 788/3636 [22:37<1:21:51,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 788/3636 [22:39<1:21:51,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 789/3636 [22:39<1:21:50,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 789/3636 [22:41<1:21:50,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 790/3636 [22:41<1:21:49,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 790/3636 [22:42<1:21:49,  1.73s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 791/3636 [22:42<1:21:50,  1.73s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 791/3636 [22:44<1:21:50,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 792/3636 [22:44<1:21:47,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 792/3636 [22:46<1:21:47,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 793/3636 [22:46<1:21:43,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 793/3636 [22:47<1:21:43,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 794/3636 [22:47<1:21:39,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 794/3636 [22:49<1:21:39,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 795/3636 [22:49<1:21:39,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 795/3636 [22:51<1:21:39,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 796/3636 [22:51<1:21:37,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 796/3636 [22:53<1:21:37,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 797/3636 [22:53<1:21:35,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 797/3636 [22:54<1:21:35,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 798/3636 [22:54<1:21:34,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 798/3636 [22:56<1:21:34,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 799/3636 [22:56<1:21:31,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 799/3636 [22:58<1:21:31,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 800/3636 [22:58<1:21:28,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 800/3636 [23:00<1:21:28,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 801/3636 [23:00<1:21:27,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 801/3636 [23:01<1:21:27,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 802/3636 [23:01<1:21:25,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 802/3636 [23:03<1:21:25,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 803/3636 [23:03<1:21:23,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 803/3636 [23:05<1:21:23,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 804/3636 [23:05<1:21:22,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 804/3636 [23:06<1:21:22,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 805/3636 [23:06<1:21:20,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 805/3636 [23:08<1:21:20,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 806/3636 [23:08<1:21:16,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 806/3636 [23:10<1:21:16,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 807/3636 [23:10<1:21:15,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 807/3636 [23:12<1:21:15,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 808/3636 [23:12<1:21:14,  1.72s/it, training_loss=0.283]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  22%|██▏       | 808/3636 [23:13<1:21:14,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 809/3636 [23:13<1:21:10,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 809/3636 [23:15<1:21:10,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 810/3636 [23:15<1:21:07,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 810/3636 [23:17<1:21:07,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 811/3636 [23:17<1:21:04,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 811/3636 [23:18<1:21:04,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 812/3636 [23:18<1:21:02,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 812/3636 [23:20<1:21:02,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 813/3636 [23:20<1:20:59,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 813/3636 [23:22<1:20:59,  1.72s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 814/3636 [23:22<1:20:57,  1.72s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 814/3636 [23:24<1:20:57,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 815/3636 [23:24<1:20:53,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 815/3636 [23:25<1:20:53,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 816/3636 [23:25<1:20:53,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 816/3636 [23:27<1:20:53,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 817/3636 [23:27<1:20:51,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 817/3636 [23:29<1:20:51,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 818/3636 [23:29<1:20:48,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 818/3636 [23:30<1:20:48,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 819/3636 [23:30<1:20:44,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 819/3636 [23:32<1:20:44,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 820/3636 [23:32<1:20:42,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 820/3636 [23:34<1:20:42,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 821/3636 [23:34<1:20:40,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 821/3636 [23:36<1:20:40,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 822/3636 [23:36<1:20:40,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 822/3636 [23:37<1:20:40,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 823/3636 [23:37<1:20:37,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 823/3636 [23:39<1:20:37,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 824/3636 [23:39<1:20:34,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 824/3636 [23:41<1:20:34,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 825/3636 [23:41<1:20:32,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 825/3636 [23:43<1:20:32,  1.72s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 826/3636 [23:43<1:20:29,  1.72s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 826/3636 [23:44<1:20:29,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 827/3636 [23:44<1:20:27,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 827/3636 [23:46<1:20:27,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 828/3636 [23:46<1:20:25,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 828/3636 [23:48<1:20:25,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 829/3636 [23:48<1:20:22,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 829/3636 [23:49<1:20:22,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 830/3636 [23:49<1:20:19,  1.72s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 830/3636 [23:51<1:20:19,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 831/3636 [23:51<1:20:19,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 831/3636 [23:53<1:20:19,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 832/3636 [23:53<1:20:18,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 832/3636 [23:55<1:20:18,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 833/3636 [23:55<1:20:15,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 833/3636 [23:56<1:20:15,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 834/3636 [23:56<1:20:15,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 834/3636 [23:58<1:20:15,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 835/3636 [23:58<1:20:17,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 835/3636 [24:00<1:20:17,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 836/3636 [24:00<1:20:12,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 836/3636 [24:01<1:20:12,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 837/3636 [24:01<1:20:18,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 837/3636 [24:03<1:20:18,  1.72s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 838/3636 [24:03<1:20:11,  1.72s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 838/3636 [24:05<1:20:11,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 839/3636 [24:05<1:20:04,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 839/3636 [24:07<1:20:04,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 840/3636 [24:07<1:20:03,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 840/3636 [24:08<1:20:03,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 841/3636 [24:08<1:20:01,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 841/3636 [24:10<1:20:01,  1.72s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 842/3636 [24:10<1:19:58,  1.72s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 842/3636 [24:12<1:19:58,  1.72s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 843/3636 [24:12<1:19:55,  1.72s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 843/3636 [24:13<1:19:55,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 844/3636 [24:13<1:19:52,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 844/3636 [24:15<1:19:52,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 845/3636 [24:15<1:19:50,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 845/3636 [24:17<1:19:50,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 846/3636 [24:17<1:19:48,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 846/3636 [24:19<1:19:48,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 847/3636 [24:19<1:19:45,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 847/3636 [24:20<1:19:45,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 848/3636 [24:20<1:19:44,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 848/3636 [24:22<1:19:44,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 849/3636 [24:22<1:19:41,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 849/3636 [24:24<1:19:41,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 850/3636 [24:24<1:19:39,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 850/3636 [24:25<1:19:39,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 851/3636 [24:25<1:19:39,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 851/3636 [24:27<1:19:39,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 852/3636 [24:27<1:19:40,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 852/3636 [24:29<1:19:40,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 853/3636 [24:29<1:19:39,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 853/3636 [24:31<1:19:39,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 854/3636 [24:31<1:19:36,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 854/3636 [24:32<1:19:36,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 855/3636 [24:32<1:19:34,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 855/3636 [24:34<1:19:34,  1.72s/it, training_loss=0.322]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  24%|██▎       | 856/3636 [24:34<1:19:31,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 856/3636 [24:36<1:19:31,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 857/3636 [24:36<1:19:30,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 857/3636 [24:37<1:19:30,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 858/3636 [24:37<1:19:28,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 858/3636 [24:39<1:19:28,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 859/3636 [24:39<1:19:26,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 859/3636 [24:41<1:19:26,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 860/3636 [24:41<1:19:28,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 860/3636 [24:43<1:19:28,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 861/3636 [24:43<1:19:26,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 861/3636 [24:44<1:19:26,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 862/3636 [24:44<1:19:24,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 862/3636 [24:46<1:19:24,  1.72s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 863/3636 [24:46<1:19:21,  1.72s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 863/3636 [24:48<1:19:21,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 864/3636 [24:48<1:19:20,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 864/3636 [24:50<1:19:20,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 865/3636 [24:50<1:19:20,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 865/3636 [24:51<1:19:20,  1.72s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 866/3636 [24:51<1:19:18,  1.72s/it, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 866/3636 [24:53<1:19:18,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 867/3636 [24:53<1:19:15,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 867/3636 [24:55<1:19:15,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 868/3636 [24:55<1:19:14,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 868/3636 [24:56<1:19:14,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 869/3636 [24:56<1:19:14,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 869/3636 [24:58<1:19:14,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 870/3636 [24:58<1:19:11,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 870/3636 [25:00<1:19:11,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 871/3636 [25:00<1:19:10,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 871/3636 [25:02<1:19:10,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 872/3636 [25:02<1:19:08,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 872/3636 [25:03<1:19:08,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 873/3636 [25:03<1:19:06,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 873/3636 [25:05<1:19:06,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 874/3636 [25:05<1:19:04,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 874/3636 [25:07<1:19:04,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 875/3636 [25:07<1:19:04,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 875/3636 [25:08<1:19:04,  1.72s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 876/3636 [25:08<1:19:03,  1.72s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 876/3636 [25:10<1:19:03,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 877/3636 [25:10<1:19:00,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 877/3636 [25:12<1:19:00,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 878/3636 [25:12<1:18:58,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 878/3636 [25:14<1:18:58,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 879/3636 [25:14<1:18:57,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 879/3636 [25:15<1:18:57,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 880/3636 [25:15<1:18:56,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 880/3636 [25:17<1:18:56,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 881/3636 [25:17<1:18:54,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 881/3636 [25:19<1:18:54,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 882/3636 [25:19<1:18:55,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 882/3636 [25:20<1:18:55,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 883/3636 [25:20<1:18:53,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 883/3636 [25:22<1:18:53,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 884/3636 [25:22<1:18:49,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 884/3636 [25:24<1:18:49,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 885/3636 [25:24<1:18:47,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 885/3636 [25:26<1:18:47,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 886/3636 [25:26<1:18:44,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 886/3636 [25:27<1:18:44,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 887/3636 [25:27<1:18:44,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 887/3636 [25:29<1:18:44,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 888/3636 [25:29<1:18:43,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 888/3636 [25:31<1:18:43,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 889/3636 [25:31<1:18:41,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 889/3636 [25:32<1:18:41,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 890/3636 [25:32<1:18:39,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 890/3636 [25:34<1:18:39,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 891/3636 [25:34<1:18:37,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 891/3636 [25:36<1:18:37,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 892/3636 [25:36<1:18:36,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 892/3636 [25:38<1:18:36,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 893/3636 [25:38<1:18:35,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 893/3636 [25:39<1:18:35,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 894/3636 [25:39<1:18:32,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 894/3636 [25:41<1:18:32,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 895/3636 [25:41<1:18:32,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 895/3636 [25:43<1:18:32,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 896/3636 [25:43<1:18:33,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 896/3636 [25:45<1:18:33,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 897/3636 [25:45<1:18:31,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 897/3636 [25:46<1:18:31,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 898/3636 [25:46<1:18:30,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 898/3636 [25:48<1:18:30,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 899/3636 [25:48<1:18:28,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 899/3636 [25:50<1:18:28,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 900/3636 [25:50<1:18:27,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 900/3636 [25:51<1:18:27,  1.72s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 901/3636 [25:51<1:18:25,  1.72s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 901/3636 [25:53<1:18:25,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 902/3636 [25:53<1:18:23,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 902/3636 [25:55<1:18:23,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 903/3636 [25:55<1:18:21,  1.72s/it, training_loss=0.301]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  25%|██▍       | 903/3636 [25:57<1:18:21,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 904/3636 [25:57<1:18:20,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 904/3636 [25:58<1:18:20,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 905/3636 [25:58<1:18:19,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 905/3636 [26:00<1:18:19,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 906/3636 [26:00<1:18:19,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 906/3636 [26:02<1:18:19,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 907/3636 [26:02<1:18:19,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 907/3636 [26:03<1:18:19,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 908/3636 [26:03<1:18:18,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 908/3636 [26:05<1:18:18,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 909/3636 [26:05<1:18:16,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 909/3636 [26:07<1:18:16,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 910/3636 [26:07<1:18:14,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 910/3636 [26:09<1:18:14,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 911/3636 [26:09<1:18:14,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 911/3636 [26:10<1:18:14,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 912/3636 [26:10<1:18:15,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 912/3636 [26:12<1:18:15,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 913/3636 [26:12<1:18:13,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 913/3636 [26:14<1:18:13,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 914/3636 [26:14<1:18:15,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 914/3636 [26:16<1:18:15,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 915/3636 [26:16<1:18:13,  1.73s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 915/3636 [26:17<1:18:13,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 916/3636 [26:17<1:18:12,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 916/3636 [26:19<1:18:12,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 917/3636 [26:19<1:18:09,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 917/3636 [26:21<1:18:09,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 918/3636 [26:21<1:18:06,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 918/3636 [26:22<1:18:06,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 919/3636 [26:22<1:18:05,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 919/3636 [26:24<1:18:05,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 920/3636 [26:24<1:18:03,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 920/3636 [26:26<1:18:03,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 921/3636 [26:26<1:18:02,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 921/3636 [26:28<1:18:02,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 922/3636 [26:28<1:18:01,  1.73s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 922/3636 [26:29<1:18:01,  1.73s/it, training_loss=0.375]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 923/3636 [26:29<1:18:00,  1.73s/it, training_loss=0.375]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 923/3636 [26:31<1:18:00,  1.73s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 924/3636 [26:31<1:17:59,  1.73s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 924/3636 [26:33<1:17:59,  1.73s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 925/3636 [26:33<1:17:56,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 925/3636 [26:34<1:17:56,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 926/3636 [26:34<1:17:53,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 926/3636 [26:36<1:17:53,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 927/3636 [26:36<1:17:53,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 927/3636 [26:38<1:17:53,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 928/3636 [26:38<1:17:50,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 928/3636 [26:40<1:17:50,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 929/3636 [26:40<1:17:46,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 929/3636 [26:41<1:17:46,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 930/3636 [26:41<1:17:49,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 930/3636 [26:43<1:17:49,  1.73s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 931/3636 [26:43<1:17:51,  1.73s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 931/3636 [26:45<1:17:51,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 932/3636 [26:45<1:17:50,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 932/3636 [26:47<1:17:50,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 933/3636 [26:47<1:17:47,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 933/3636 [26:48<1:17:47,  1.73s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 934/3636 [26:48<1:17:50,  1.73s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 934/3636 [26:50<1:17:50,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 935/3636 [26:50<1:17:46,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 935/3636 [26:52<1:17:46,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 936/3636 [26:52<1:17:44,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 936/3636 [26:53<1:17:44,  1.73s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 937/3636 [26:53<1:17:39,  1.73s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 937/3636 [26:55<1:17:39,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 938/3636 [26:55<1:17:36,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 938/3636 [26:57<1:17:36,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 939/3636 [26:57<1:17:32,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 939/3636 [26:59<1:17:32,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 940/3636 [26:59<1:17:32,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 940/3636 [27:00<1:17:32,  1.73s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 941/3636 [27:00<1:17:31,  1.73s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 941/3636 [27:02<1:17:31,  1.73s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 942/3636 [27:02<1:17:31,  1.73s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 942/3636 [27:04<1:17:31,  1.73s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 943/3636 [27:04<1:17:29,  1.73s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 943/3636 [27:06<1:17:29,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 944/3636 [27:06<1:17:26,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 944/3636 [27:07<1:17:26,  1.73s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 945/3636 [27:07<1:17:26,  1.73s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 945/3636 [27:09<1:17:26,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 946/3636 [27:09<1:17:25,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 946/3636 [27:11<1:17:25,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 947/3636 [27:11<1:17:24,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 947/3636 [27:12<1:17:24,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 948/3636 [27:12<1:17:23,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 948/3636 [27:14<1:17:23,  1.73s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 949/3636 [27:14<1:17:19,  1.73s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 949/3636 [27:16<1:17:19,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 950/3636 [27:16<1:17:17,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 950/3636 [27:18<1:17:17,  1.73s/it, training_loss=0.283]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  26%|██▌       | 951/3636 [27:18<1:17:17,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 951/3636 [27:19<1:17:17,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 952/3636 [27:19<1:17:15,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 952/3636 [27:21<1:17:15,  1.73s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 953/3636 [27:21<1:17:13,  1.73s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 953/3636 [27:23<1:17:13,  1.73s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 954/3636 [27:23<1:17:10,  1.73s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 954/3636 [27:25<1:17:10,  1.73s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 955/3636 [27:25<1:17:08,  1.73s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 955/3636 [27:26<1:17:08,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 956/3636 [27:26<1:17:08,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 956/3636 [27:28<1:17:08,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 957/3636 [27:28<1:17:08,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 957/3636 [27:30<1:17:08,  1.73s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 958/3636 [27:30<1:17:06,  1.73s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 958/3636 [27:31<1:17:06,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 959/3636 [27:31<1:17:06,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 959/3636 [27:33<1:17:06,  1.73s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 960/3636 [27:33<1:17:04,  1.73s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 960/3636 [27:35<1:17:04,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 961/3636 [27:35<1:17:01,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 961/3636 [27:37<1:17:01,  1.73s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 962/3636 [27:37<1:17:01,  1.73s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 962/3636 [27:38<1:17:01,  1.73s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 963/3636 [27:38<1:17:01,  1.73s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 963/3636 [27:40<1:17:01,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 964/3636 [27:40<1:16:58,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 964/3636 [27:42<1:16:58,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 965/3636 [27:42<1:16:56,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 965/3636 [27:44<1:16:56,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 966/3636 [27:44<1:16:53,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 966/3636 [27:45<1:16:53,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 967/3636 [27:45<1:16:52,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 967/3636 [27:47<1:16:52,  1.73s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 968/3636 [27:47<1:16:50,  1.73s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 968/3636 [27:49<1:16:50,  1.73s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 969/3636 [27:49<1:16:49,  1.73s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 969/3636 [27:50<1:16:49,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 970/3636 [27:50<1:16:47,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 970/3636 [27:52<1:16:47,  1.73s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 971/3636 [27:52<1:16:46,  1.73s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 971/3636 [27:54<1:16:46,  1.73s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 972/3636 [27:54<1:16:44,  1.73s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 972/3636 [27:56<1:16:44,  1.73s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 973/3636 [27:56<1:16:44,  1.73s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 973/3636 [27:57<1:16:44,  1.73s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 974/3636 [27:57<1:16:44,  1.73s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 974/3636 [27:59<1:16:44,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 975/3636 [27:59<1:16:41,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 975/3636 [28:01<1:16:41,  1.73s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 976/3636 [28:01<1:16:39,  1.73s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 976/3636 [28:03<1:16:39,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 977/3636 [28:03<1:16:37,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 977/3636 [28:04<1:16:37,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 978/3636 [28:04<1:16:34,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 978/3636 [28:06<1:16:34,  1.73s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 979/3636 [28:06<1:16:33,  1.73s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 979/3636 [28:08<1:16:33,  1.73s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 980/3636 [28:08<1:16:30,  1.73s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 980/3636 [28:10<1:16:30,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 981/3636 [28:10<1:16:29,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 981/3636 [28:11<1:16:29,  1.73s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 982/3636 [28:11<1:16:26,  1.73s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 982/3636 [28:13<1:16:26,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 983/3636 [28:13<1:16:24,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 983/3636 [28:15<1:16:24,  1.73s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 984/3636 [28:15<1:16:22,  1.73s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 984/3636 [28:16<1:16:22,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 985/3636 [28:16<1:16:20,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 985/3636 [28:18<1:16:20,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 986/3636 [28:18<1:16:21,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 986/3636 [28:20<1:16:21,  1.73s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 987/3636 [28:20<1:16:20,  1.73s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 987/3636 [28:22<1:16:20,  1.73s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 988/3636 [28:22<1:16:19,  1.73s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 988/3636 [28:23<1:16:19,  1.73s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 989/3636 [28:23<1:16:17,  1.73s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 989/3636 [28:25<1:16:17,  1.73s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 990/3636 [28:25<1:16:17,  1.73s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 990/3636 [28:27<1:16:17,  1.73s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 991/3636 [28:27<1:16:14,  1.73s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 991/3636 [28:29<1:16:14,  1.73s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 992/3636 [28:29<1:16:13,  1.73s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 992/3636 [28:30<1:16:13,  1.73s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 993/3636 [28:30<1:16:10,  1.73s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 993/3636 [28:32<1:16:10,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 994/3636 [28:32<1:16:08,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 994/3636 [28:34<1:16:08,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 995/3636 [28:34<1:16:05,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 995/3636 [28:35<1:16:05,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 996/3636 [28:35<1:16:03,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 996/3636 [28:37<1:16:03,  1.73s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 997/3636 [28:37<1:16:03,  1.73s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 997/3636 [28:39<1:16:03,  1.73s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 998/3636 [28:39<1:16:02,  1.73s/it, training_loss=0.297]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  27%|██▋       | 998/3636 [28:41<1:16:02,  1.73s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 999/3636 [28:41<1:16:02,  1.73s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 999/3636 [28:42<1:16:02,  1.73s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1000/3636 [28:42<1:16:01,  1.73s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1000/3636 [28:44<1:16:01,  1.73s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1001/3636 [28:44<1:15:59,  1.73s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1001/3636 [28:46<1:15:59,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1002/3636 [28:46<1:15:58,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1002/3636 [28:48<1:15:58,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1003/3636 [28:48<1:15:55,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1003/3636 [28:49<1:15:55,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1004/3636 [28:49<1:15:53,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1004/3636 [28:51<1:15:53,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1005/3636 [28:51<1:15:50,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1005/3636 [28:53<1:15:50,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1006/3636 [28:53<1:15:47,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1006/3636 [28:54<1:15:47,  1.73s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1007/3636 [28:54<1:15:45,  1.73s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1007/3636 [28:56<1:15:45,  1.73s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1008/3636 [28:56<1:15:44,  1.73s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1008/3636 [28:58<1:15:44,  1.73s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1009/3636 [28:58<1:15:41,  1.73s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1009/3636 [29:00<1:15:41,  1.73s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1010/3636 [29:00<1:15:42,  1.73s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1010/3636 [29:01<1:15:42,  1.73s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1011/3636 [29:01<1:15:41,  1.73s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1011/3636 [29:03<1:15:41,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1012/3636 [29:03<1:15:41,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1012/3636 [29:05<1:15:41,  1.73s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1013/3636 [29:05<1:15:35,  1.73s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1013/3636 [29:07<1:15:35,  1.73s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1014/3636 [29:07<1:15:33,  1.73s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1014/3636 [29:08<1:15:33,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1015/3636 [29:08<1:15:32,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1015/3636 [29:10<1:15:32,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1016/3636 [29:10<1:15:31,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1016/3636 [29:12<1:15:31,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1017/3636 [29:12<1:15:29,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1017/3636 [29:13<1:15:29,  1.73s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1018/3636 [29:13<1:15:25,  1.73s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1018/3636 [29:15<1:15:25,  1.73s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1019/3636 [29:15<1:15:24,  1.73s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1019/3636 [29:17<1:15:24,  1.73s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1020/3636 [29:17<1:15:25,  1.73s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1020/3636 [29:19<1:15:25,  1.73s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1021/3636 [29:19<1:15:23,  1.73s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1021/3636 [29:20<1:15:23,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1022/3636 [29:20<1:15:23,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1022/3636 [29:22<1:15:23,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1023/3636 [29:22<1:15:20,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1023/3636 [29:24<1:15:20,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1024/3636 [29:24<1:15:17,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1024/3636 [29:26<1:15:17,  1.73s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1025/3636 [29:26<1:15:15,  1.73s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1025/3636 [29:27<1:15:15,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1026/3636 [29:27<1:15:13,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1026/3636 [29:29<1:15:13,  1.73s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1027/3636 [29:29<1:15:11,  1.73s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1027/3636 [29:31<1:15:11,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1028/3636 [29:31<1:15:10,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1028/3636 [29:33<1:15:10,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1029/3636 [29:33<1:15:10,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1029/3636 [29:34<1:15:10,  1.73s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1030/3636 [29:34<1:15:08,  1.73s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1030/3636 [29:36<1:15:08,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1031/3636 [29:36<1:15:06,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1031/3636 [29:38<1:15:06,  1.73s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1032/3636 [29:38<1:15:04,  1.73s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1032/3636 [29:39<1:15:04,  1.73s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1033/3636 [29:39<1:15:00,  1.73s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1033/3636 [29:41<1:15:00,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1034/3636 [29:41<1:14:58,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1034/3636 [29:43<1:14:58,  1.73s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1035/3636 [29:43<1:14:54,  1.73s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1035/3636 [29:45<1:14:54,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1036/3636 [29:45<1:14:54,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 1036/3636 [29:46<1:14:54,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1037/3636 [29:46<1:14:52,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1037/3636 [29:48<1:14:52,  1.73s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1038/3636 [29:48<1:14:54,  1.73s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1038/3636 [29:50<1:14:54,  1.73s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1039/3636 [29:50<1:14:54,  1.73s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1039/3636 [29:52<1:14:54,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1040/3636 [29:52<1:14:50,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1040/3636 [29:53<1:14:50,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1041/3636 [29:53<1:14:46,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1041/3636 [29:55<1:14:46,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1042/3636 [29:55<1:14:44,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1042/3636 [29:57<1:14:44,  1.73s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1043/3636 [29:57<1:14:44,  1.73s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1043/3636 [29:58<1:14:44,  1.73s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1044/3636 [29:58<1:14:42,  1.73s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1044/3636 [30:00<1:14:42,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 1045/3636 [30:00<1:14:37,  1.73s/it, training_loss=0.318]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  29%|██▊       | 1045/3636 [30:02<1:14:37,  1.73s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1046/3636 [30:02<1:14:35,  1.73s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1046/3636 [30:04<1:14:35,  1.73s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1047/3636 [30:04<1:14:34,  1.73s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1047/3636 [30:05<1:14:34,  1.73s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1048/3636 [30:05<1:14:32,  1.73s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1048/3636 [30:07<1:14:32,  1.73s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1049/3636 [30:07<1:14:29,  1.73s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1049/3636 [30:09<1:14:29,  1.73s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1050/3636 [30:09<1:14:28,  1.73s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1050/3636 [30:11<1:14:28,  1.73s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1051/3636 [30:11<1:14:26,  1.73s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1051/3636 [30:12<1:14:26,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1052/3636 [30:12<1:14:26,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1052/3636 [30:14<1:14:26,  1.73s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1053/3636 [30:14<1:14:24,  1.73s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1053/3636 [30:16<1:14:24,  1.73s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1054/3636 [30:16<1:14:22,  1.73s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1054/3636 [30:17<1:14:22,  1.73s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1055/3636 [30:17<1:14:20,  1.73s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1055/3636 [30:19<1:14:20,  1.73s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1056/3636 [30:19<1:14:18,  1.73s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1056/3636 [30:21<1:14:18,  1.73s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1057/3636 [30:21<1:14:18,  1.73s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1057/3636 [30:23<1:14:18,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1058/3636 [30:23<1:14:15,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1058/3636 [30:24<1:14:15,  1.73s/it, training_loss=0.422]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1059/3636 [30:24<1:14:12,  1.73s/it, training_loss=0.422]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1059/3636 [30:26<1:14:12,  1.73s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1060/3636 [30:26<1:14:09,  1.73s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1060/3636 [30:28<1:14:09,  1.73s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1061/3636 [30:28<1:14:07,  1.73s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1061/3636 [30:30<1:14:07,  1.73s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1062/3636 [30:30<1:14:07,  1.73s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1062/3636 [30:31<1:14:07,  1.73s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1063/3636 [30:31<1:14:05,  1.73s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1063/3636 [30:33<1:14:05,  1.73s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1064/3636 [30:33<1:14:04,  1.73s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1064/3636 [30:35<1:14:04,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1065/3636 [30:35<1:14:02,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1065/3636 [30:36<1:14:02,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1066/3636 [30:36<1:13:59,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1066/3636 [30:38<1:13:59,  1.73s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1067/3636 [30:38<1:13:57,  1.73s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1067/3636 [30:40<1:13:57,  1.73s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1068/3636 [30:40<1:13:56,  1.73s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1068/3636 [30:42<1:13:56,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1069/3636 [30:42<1:13:54,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1069/3636 [30:43<1:13:54,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1070/3636 [30:43<1:13:51,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1070/3636 [30:45<1:13:51,  1.73s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1071/3636 [30:45<1:13:49,  1.73s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1071/3636 [30:47<1:13:49,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1072/3636 [30:47<1:13:46,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 1072/3636 [30:49<1:13:46,  1.73s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1073/3636 [30:49<1:13:43,  1.73s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1073/3636 [30:50<1:13:43,  1.73s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1074/3636 [30:50<1:13:40,  1.73s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1074/3636 [30:52<1:13:40,  1.73s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1075/3636 [30:52<1:13:40,  1.73s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1075/3636 [30:54<1:13:40,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1076/3636 [30:54<1:13:37,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1076/3636 [30:55<1:13:37,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1077/3636 [30:55<1:13:35,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1077/3636 [30:57<1:13:35,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1078/3636 [30:57<1:13:35,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1078/3636 [30:59<1:13:35,  1.73s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1079/3636 [30:59<1:13:30,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1079/3636 [31:01<1:13:30,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1080/3636 [31:01<1:13:27,  1.72s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1080/3636 [31:02<1:13:27,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1081/3636 [31:02<1:13:25,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1081/3636 [31:04<1:13:25,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1082/3636 [31:04<1:13:22,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1082/3636 [31:06<1:13:22,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1083/3636 [31:06<1:13:19,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1083/3636 [31:08<1:13:19,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1084/3636 [31:08<1:13:17,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1084/3636 [31:09<1:13:17,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1085/3636 [31:09<1:13:18,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1085/3636 [31:11<1:13:18,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1086/3636 [31:11<1:13:16,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1086/3636 [31:13<1:13:16,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1087/3636 [31:13<1:13:12,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1087/3636 [31:14<1:13:12,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1088/3636 [31:14<1:13:09,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1088/3636 [31:16<1:13:09,  1.72s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1089/3636 [31:16<1:13:08,  1.72s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1089/3636 [31:18<1:13:08,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1090/3636 [31:18<1:13:07,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 1090/3636 [31:20<1:13:07,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  30%|███       | 1091/3636 [31:20<1:13:02,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  30%|███       | 1091/3636 [31:21<1:13:02,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  30%|███       | 1092/3636 [31:21<1:13:02,  1.72s/it, training_loss=0.278]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  30%|███       | 1092/3636 [31:23<1:13:02,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  30%|███       | 1093/3636 [31:23<1:13:00,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  30%|███       | 1093/3636 [31:25<1:13:00,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  30%|███       | 1094/3636 [31:25<1:12:58,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  30%|███       | 1094/3636 [31:26<1:12:58,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  30%|███       | 1095/3636 [31:26<1:12:55,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  30%|███       | 1095/3636 [31:28<1:12:55,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  30%|███       | 1096/3636 [31:28<1:12:53,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  30%|███       | 1096/3636 [31:30<1:12:53,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  30%|███       | 1097/3636 [31:30<1:12:55,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  30%|███       | 1097/3636 [31:32<1:12:55,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  30%|███       | 1098/3636 [31:32<1:12:53,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  30%|███       | 1098/3636 [31:33<1:12:53,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  30%|███       | 1099/3636 [31:33<1:12:50,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  30%|███       | 1099/3636 [31:35<1:12:50,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  30%|███       | 1100/3636 [31:35<1:12:46,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  30%|███       | 1100/3636 [31:37<1:12:46,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  30%|███       | 1101/3636 [31:37<1:12:43,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  30%|███       | 1101/3636 [31:39<1:12:43,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  30%|███       | 1102/3636 [31:39<1:12:40,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  30%|███       | 1102/3636 [31:40<1:12:40,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  30%|███       | 1103/3636 [31:40<1:12:39,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  30%|███       | 1103/3636 [31:42<1:12:39,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  30%|███       | 1104/3636 [31:42<1:12:38,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  30%|███       | 1104/3636 [31:44<1:12:38,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  30%|███       | 1105/3636 [31:44<1:12:35,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  30%|███       | 1105/3636 [31:45<1:12:35,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  30%|███       | 1106/3636 [31:45<1:12:33,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  30%|███       | 1106/3636 [31:47<1:12:33,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  30%|███       | 1107/3636 [31:47<1:12:30,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  30%|███       | 1107/3636 [31:49<1:12:30,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  30%|███       | 1108/3636 [31:49<1:12:27,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  30%|███       | 1108/3636 [31:51<1:12:27,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  31%|███       | 1109/3636 [31:51<1:12:23,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  31%|███       | 1109/3636 [31:52<1:12:23,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  31%|███       | 1110/3636 [31:52<1:12:20,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  31%|███       | 1110/3636 [31:54<1:12:20,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  31%|███       | 1111/3636 [31:54<1:12:18,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  31%|███       | 1111/3636 [31:56<1:12:18,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  31%|███       | 1112/3636 [31:56<1:12:15,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  31%|███       | 1112/3636 [31:57<1:12:15,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  31%|███       | 1113/3636 [31:57<1:12:12,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  31%|███       | 1113/3636 [31:59<1:12:12,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  31%|███       | 1114/3636 [31:59<1:12:11,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  31%|███       | 1114/3636 [32:01<1:12:11,  1.72s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  31%|███       | 1115/3636 [32:01<1:12:08,  1.72s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  31%|███       | 1115/3636 [32:03<1:12:08,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  31%|███       | 1116/3636 [32:03<1:12:07,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  31%|███       | 1116/3636 [32:04<1:12:07,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  31%|███       | 1117/3636 [32:04<1:12:04,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  31%|███       | 1117/3636 [32:06<1:12:04,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  31%|███       | 1118/3636 [32:06<1:12:03,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  31%|███       | 1118/3636 [32:08<1:12:03,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  31%|███       | 1119/3636 [32:08<1:12:01,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  31%|███       | 1119/3636 [32:09<1:12:01,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  31%|███       | 1120/3636 [32:09<1:11:58,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  31%|███       | 1120/3636 [32:11<1:11:58,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  31%|███       | 1121/3636 [32:11<1:11:56,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  31%|███       | 1121/3636 [32:13<1:11:56,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  31%|███       | 1122/3636 [32:13<1:11:56,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  31%|███       | 1122/3636 [32:15<1:11:56,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  31%|███       | 1123/3636 [32:15<1:11:54,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  31%|███       | 1123/3636 [32:16<1:11:54,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  31%|███       | 1124/3636 [32:16<1:11:53,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  31%|███       | 1124/3636 [32:18<1:11:53,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  31%|███       | 1125/3636 [32:18<1:11:51,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  31%|███       | 1125/3636 [32:20<1:11:51,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  31%|███       | 1126/3636 [32:20<1:11:49,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  31%|███       | 1126/3636 [32:21<1:11:49,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  31%|███       | 1127/3636 [32:21<1:11:47,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  31%|███       | 1127/3636 [32:23<1:11:47,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  31%|███       | 1128/3636 [32:23<1:11:46,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  31%|███       | 1128/3636 [32:25<1:11:46,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  31%|███       | 1129/3636 [32:25<1:11:45,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  31%|███       | 1129/3636 [32:27<1:11:45,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  31%|███       | 1130/3636 [32:27<1:11:43,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  31%|███       | 1130/3636 [32:28<1:11:43,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  31%|███       | 1131/3636 [32:28<1:11:40,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  31%|███       | 1131/3636 [32:30<1:11:40,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  31%|███       | 1132/3636 [32:30<1:11:38,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  31%|███       | 1132/3636 [32:32<1:11:38,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  31%|███       | 1133/3636 [32:32<1:11:36,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  31%|███       | 1133/3636 [32:33<1:11:36,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  31%|███       | 1134/3636 [32:33<1:11:33,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  31%|███       | 1134/3636 [32:35<1:11:33,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  31%|███       | 1135/3636 [32:35<1:11:31,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  31%|███       | 1135/3636 [32:37<1:11:31,  1.72s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  31%|███       | 1136/3636 [32:37<1:11:28,  1.72s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  31%|███       | 1136/3636 [32:39<1:11:28,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1137/3636 [32:39<1:11:28,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1137/3636 [32:40<1:11:28,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1138/3636 [32:40<1:11:25,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1138/3636 [32:42<1:11:25,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1139/3636 [32:42<1:11:23,  1.72s/it, training_loss=0.270]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  31%|███▏      | 1139/3636 [32:44<1:11:23,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1140/3636 [32:44<1:11:21,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1140/3636 [32:45<1:11:21,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1141/3636 [32:45<1:11:20,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1141/3636 [32:47<1:11:20,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1142/3636 [32:47<1:11:17,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1142/3636 [32:49<1:11:17,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1143/3636 [32:49<1:11:16,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1143/3636 [32:51<1:11:16,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1144/3636 [32:51<1:11:15,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1144/3636 [32:52<1:11:15,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1145/3636 [32:52<1:11:14,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 1145/3636 [32:54<1:11:14,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1146/3636 [32:54<1:11:13,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1146/3636 [32:56<1:11:13,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1147/3636 [32:56<1:11:12,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1147/3636 [32:57<1:11:12,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1148/3636 [32:58<1:11:09,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1148/3636 [32:59<1:11:09,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1149/3636 [32:59<1:11:07,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1149/3636 [33:01<1:11:07,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1150/3636 [33:01<1:11:05,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1150/3636 [33:03<1:11:05,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1151/3636 [33:03<1:11:03,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1151/3636 [33:04<1:11:03,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1152/3636 [33:04<1:11:01,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1152/3636 [33:06<1:11:01,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1153/3636 [33:06<1:10:59,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1153/3636 [33:08<1:10:59,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1154/3636 [33:08<1:10:58,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1154/3636 [33:10<1:10:58,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1155/3636 [33:10<1:10:57,  1.72s/it, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1155/3636 [33:11<1:10:57,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1156/3636 [33:11<1:10:54,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1156/3636 [33:13<1:10:54,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1157/3636 [33:13<1:10:52,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1157/3636 [33:15<1:10:52,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1158/3636 [33:15<1:10:50,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1158/3636 [33:16<1:10:50,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1159/3636 [33:16<1:10:49,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1159/3636 [33:18<1:10:49,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1160/3636 [33:18<1:10:48,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1160/3636 [33:20<1:10:48,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1161/3636 [33:20<1:10:45,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1161/3636 [33:22<1:10:45,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1162/3636 [33:22<1:10:44,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1162/3636 [33:23<1:10:44,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1163/3636 [33:23<1:10:43,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1163/3636 [33:25<1:10:43,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1164/3636 [33:25<1:10:42,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1164/3636 [33:27<1:10:42,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1165/3636 [33:27<1:10:40,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1165/3636 [33:28<1:10:40,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1166/3636 [33:28<1:10:40,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1166/3636 [33:30<1:10:40,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1167/3636 [33:30<1:10:38,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1167/3636 [33:32<1:10:38,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1168/3636 [33:32<1:10:37,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1168/3636 [33:34<1:10:37,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1169/3636 [33:34<1:10:35,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1169/3636 [33:35<1:10:35,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1170/3636 [33:35<1:10:32,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1170/3636 [33:37<1:10:32,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1171/3636 [33:37<1:10:29,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1171/3636 [33:39<1:10:29,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1172/3636 [33:39<1:10:26,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1172/3636 [33:40<1:10:26,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1173/3636 [33:40<1:10:26,  1.72s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1173/3636 [33:42<1:10:26,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1174/3636 [33:42<1:10:22,  1.71s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1174/3636 [33:44<1:10:22,  1.71s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1175/3636 [33:44<1:10:21,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1175/3636 [33:46<1:10:21,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1176/3636 [33:46<1:10:18,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1176/3636 [33:47<1:10:18,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1177/3636 [33:47<1:10:18,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1177/3636 [33:49<1:10:18,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1178/3636 [33:49<1:10:15,  1.71s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1178/3636 [33:51<1:10:15,  1.71s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1179/3636 [33:51<1:10:12,  1.71s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1179/3636 [33:52<1:10:12,  1.71s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1180/3636 [33:52<1:10:10,  1.71s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1180/3636 [33:54<1:10:10,  1.71s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1181/3636 [33:54<1:10:07,  1.71s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1181/3636 [33:56<1:10:07,  1.71s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1182/3636 [33:56<1:10:06,  1.71s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1182/3636 [33:58<1:10:06,  1.71s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1183/3636 [33:58<1:10:03,  1.71s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1183/3636 [33:59<1:10:03,  1.71s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1184/3636 [33:59<1:10:02,  1.71s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1184/3636 [34:01<1:10:02,  1.71s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1185/3636 [34:01<1:10:03,  1.71s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1185/3636 [34:03<1:10:03,  1.71s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1186/3636 [34:03<1:10:02,  1.72s/it, training_loss=0.280]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  33%|███▎      | 1186/3636 [34:04<1:10:02,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1187/3636 [34:04<1:10:00,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1187/3636 [34:06<1:10:00,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1188/3636 [34:06<1:10:00,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1188/3636 [34:08<1:10:00,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1189/3636 [34:08<1:09:56,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1189/3636 [34:10<1:09:56,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1190/3636 [34:10<1:09:55,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1190/3636 [34:11<1:09:55,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1191/3636 [34:11<1:09:53,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1191/3636 [34:13<1:09:53,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1192/3636 [34:13<1:09:51,  1.71s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1192/3636 [34:15<1:09:51,  1.71s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1193/3636 [34:15<1:09:47,  1.71s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1193/3636 [34:16<1:09:47,  1.71s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1194/3636 [34:16<1:09:45,  1.71s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1194/3636 [34:18<1:09:45,  1.71s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1195/3636 [34:18<1:09:44,  1.71s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1195/3636 [34:20<1:09:44,  1.71s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1196/3636 [34:20<1:09:42,  1.71s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1196/3636 [34:22<1:09:42,  1.71s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1197/3636 [34:22<1:09:40,  1.71s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1197/3636 [34:23<1:09:40,  1.71s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1198/3636 [34:23<1:09:39,  1.71s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1198/3636 [34:25<1:09:39,  1.71s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1199/3636 [34:25<1:09:37,  1.71s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1199/3636 [34:27<1:09:37,  1.71s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1200/3636 [34:27<1:09:36,  1.71s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1200/3636 [34:28<1:09:36,  1.71s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1201/3636 [34:28<1:09:33,  1.71s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1201/3636 [34:30<1:09:33,  1.71s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1202/3636 [34:30<1:09:32,  1.71s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1202/3636 [34:32<1:09:32,  1.71s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1203/3636 [34:32<1:09:30,  1.71s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1203/3636 [34:34<1:09:30,  1.71s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1204/3636 [34:34<1:09:28,  1.71s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1204/3636 [34:35<1:09:28,  1.71s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1205/3636 [34:35<1:09:28,  1.71s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1205/3636 [34:37<1:09:28,  1.71s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1206/3636 [34:37<1:09:27,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1206/3636 [34:39<1:09:27,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1207/3636 [34:39<1:09:26,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1207/3636 [34:40<1:09:26,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1208/3636 [34:40<1:09:23,  1.71s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1208/3636 [34:42<1:09:23,  1.71s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1209/3636 [34:42<1:09:22,  1.72s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1209/3636 [34:44<1:09:22,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1210/3636 [34:44<1:09:21,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1210/3636 [34:46<1:09:21,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1211/3636 [34:46<1:09:20,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1211/3636 [34:47<1:09:20,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1212/3636 [34:47<1:09:19,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1212/3636 [34:49<1:09:19,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1213/3636 [34:49<1:09:17,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1213/3636 [34:51<1:09:17,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1214/3636 [34:51<1:09:16,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1214/3636 [34:52<1:09:16,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1215/3636 [34:52<1:09:15,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1215/3636 [34:54<1:09:15,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1216/3636 [34:54<1:09:13,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1216/3636 [34:56<1:09:13,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1217/3636 [34:56<1:09:10,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1217/3636 [34:58<1:09:10,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1218/3636 [34:58<1:09:07,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1218/3636 [34:59<1:09:07,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1219/3636 [34:59<1:09:05,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1219/3636 [35:01<1:09:05,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1220/3636 [35:01<1:09:03,  1.71s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1220/3636 [35:03<1:09:03,  1.71s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1221/3636 [35:03<1:09:01,  1.71s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1221/3636 [35:04<1:09:01,  1.71s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1222/3636 [35:04<1:08:59,  1.71s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1222/3636 [35:06<1:08:59,  1.71s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1223/3636 [35:06<1:08:58,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1223/3636 [35:08<1:08:58,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1224/3636 [35:08<1:08:57,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1224/3636 [35:10<1:08:57,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1225/3636 [35:10<1:08:55,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1225/3636 [35:11<1:08:55,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1226/3636 [35:11<1:08:56,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1226/3636 [35:13<1:08:56,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1227/3636 [35:13<1:08:53,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 1227/3636 [35:15<1:08:53,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1228/3636 [35:15<1:08:51,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1228/3636 [35:16<1:08:51,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1229/3636 [35:16<1:08:54,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1229/3636 [35:18<1:08:54,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1230/3636 [35:18<1:08:51,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1230/3636 [35:20<1:08:51,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1231/3636 [35:20<1:08:47,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1231/3636 [35:22<1:08:47,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1232/3636 [35:22<1:08:46,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1232/3636 [35:23<1:08:46,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1233/3636 [35:23<1:08:44,  1.72s/it, training_loss=0.289]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  34%|███▍      | 1233/3636 [35:25<1:08:44,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1234/3636 [35:25<1:08:42,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1234/3636 [35:27<1:08:42,  1.72s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1235/3636 [35:27<1:08:42,  1.72s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1235/3636 [35:28<1:08:42,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1236/3636 [35:28<1:08:39,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1236/3636 [35:30<1:08:39,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1237/3636 [35:30<1:08:37,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1237/3636 [35:32<1:08:37,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1238/3636 [35:32<1:08:35,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1238/3636 [35:34<1:08:35,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1239/3636 [35:34<1:08:32,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1239/3636 [35:35<1:08:32,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1240/3636 [35:35<1:08:31,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1240/3636 [35:37<1:08:31,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1241/3636 [35:37<1:08:30,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1241/3636 [35:39<1:08:30,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1242/3636 [35:39<1:08:30,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1242/3636 [35:40<1:08:30,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1243/3636 [35:40<1:08:29,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1243/3636 [35:42<1:08:29,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1244/3636 [35:42<1:08:26,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1244/3636 [35:44<1:08:26,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1245/3636 [35:44<1:08:24,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1245/3636 [35:46<1:08:24,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1246/3636 [35:46<1:08:23,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1246/3636 [35:47<1:08:23,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1247/3636 [35:47<1:08:20,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1247/3636 [35:49<1:08:20,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1248/3636 [35:49<1:08:20,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1248/3636 [35:51<1:08:20,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1249/3636 [35:51<1:08:19,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1249/3636 [35:52<1:08:19,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1250/3636 [35:52<1:08:16,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1250/3636 [35:54<1:08:16,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1251/3636 [35:54<1:08:15,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1251/3636 [35:56<1:08:15,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1252/3636 [35:56<1:08:14,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1252/3636 [35:58<1:08:14,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1253/3636 [35:58<1:08:12,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1253/3636 [35:59<1:08:12,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1254/3636 [35:59<1:08:11,  1.72s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 1254/3636 [36:01<1:08:11,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1255/3636 [36:01<1:08:08,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1255/3636 [36:03<1:08:08,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1256/3636 [36:03<1:08:07,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1256/3636 [36:05<1:08:07,  1.72s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1257/3636 [36:05<1:08:06,  1.72s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1257/3636 [36:06<1:08:06,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1258/3636 [36:06<1:08:03,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1258/3636 [36:08<1:08:03,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1259/3636 [36:08<1:08:03,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1259/3636 [36:10<1:08:03,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1260/3636 [36:10<1:08:01,  1.72s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1260/3636 [36:11<1:08:01,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1261/3636 [36:11<1:08:00,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1261/3636 [36:13<1:08:00,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1262/3636 [36:13<1:07:59,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1262/3636 [36:15<1:07:59,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1263/3636 [36:15<1:07:56,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1263/3636 [36:17<1:07:56,  1.72s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1264/3636 [36:17<1:07:54,  1.72s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1264/3636 [36:18<1:07:54,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1265/3636 [36:18<1:07:54,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1265/3636 [36:20<1:07:54,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1266/3636 [36:20<1:07:53,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1266/3636 [36:22<1:07:53,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1267/3636 [36:22<1:07:49,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1267/3636 [36:23<1:07:49,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1268/3636 [36:23<1:07:48,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1268/3636 [36:25<1:07:48,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1269/3636 [36:25<1:07:47,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1269/3636 [36:27<1:07:47,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1270/3636 [36:27<1:07:45,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1270/3636 [36:29<1:07:45,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1271/3636 [36:29<1:07:43,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1271/3636 [36:30<1:07:43,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1272/3636 [36:30<1:07:42,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 1272/3636 [36:32<1:07:42,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1273/3636 [36:32<1:07:40,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1273/3636 [36:34<1:07:40,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1274/3636 [36:34<1:07:39,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1274/3636 [36:35<1:07:39,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1275/3636 [36:35<1:07:38,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1275/3636 [36:37<1:07:38,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1276/3636 [36:37<1:07:37,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1276/3636 [36:39<1:07:37,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1277/3636 [36:39<1:07:34,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1277/3636 [36:41<1:07:34,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1278/3636 [36:41<1:07:32,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1278/3636 [36:42<1:07:32,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1279/3636 [36:42<1:07:30,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1279/3636 [36:44<1:07:30,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1280/3636 [36:44<1:07:29,  1.72s/it, training_loss=0.287]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  35%|███▌      | 1280/3636 [36:46<1:07:29,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1281/3636 [36:46<1:07:27,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1281/3636 [36:47<1:07:27,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1282/3636 [36:47<1:07:27,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1282/3636 [36:49<1:07:27,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1283/3636 [36:49<1:07:24,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1283/3636 [36:51<1:07:24,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1284/3636 [36:51<1:07:22,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1284/3636 [36:53<1:07:22,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1285/3636 [36:53<1:07:20,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1285/3636 [36:54<1:07:20,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1286/3636 [36:54<1:07:19,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1286/3636 [36:56<1:07:19,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1287/3636 [36:56<1:07:15,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1287/3636 [36:58<1:07:15,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1288/3636 [36:58<1:07:14,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1288/3636 [37:00<1:07:14,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1289/3636 [37:00<1:07:13,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1289/3636 [37:01<1:07:13,  1.72s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1290/3636 [37:01<1:07:11,  1.72s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 1290/3636 [37:03<1:07:11,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1291/3636 [37:03<1:07:10,  1.72s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1291/3636 [37:05<1:07:10,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1292/3636 [37:05<1:07:08,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1292/3636 [37:06<1:07:08,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1293/3636 [37:06<1:07:06,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1293/3636 [37:08<1:07:06,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1294/3636 [37:08<1:07:05,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1294/3636 [37:10<1:07:05,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1295/3636 [37:10<1:07:04,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1295/3636 [37:12<1:07:04,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1296/3636 [37:12<1:07:01,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1296/3636 [37:13<1:07:01,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1297/3636 [37:13<1:06:58,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1297/3636 [37:15<1:06:58,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1298/3636 [37:15<1:06:57,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1298/3636 [37:17<1:06:57,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1299/3636 [37:17<1:06:56,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1299/3636 [37:18<1:06:56,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1300/3636 [37:18<1:06:55,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1300/3636 [37:20<1:06:55,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1301/3636 [37:20<1:06:55,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1301/3636 [37:22<1:06:55,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1302/3636 [37:22<1:06:52,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1302/3636 [37:24<1:06:52,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1303/3636 [37:24<1:06:51,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1303/3636 [37:25<1:06:51,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1304/3636 [37:25<1:06:51,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1304/3636 [37:27<1:06:51,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1305/3636 [37:27<1:06:49,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1305/3636 [37:29<1:06:49,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1306/3636 [37:29<1:06:51,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1306/3636 [37:30<1:06:51,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1307/3636 [37:30<1:06:49,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1307/3636 [37:32<1:06:49,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1308/3636 [37:32<1:06:48,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1308/3636 [37:34<1:06:48,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1309/3636 [37:34<1:06:44,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1309/3636 [37:36<1:06:44,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1310/3636 [37:36<1:06:44,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1310/3636 [37:37<1:06:44,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1311/3636 [37:37<1:06:42,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1311/3636 [37:39<1:06:42,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1312/3636 [37:39<1:06:39,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1312/3636 [37:41<1:06:39,  1.72s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1313/3636 [37:41<1:06:38,  1.72s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1313/3636 [37:43<1:06:38,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1314/3636 [37:43<1:06:37,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1314/3636 [37:44<1:06:37,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1315/3636 [37:44<1:06:36,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1315/3636 [37:46<1:06:36,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1316/3636 [37:46<1:06:34,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1316/3636 [37:48<1:06:34,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1317/3636 [37:48<1:06:32,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1317/3636 [37:49<1:06:32,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1318/3636 [37:49<1:06:29,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 1318/3636 [37:51<1:06:29,  1.72s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1319/3636 [37:51<1:06:28,  1.72s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1319/3636 [37:53<1:06:28,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1320/3636 [37:53<1:06:27,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1320/3636 [37:55<1:06:27,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1321/3636 [37:55<1:06:25,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1321/3636 [37:56<1:06:25,  1.72s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1322/3636 [37:56<1:06:25,  1.72s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1322/3636 [37:58<1:06:25,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1323/3636 [37:58<1:06:22,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1323/3636 [38:00<1:06:22,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1324/3636 [38:00<1:06:22,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1324/3636 [38:01<1:06:22,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1325/3636 [38:01<1:06:24,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1325/3636 [38:03<1:06:24,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1326/3636 [38:03<1:06:20,  1.72s/it, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1326/3636 [38:05<1:06:20,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 1327/3636 [38:05<1:06:16,  1.72s/it, training_loss=0.298]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  36%|███▋      | 1327/3636 [38:07<1:06:16,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1328/3636 [38:07<1:06:13,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1328/3636 [38:08<1:06:13,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1329/3636 [38:08<1:06:11,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1329/3636 [38:10<1:06:11,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1330/3636 [38:10<1:06:11,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1330/3636 [38:12<1:06:11,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1331/3636 [38:12<1:06:10,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1331/3636 [38:14<1:06:10,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1332/3636 [38:14<1:06:07,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1332/3636 [38:15<1:06:07,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1333/3636 [38:15<1:06:05,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1333/3636 [38:17<1:06:05,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1334/3636 [38:17<1:06:03,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1334/3636 [38:19<1:06:03,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1335/3636 [38:19<1:06:00,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1335/3636 [38:20<1:06:00,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1336/3636 [38:20<1:05:57,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1336/3636 [38:22<1:05:57,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1337/3636 [38:22<1:05:55,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1337/3636 [38:24<1:05:55,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1338/3636 [38:24<1:05:56,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1338/3636 [38:26<1:05:56,  1.72s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1339/3636 [38:26<1:05:54,  1.72s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1339/3636 [38:27<1:05:54,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1340/3636 [38:27<1:05:52,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1340/3636 [38:29<1:05:52,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1341/3636 [38:29<1:05:50,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1341/3636 [38:31<1:05:50,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1342/3636 [38:31<1:05:49,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1342/3636 [38:32<1:05:49,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1343/3636 [38:32<1:05:47,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1343/3636 [38:34<1:05:47,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1344/3636 [38:34<1:05:46,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1344/3636 [38:36<1:05:46,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1345/3636 [38:36<1:05:45,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1345/3636 [38:38<1:05:45,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1346/3636 [38:38<1:05:44,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1346/3636 [38:39<1:05:44,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1347/3636 [38:39<1:05:42,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1347/3636 [38:41<1:05:42,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1348/3636 [38:41<1:05:40,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1348/3636 [38:43<1:05:40,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1349/3636 [38:43<1:05:39,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1349/3636 [38:45<1:05:39,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1350/3636 [38:45<1:05:40,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1350/3636 [38:46<1:05:40,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1351/3636 [38:46<1:05:38,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1351/3636 [38:48<1:05:38,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1352/3636 [38:48<1:05:38,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1352/3636 [38:50<1:05:38,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1353/3636 [38:50<1:05:35,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1353/3636 [38:51<1:05:35,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1354/3636 [38:51<1:05:33,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1354/3636 [38:53<1:05:33,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1355/3636 [38:53<1:05:31,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1355/3636 [38:55<1:05:31,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1356/3636 [38:55<1:05:31,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1356/3636 [38:57<1:05:31,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1357/3636 [38:57<1:05:27,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1357/3636 [38:58<1:05:27,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1358/3636 [38:58<1:05:29,  1.73s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1358/3636 [39:00<1:05:29,  1.73s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1359/3636 [39:00<1:05:24,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1359/3636 [39:02<1:05:24,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1360/3636 [39:02<1:05:23,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1360/3636 [39:03<1:05:23,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1361/3636 [39:03<1:05:22,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1361/3636 [39:05<1:05:22,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1362/3636 [39:05<1:05:19,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1362/3636 [39:07<1:05:19,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1363/3636 [39:07<1:05:17,  1.72s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 1363/3636 [39:09<1:05:17,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1364/3636 [39:09<1:05:15,  1.72s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1364/3636 [39:10<1:05:15,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1365/3636 [39:10<1:05:12,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1365/3636 [39:12<1:05:12,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1366/3636 [39:12<1:05:09,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1366/3636 [39:14<1:05:09,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1367/3636 [39:14<1:05:07,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1367/3636 [39:16<1:05:07,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1368/3636 [39:16<1:05:06,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1368/3636 [39:17<1:05:06,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1369/3636 [39:17<1:05:05,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1369/3636 [39:19<1:05:05,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1370/3636 [39:19<1:05:03,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1370/3636 [39:21<1:05:03,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1371/3636 [39:21<1:05:01,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1371/3636 [39:22<1:05:01,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1372/3636 [39:22<1:05:00,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1372/3636 [39:24<1:05:00,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1373/3636 [39:24<1:04:57,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1373/3636 [39:26<1:04:57,  1.72s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1374/3636 [39:26<1:04:55,  1.72s/it, training_loss=0.254]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  38%|███▊      | 1374/3636 [39:28<1:04:55,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1375/3636 [39:28<1:04:52,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1375/3636 [39:29<1:04:52,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1376/3636 [39:29<1:04:51,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1376/3636 [39:31<1:04:51,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1377/3636 [39:31<1:04:48,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1377/3636 [39:33<1:04:48,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1378/3636 [39:33<1:04:49,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1378/3636 [39:34<1:04:49,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1379/3636 [39:34<1:04:46,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1379/3636 [39:36<1:04:46,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1380/3636 [39:36<1:04:43,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1380/3636 [39:38<1:04:43,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1381/3636 [39:38<1:04:42,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1381/3636 [39:40<1:04:42,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1382/3636 [39:40<1:04:39,  1.72s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1382/3636 [39:41<1:04:39,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1383/3636 [39:41<1:04:37,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1383/3636 [39:43<1:04:37,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1384/3636 [39:43<1:04:34,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1384/3636 [39:45<1:04:34,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1385/3636 [39:45<1:04:32,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1385/3636 [39:47<1:04:32,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1386/3636 [39:47<1:04:30,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1386/3636 [39:48<1:04:30,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1387/3636 [39:48<1:04:28,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1387/3636 [39:50<1:04:28,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1388/3636 [39:50<1:04:27,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1388/3636 [39:52<1:04:27,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1389/3636 [39:52<1:04:25,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1389/3636 [39:53<1:04:25,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1390/3636 [39:53<1:04:23,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1390/3636 [39:55<1:04:23,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1391/3636 [39:55<1:04:20,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1391/3636 [39:57<1:04:20,  1.72s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1392/3636 [39:57<1:04:18,  1.72s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1392/3636 [39:59<1:04:18,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1393/3636 [39:59<1:04:16,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1393/3636 [40:00<1:04:16,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1394/3636 [40:00<1:04:15,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1394/3636 [40:02<1:04:15,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1395/3636 [40:02<1:04:12,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1395/3636 [40:04<1:04:12,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1396/3636 [40:04<1:04:11,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1396/3636 [40:05<1:04:11,  1.72s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1397/3636 [40:05<1:04:08,  1.72s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1397/3636 [40:07<1:04:08,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1398/3636 [40:07<1:04:07,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1398/3636 [40:09<1:04:07,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1399/3636 [40:09<1:04:04,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 1399/3636 [40:11<1:04:04,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1400/3636 [40:11<1:04:03,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1400/3636 [40:12<1:04:03,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1401/3636 [40:12<1:03:59,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1401/3636 [40:14<1:03:59,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1402/3636 [40:14<1:03:58,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1402/3636 [40:16<1:03:58,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1403/3636 [40:16<1:03:56,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1403/3636 [40:17<1:03:56,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1404/3636 [40:17<1:03:56,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1404/3636 [40:19<1:03:56,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1405/3636 [40:19<1:03:53,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1405/3636 [40:21<1:03:53,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1406/3636 [40:21<1:03:51,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1406/3636 [40:23<1:03:51,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1407/3636 [40:23<1:03:49,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1407/3636 [40:24<1:03:49,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1408/3636 [40:24<1:03:48,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 1408/3636 [40:26<1:03:48,  1.72s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1409/3636 [40:26<1:03:46,  1.72s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1409/3636 [40:28<1:03:46,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1410/3636 [40:28<1:03:44,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1410/3636 [40:29<1:03:44,  1.72s/it, training_loss=0.189]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1411/3636 [40:29<1:03:43,  1.72s/it, training_loss=0.189]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1411/3636 [40:31<1:03:43,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1412/3636 [40:31<1:03:43,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1412/3636 [40:33<1:03:43,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1413/3636 [40:33<1:03:42,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1413/3636 [40:35<1:03:42,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1414/3636 [40:35<1:03:39,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1414/3636 [40:36<1:03:39,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1415/3636 [40:36<1:03:37,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1415/3636 [40:38<1:03:37,  1.72s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1416/3636 [40:38<1:03:36,  1.72s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1416/3636 [40:40<1:03:36,  1.72s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1417/3636 [40:40<1:03:35,  1.72s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1417/3636 [40:42<1:03:35,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1418/3636 [40:42<1:03:34,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1418/3636 [40:43<1:03:34,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1419/3636 [40:43<1:03:32,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1419/3636 [40:45<1:03:32,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1420/3636 [40:45<1:03:29,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1420/3636 [40:47<1:03:29,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1421/3636 [40:47<1:03:26,  1.72s/it, training_loss=0.295]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  39%|███▉      | 1421/3636 [40:48<1:03:26,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1422/3636 [40:48<1:03:25,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1422/3636 [40:50<1:03:25,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1423/3636 [40:50<1:03:24,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1423/3636 [40:52<1:03:24,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1424/3636 [40:52<1:03:23,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1424/3636 [40:54<1:03:23,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1425/3636 [40:54<1:03:21,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1425/3636 [40:55<1:03:21,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1426/3636 [40:55<1:03:22,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1426/3636 [40:57<1:03:22,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1427/3636 [40:57<1:03:19,  1.72s/it, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1427/3636 [40:59<1:03:19,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1428/3636 [40:59<1:03:17,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1428/3636 [41:00<1:03:17,  1.72s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1429/3636 [41:00<1:03:17,  1.72s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1429/3636 [41:02<1:03:17,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1430/3636 [41:02<1:03:15,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1430/3636 [41:04<1:03:15,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1431/3636 [41:04<1:03:13,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1431/3636 [41:06<1:03:13,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1432/3636 [41:06<1:03:12,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1432/3636 [41:07<1:03:12,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1433/3636 [41:07<1:03:09,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1433/3636 [41:09<1:03:09,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1434/3636 [41:09<1:03:09,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1434/3636 [41:11<1:03:09,  1.72s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1435/3636 [41:11<1:03:09,  1.72s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1435/3636 [41:12<1:03:09,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1436/3636 [41:12<1:03:07,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 1436/3636 [41:14<1:03:07,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1437/3636 [41:14<1:03:06,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1437/3636 [41:16<1:03:06,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1438/3636 [41:16<1:03:05,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1438/3636 [41:18<1:03:05,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1439/3636 [41:18<1:03:03,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1439/3636 [41:19<1:03:03,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1440/3636 [41:19<1:03:02,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1440/3636 [41:21<1:03:02,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1441/3636 [41:21<1:03:00,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1441/3636 [41:23<1:03:00,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1442/3636 [41:23<1:02:59,  1.72s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1442/3636 [41:25<1:02:59,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1443/3636 [41:25<1:02:57,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1443/3636 [41:26<1:02:57,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1444/3636 [41:26<1:02:55,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1444/3636 [41:28<1:02:55,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1445/3636 [41:28<1:02:54,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1445/3636 [41:30<1:02:54,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1446/3636 [41:30<1:02:55,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1446/3636 [41:31<1:02:55,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1447/3636 [41:31<1:02:52,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1447/3636 [41:33<1:02:52,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1448/3636 [41:33<1:02:51,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1448/3636 [41:35<1:02:51,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1449/3636 [41:35<1:02:48,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1449/3636 [41:37<1:02:48,  1.72s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1450/3636 [41:37<1:02:47,  1.72s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1450/3636 [41:38<1:02:47,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1451/3636 [41:38<1:02:47,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1451/3636 [41:40<1:02:47,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1452/3636 [41:40<1:02:46,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1452/3636 [41:42<1:02:46,  1.72s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1453/3636 [41:42<1:02:45,  1.72s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1453/3636 [41:44<1:02:45,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1454/3636 [41:44<1:02:43,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 1454/3636 [41:45<1:02:43,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  40%|████      | 1455/3636 [41:45<1:02:41,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  40%|████      | 1455/3636 [41:47<1:02:41,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  40%|████      | 1456/3636 [41:47<1:02:40,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  40%|████      | 1456/3636 [41:49<1:02:40,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  40%|████      | 1457/3636 [41:49<1:02:38,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  40%|████      | 1457/3636 [41:50<1:02:38,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  40%|████      | 1458/3636 [41:50<1:02:38,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  40%|████      | 1458/3636 [41:52<1:02:38,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  40%|████      | 1459/3636 [41:52<1:02:38,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  40%|████      | 1459/3636 [41:54<1:02:38,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  40%|████      | 1460/3636 [41:54<1:02:37,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  40%|████      | 1460/3636 [41:56<1:02:37,  1.73s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  40%|████      | 1461/3636 [41:56<1:02:35,  1.73s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  40%|████      | 1461/3636 [41:57<1:02:35,  1.73s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  40%|████      | 1462/3636 [41:57<1:02:31,  1.73s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  40%|████      | 1462/3636 [41:59<1:02:31,  1.73s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  40%|████      | 1463/3636 [41:59<1:02:30,  1.73s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  40%|████      | 1463/3636 [42:01<1:02:30,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  40%|████      | 1464/3636 [42:01<1:02:28,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  40%|████      | 1464/3636 [42:02<1:02:28,  1.73s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  40%|████      | 1465/3636 [42:02<1:02:25,  1.73s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  40%|████      | 1465/3636 [42:04<1:02:25,  1.73s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  40%|████      | 1466/3636 [42:04<1:02:25,  1.73s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  40%|████      | 1466/3636 [42:06<1:02:25,  1.73s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  40%|████      | 1467/3636 [42:06<1:02:23,  1.73s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  40%|████      | 1467/3636 [42:08<1:02:23,  1.73s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  40%|████      | 1468/3636 [42:08<1:02:23,  1.73s/it, training_loss=0.270]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  40%|████      | 1468/3636 [42:09<1:02:23,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  40%|████      | 1469/3636 [42:09<1:02:21,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  40%|████      | 1469/3636 [42:11<1:02:21,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  40%|████      | 1470/3636 [42:11<1:02:19,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  40%|████      | 1470/3636 [42:13<1:02:19,  1.73s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  40%|████      | 1471/3636 [42:13<1:02:17,  1.73s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  40%|████      | 1471/3636 [42:15<1:02:17,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  40%|████      | 1472/3636 [42:15<1:02:15,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  40%|████      | 1472/3636 [42:16<1:02:15,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  41%|████      | 1473/3636 [42:16<1:02:14,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  41%|████      | 1473/3636 [42:18<1:02:14,  1.73s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  41%|████      | 1474/3636 [42:18<1:02:12,  1.73s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  41%|████      | 1474/3636 [42:20<1:02:12,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  41%|████      | 1475/3636 [42:20<1:02:12,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  41%|████      | 1475/3636 [42:21<1:02:12,  1.73s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  41%|████      | 1476/3636 [42:21<1:02:11,  1.73s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  41%|████      | 1476/3636 [42:23<1:02:11,  1.73s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  41%|████      | 1477/3636 [42:23<1:02:08,  1.73s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  41%|████      | 1477/3636 [42:25<1:02:08,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  41%|████      | 1478/3636 [42:25<1:02:08,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  41%|████      | 1478/3636 [42:27<1:02:08,  1.73s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  41%|████      | 1479/3636 [42:27<1:02:08,  1.73s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  41%|████      | 1479/3636 [42:28<1:02:08,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  41%|████      | 1480/3636 [42:28<1:02:08,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  41%|████      | 1480/3636 [42:30<1:02:08,  1.73s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  41%|████      | 1481/3636 [42:30<1:02:05,  1.73s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  41%|████      | 1481/3636 [42:32<1:02:05,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  41%|████      | 1482/3636 [42:32<1:02:03,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  41%|████      | 1482/3636 [42:34<1:02:03,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  41%|████      | 1483/3636 [42:34<1:02:01,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  41%|████      | 1483/3636 [42:35<1:02:01,  1.73s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  41%|████      | 1484/3636 [42:35<1:01:59,  1.73s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  41%|████      | 1484/3636 [42:37<1:01:59,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  41%|████      | 1485/3636 [42:37<1:01:56,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  41%|████      | 1485/3636 [42:39<1:01:56,  1.73s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  41%|████      | 1486/3636 [42:39<1:01:55,  1.73s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  41%|████      | 1486/3636 [42:41<1:01:55,  1.73s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  41%|████      | 1487/3636 [42:41<1:01:54,  1.73s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  41%|████      | 1487/3636 [42:42<1:01:54,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  41%|████      | 1488/3636 [42:42<1:01:52,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  41%|████      | 1488/3636 [42:44<1:01:52,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  41%|████      | 1489/3636 [42:44<1:01:51,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  41%|████      | 1489/3636 [42:46<1:01:51,  1.73s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  41%|████      | 1490/3636 [42:46<1:01:51,  1.73s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  41%|████      | 1490/3636 [42:47<1:01:51,  1.73s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  41%|████      | 1491/3636 [42:47<1:01:48,  1.73s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  41%|████      | 1491/3636 [42:49<1:01:48,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  41%|████      | 1492/3636 [42:49<1:01:47,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  41%|████      | 1492/3636 [42:51<1:01:47,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  41%|████      | 1493/3636 [42:51<1:01:45,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  41%|████      | 1493/3636 [42:53<1:01:45,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  41%|████      | 1494/3636 [42:53<1:01:42,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  41%|████      | 1494/3636 [42:54<1:01:42,  1.73s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  41%|████      | 1495/3636 [42:54<1:01:41,  1.73s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  41%|████      | 1495/3636 [42:56<1:01:41,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  41%|████      | 1496/3636 [42:56<1:01:40,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  41%|████      | 1496/3636 [42:58<1:01:40,  1.73s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  41%|████      | 1497/3636 [42:58<1:01:39,  1.73s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  41%|████      | 1497/3636 [43:00<1:01:39,  1.73s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  41%|████      | 1498/3636 [43:00<1:01:37,  1.73s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  41%|████      | 1498/3636 [43:01<1:01:37,  1.73s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  41%|████      | 1499/3636 [43:01<1:01:35,  1.73s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  41%|████      | 1499/3636 [43:03<1:01:35,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1500/3636 [43:03<1:01:34,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1500/3636 [43:05<1:01:34,  1.73s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1501/3636 [43:05<1:01:34,  1.73s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1501/3636 [43:06<1:01:34,  1.73s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1502/3636 [43:06<1:01:33,  1.73s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1502/3636 [43:08<1:01:33,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1503/3636 [43:08<1:01:30,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1503/3636 [43:10<1:01:30,  1.73s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1504/3636 [43:10<1:01:28,  1.73s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1504/3636 [43:12<1:01:28,  1.73s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1505/3636 [43:12<1:01:27,  1.73s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1505/3636 [43:13<1:01:27,  1.73s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1506/3636 [43:13<1:01:29,  1.73s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1506/3636 [43:15<1:01:29,  1.73s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1507/3636 [43:15<1:01:25,  1.73s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1507/3636 [43:17<1:01:25,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1508/3636 [43:17<1:01:23,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 1508/3636 [43:19<1:01:23,  1.73s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1509/3636 [43:19<1:01:20,  1.73s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1509/3636 [43:20<1:01:20,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1510/3636 [43:20<1:01:16,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1510/3636 [43:22<1:01:16,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1511/3636 [43:22<1:01:16,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1511/3636 [43:24<1:01:16,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1512/3636 [43:24<1:01:16,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1512/3636 [43:25<1:01:16,  1.73s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1513/3636 [43:25<1:01:13,  1.73s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1513/3636 [43:27<1:01:13,  1.73s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1514/3636 [43:27<1:01:10,  1.73s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1514/3636 [43:29<1:01:10,  1.73s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1515/3636 [43:29<1:01:08,  1.73s/it, training_loss=0.237]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  42%|████▏     | 1515/3636 [43:31<1:01:08,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1516/3636 [43:31<1:01:05,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1516/3636 [43:32<1:01:05,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1517/3636 [43:32<1:01:04,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1517/3636 [43:34<1:01:04,  1.73s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1518/3636 [43:34<1:01:00,  1.73s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1518/3636 [43:36<1:01:00,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1519/3636 [43:36<1:00:58,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1519/3636 [43:38<1:00:58,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1520/3636 [43:38<1:00:58,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1520/3636 [43:39<1:00:58,  1.73s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1521/3636 [43:39<1:00:57,  1.73s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1521/3636 [43:41<1:00:57,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1522/3636 [43:41<1:00:55,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1522/3636 [43:43<1:00:55,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1523/3636 [43:43<1:00:55,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1523/3636 [43:45<1:00:55,  1.73s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1524/3636 [43:45<1:00:54,  1.73s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1524/3636 [43:46<1:00:54,  1.73s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1525/3636 [43:46<1:00:51,  1.73s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1525/3636 [43:48<1:00:51,  1.73s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1526/3636 [43:48<1:00:50,  1.73s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1526/3636 [43:50<1:00:50,  1.73s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1527/3636 [43:50<1:00:48,  1.73s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1527/3636 [43:51<1:00:48,  1.73s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1528/3636 [43:51<1:00:50,  1.73s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1528/3636 [43:53<1:00:50,  1.73s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1529/3636 [43:53<1:00:46,  1.73s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1529/3636 [43:55<1:00:46,  1.73s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1530/3636 [43:55<1:00:44,  1.73s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1530/3636 [43:57<1:00:44,  1.73s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1531/3636 [43:57<1:00:42,  1.73s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1531/3636 [43:58<1:00:42,  1.73s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1532/3636 [43:58<1:00:40,  1.73s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1532/3636 [44:00<1:00:40,  1.73s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1533/3636 [44:00<1:00:38,  1.73s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1533/3636 [44:02<1:00:38,  1.73s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1534/3636 [44:02<1:00:35,  1.73s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1534/3636 [44:04<1:00:35,  1.73s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1535/3636 [44:04<1:00:34,  1.73s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1535/3636 [44:05<1:00:34,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1536/3636 [44:05<1:00:32,  1.73s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1536/3636 [44:07<1:00:32,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1537/3636 [44:07<1:00:32,  1.73s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1537/3636 [44:09<1:00:32,  1.73s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1538/3636 [44:09<1:00:30,  1.73s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1538/3636 [44:10<1:00:30,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1539/3636 [44:10<1:00:27,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1539/3636 [44:12<1:00:27,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1540/3636 [44:12<1:00:27,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1540/3636 [44:14<1:00:27,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1541/3636 [44:14<1:00:24,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1541/3636 [44:16<1:00:24,  1.73s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1542/3636 [44:16<1:00:22,  1.73s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1542/3636 [44:17<1:00:22,  1.73s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1543/3636 [44:17<1:00:20,  1.73s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1543/3636 [44:19<1:00:20,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1544/3636 [44:19<1:00:19,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1544/3636 [44:21<1:00:19,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1545/3636 [44:21<1:00:19,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 1545/3636 [44:23<1:00:19,  1.73s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1546/3636 [44:23<1:00:15,  1.73s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1546/3636 [44:24<1:00:15,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1547/3636 [44:24<1:00:12,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1547/3636 [44:26<1:00:12,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1548/3636 [44:26<1:00:12,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1548/3636 [44:28<1:00:12,  1.73s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1549/3636 [44:28<1:00:11,  1.73s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1549/3636 [44:29<1:00:11,  1.73s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1550/3636 [44:29<1:00:08,  1.73s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1550/3636 [44:31<1:00:08,  1.73s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1551/3636 [44:31<1:00:06,  1.73s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1551/3636 [44:33<1:00:06,  1.73s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1552/3636 [44:33<1:00:04,  1.73s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1552/3636 [44:35<1:00:04,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1553/3636 [44:35<1:00:03,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1553/3636 [44:36<1:00:03,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1554/3636 [44:36<1:00:03,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1554/3636 [44:38<1:00:03,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1555/3636 [44:38<1:00:01,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1555/3636 [44:40<1:00:01,  1.73s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1556/3636 [44:40<59:59,  1.73s/it, training_loss=0.238]  \u001b[A\n",
      "Epoch 1:  43%|████▎     | 1556/3636 [44:42<59:59,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1557/3636 [44:42<59:56,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1557/3636 [44:43<59:56,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1558/3636 [44:43<59:54,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1558/3636 [44:45<59:54,  1.73s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1559/3636 [44:45<59:51,  1.73s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1559/3636 [44:47<59:51,  1.73s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1560/3636 [44:47<59:47,  1.73s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1560/3636 [44:49<59:47,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1561/3636 [44:49<59:47,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1561/3636 [44:50<59:47,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1562/3636 [44:50<59:47,  1.73s/it, training_loss=0.262]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  43%|████▎     | 1562/3636 [44:52<59:47,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1563/3636 [44:52<59:46,  1.73s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1563/3636 [44:54<59:46,  1.73s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1564/3636 [44:54<59:43,  1.73s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1564/3636 [44:55<59:43,  1.73s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1565/3636 [44:55<59:39,  1.73s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1565/3636 [44:57<59:39,  1.73s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1566/3636 [44:57<59:37,  1.73s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1566/3636 [44:59<59:37,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1567/3636 [44:59<59:36,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1567/3636 [45:01<59:36,  1.73s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1568/3636 [45:01<59:33,  1.73s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1568/3636 [45:02<59:33,  1.73s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1569/3636 [45:02<59:31,  1.73s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1569/3636 [45:04<59:31,  1.73s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1570/3636 [45:04<59:29,  1.73s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1570/3636 [45:06<59:29,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1571/3636 [45:06<59:29,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1571/3636 [45:08<59:29,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1572/3636 [45:08<59:28,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1572/3636 [45:09<59:28,  1.73s/it, training_loss=0.393]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1573/3636 [45:09<59:24,  1.73s/it, training_loss=0.393]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1573/3636 [45:11<59:24,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1574/3636 [45:11<59:24,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1574/3636 [45:13<59:24,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1575/3636 [45:13<59:22,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1575/3636 [45:14<59:22,  1.73s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1576/3636 [45:14<59:20,  1.73s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1576/3636 [45:16<59:20,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1577/3636 [45:16<59:17,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1577/3636 [45:18<59:17,  1.73s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1578/3636 [45:18<59:15,  1.73s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1578/3636 [45:20<59:15,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1579/3636 [45:20<59:13,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1579/3636 [45:21<59:13,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1580/3636 [45:21<59:12,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1580/3636 [45:23<59:12,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1581/3636 [45:23<59:08,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 1581/3636 [45:25<59:08,  1.73s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1582/3636 [45:25<59:07,  1.73s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1582/3636 [45:27<59:07,  1.73s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1583/3636 [45:27<59:05,  1.73s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1583/3636 [45:28<59:05,  1.73s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1584/3636 [45:28<59:03,  1.73s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1584/3636 [45:30<59:03,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1585/3636 [45:30<58:59,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1585/3636 [45:32<58:59,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1586/3636 [45:32<58:57,  1.73s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1586/3636 [45:33<58:57,  1.73s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1587/3636 [45:33<58:55,  1.73s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1587/3636 [45:35<58:55,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1588/3636 [45:35<58:53,  1.73s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1588/3636 [45:37<58:53,  1.73s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1589/3636 [45:37<58:50,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1589/3636 [45:39<58:50,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1590/3636 [45:39<58:49,  1.73s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 1590/3636 [45:40<58:49,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1591/3636 [45:40<58:53,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1591/3636 [45:42<58:53,  1.73s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1592/3636 [45:42<58:54,  1.73s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1592/3636 [45:44<58:54,  1.73s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1593/3636 [45:44<58:50,  1.73s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1593/3636 [45:46<58:50,  1.73s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1594/3636 [45:46<58:46,  1.73s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1594/3636 [45:47<58:46,  1.73s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1595/3636 [45:47<58:42,  1.73s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1595/3636 [45:49<58:42,  1.73s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1596/3636 [45:49<58:39,  1.73s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1596/3636 [45:51<58:39,  1.73s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1597/3636 [45:51<58:36,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1597/3636 [45:52<58:36,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1598/3636 [45:52<58:34,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1598/3636 [45:54<58:34,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1599/3636 [45:54<58:34,  1.73s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1599/3636 [45:56<58:34,  1.73s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1600/3636 [45:56<58:37,  1.73s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1600/3636 [45:58<58:37,  1.73s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1601/3636 [45:58<58:31,  1.73s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1601/3636 [45:59<58:31,  1.73s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1602/3636 [45:59<58:30,  1.73s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1602/3636 [46:01<58:30,  1.73s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1603/3636 [46:01<58:26,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1603/3636 [46:03<58:26,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1604/3636 [46:03<58:23,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1604/3636 [46:04<58:23,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1605/3636 [46:04<58:22,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1605/3636 [46:06<58:22,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1606/3636 [46:06<58:18,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1606/3636 [46:08<58:18,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1607/3636 [46:08<58:15,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1607/3636 [46:10<58:15,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1608/3636 [46:10<58:13,  1.72s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1608/3636 [46:11<58:13,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1609/3636 [46:11<58:12,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1609/3636 [46:13<58:12,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1610/3636 [46:13<58:09,  1.72s/it, training_loss=0.337]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  44%|████▍     | 1610/3636 [46:15<58:09,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1611/3636 [46:15<58:08,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1611/3636 [46:17<58:08,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1612/3636 [46:17<58:05,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1612/3636 [46:18<58:05,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1613/3636 [46:18<58:03,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1613/3636 [46:20<58:03,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1614/3636 [46:20<58:02,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1614/3636 [46:22<58:02,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1615/3636 [46:22<58:00,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1615/3636 [46:23<58:00,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1616/3636 [46:23<57:59,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1616/3636 [46:25<57:59,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1617/3636 [46:25<57:56,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1617/3636 [46:27<57:56,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1618/3636 [46:27<57:54,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 1618/3636 [46:29<57:54,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1619/3636 [46:29<57:52,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1619/3636 [46:30<57:52,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1620/3636 [46:30<57:51,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1620/3636 [46:32<57:51,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1621/3636 [46:32<57:52,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1621/3636 [46:34<57:52,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1622/3636 [46:34<57:49,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1622/3636 [46:35<57:49,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1623/3636 [46:35<57:47,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1623/3636 [46:37<57:47,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1624/3636 [46:37<57:44,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1624/3636 [46:39<57:44,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1625/3636 [46:39<57:42,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1625/3636 [46:41<57:42,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1626/3636 [46:41<57:40,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1626/3636 [46:42<57:40,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1627/3636 [46:42<57:38,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1627/3636 [46:44<57:38,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1628/3636 [46:44<57:33,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1628/3636 [46:46<57:33,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1629/3636 [46:46<57:31,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1629/3636 [46:48<57:31,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1630/3636 [46:48<57:29,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1630/3636 [46:49<57:29,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1631/3636 [46:49<57:27,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1631/3636 [46:51<57:27,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1632/3636 [46:51<57:25,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1632/3636 [46:53<57:25,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1633/3636 [46:53<57:24,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1633/3636 [46:54<57:24,  1.72s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1634/3636 [46:54<57:24,  1.72s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1634/3636 [46:56<57:24,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1635/3636 [46:56<57:21,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1635/3636 [46:58<57:21,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1636/3636 [46:58<57:19,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 1636/3636 [47:00<57:19,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1637/3636 [47:00<57:16,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1637/3636 [47:01<57:16,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1638/3636 [47:01<57:13,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1638/3636 [47:03<57:13,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1639/3636 [47:03<57:12,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1639/3636 [47:05<57:12,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1640/3636 [47:05<57:11,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1640/3636 [47:06<57:11,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1641/3636 [47:06<57:10,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1641/3636 [47:08<57:10,  1.72s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1642/3636 [47:08<57:10,  1.72s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1642/3636 [47:10<57:10,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1643/3636 [47:10<57:07,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1643/3636 [47:12<57:07,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1644/3636 [47:12<57:04,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1644/3636 [47:13<57:04,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1645/3636 [47:13<57:01,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1645/3636 [47:15<57:01,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1646/3636 [47:15<56:58,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1646/3636 [47:17<56:58,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1647/3636 [47:17<56:54,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1647/3636 [47:18<56:54,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1648/3636 [47:18<56:54,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1648/3636 [47:20<56:54,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1649/3636 [47:20<56:51,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1649/3636 [47:22<56:51,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1650/3636 [47:22<56:49,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1650/3636 [47:24<56:49,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1651/3636 [47:24<56:46,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1651/3636 [47:25<56:46,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1652/3636 [47:25<56:44,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1652/3636 [47:27<56:44,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1653/3636 [47:27<56:42,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1653/3636 [47:29<56:42,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1654/3636 [47:29<56:39,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 1654/3636 [47:30<56:39,  1.72s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1655/3636 [47:30<56:36,  1.71s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1655/3636 [47:32<56:36,  1.71s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1656/3636 [47:32<56:35,  1.71s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1656/3636 [47:34<56:35,  1.71s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1657/3636 [47:34<56:33,  1.71s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1657/3636 [47:36<56:33,  1.71s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1658/3636 [47:36<56:31,  1.71s/it, training_loss=0.287]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  46%|████▌     | 1658/3636 [47:37<56:31,  1.71s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1659/3636 [47:37<56:30,  1.71s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1659/3636 [47:39<56:30,  1.71s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1660/3636 [47:39<56:27,  1.71s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1660/3636 [47:41<56:27,  1.71s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1661/3636 [47:41<56:26,  1.71s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1661/3636 [47:42<56:26,  1.71s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1662/3636 [47:42<56:25,  1.71s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1662/3636 [47:44<56:25,  1.71s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1663/3636 [47:44<56:23,  1.71s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1663/3636 [47:46<56:23,  1.71s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1664/3636 [47:46<56:24,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1664/3636 [47:48<56:24,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1665/3636 [47:48<56:24,  1.72s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1665/3636 [47:49<56:24,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1666/3636 [47:49<56:23,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1666/3636 [47:51<56:23,  1.72s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1667/3636 [47:51<56:20,  1.72s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1667/3636 [47:53<56:20,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1668/3636 [47:53<56:17,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1668/3636 [47:54<56:17,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1669/3636 [47:54<56:14,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1669/3636 [47:56<56:14,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1670/3636 [47:56<56:13,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1670/3636 [47:58<56:13,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1671/3636 [47:58<56:11,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1671/3636 [48:00<56:11,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1672/3636 [48:00<56:09,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1672/3636 [48:01<56:09,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1673/3636 [48:01<56:07,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1673/3636 [48:03<56:07,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1674/3636 [48:03<56:05,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1674/3636 [48:05<56:05,  1.72s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1675/3636 [48:05<56:05,  1.72s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1675/3636 [48:07<56:05,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1676/3636 [48:07<56:02,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1676/3636 [48:08<56:02,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1677/3636 [48:08<55:59,  1.71s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1677/3636 [48:10<55:59,  1.71s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1678/3636 [48:10<55:57,  1.71s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1678/3636 [48:12<55:57,  1.71s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1679/3636 [48:12<55:54,  1.71s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1679/3636 [48:13<55:54,  1.71s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1680/3636 [48:13<55:52,  1.71s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1680/3636 [48:15<55:52,  1.71s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1681/3636 [48:15<55:52,  1.71s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 1681/3636 [48:17<55:52,  1.71s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1682/3636 [48:17<55:50,  1.71s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1682/3636 [48:19<55:50,  1.71s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1683/3636 [48:19<55:46,  1.71s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1683/3636 [48:20<55:46,  1.71s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1684/3636 [48:20<55:44,  1.71s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1684/3636 [48:22<55:44,  1.71s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1685/3636 [48:22<55:41,  1.71s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1685/3636 [48:24<55:41,  1.71s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1686/3636 [48:24<55:39,  1.71s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1686/3636 [48:25<55:39,  1.71s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1687/3636 [48:25<55:36,  1.71s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1687/3636 [48:27<55:36,  1.71s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1688/3636 [48:27<55:34,  1.71s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1688/3636 [48:29<55:34,  1.71s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1689/3636 [48:29<55:32,  1.71s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1689/3636 [48:30<55:32,  1.71s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1690/3636 [48:30<55:31,  1.71s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 1690/3636 [48:32<55:31,  1.71s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1691/3636 [48:32<55:30,  1.71s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1691/3636 [48:34<55:30,  1.71s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1692/3636 [48:34<55:28,  1.71s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1692/3636 [48:36<55:28,  1.71s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1693/3636 [48:36<55:27,  1.71s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1693/3636 [48:37<55:27,  1.71s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1694/3636 [48:37<55:25,  1.71s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1694/3636 [48:39<55:25,  1.71s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1695/3636 [48:39<55:23,  1.71s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1695/3636 [48:41<55:23,  1.71s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1696/3636 [48:41<55:21,  1.71s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1696/3636 [48:42<55:21,  1.71s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1697/3636 [48:42<55:19,  1.71s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1697/3636 [48:44<55:19,  1.71s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1698/3636 [48:44<55:18,  1.71s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1698/3636 [48:46<55:18,  1.71s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1699/3636 [48:46<55:16,  1.71s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1699/3636 [48:48<55:16,  1.71s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1700/3636 [48:48<55:14,  1.71s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1700/3636 [48:49<55:14,  1.71s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1701/3636 [48:49<55:12,  1.71s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1701/3636 [48:51<55:12,  1.71s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1702/3636 [48:51<55:10,  1.71s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1702/3636 [48:53<55:10,  1.71s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1703/3636 [48:53<55:09,  1.71s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1703/3636 [48:54<55:09,  1.71s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1704/3636 [48:54<55:08,  1.71s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1704/3636 [48:56<55:08,  1.71s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1705/3636 [48:56<55:06,  1.71s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1705/3636 [48:58<55:06,  1.71s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1706/3636 [48:58<55:06,  1.71s/it, training_loss=0.318]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  47%|████▋     | 1706/3636 [49:00<55:06,  1.71s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1707/3636 [49:00<55:02,  1.71s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1707/3636 [49:01<55:02,  1.71s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1708/3636 [49:01<55:02,  1.71s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1708/3636 [49:03<55:02,  1.71s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1709/3636 [49:03<55:00,  1.71s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1709/3636 [49:05<55:00,  1.71s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1710/3636 [49:05<54:59,  1.71s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1710/3636 [49:06<54:59,  1.71s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1711/3636 [49:06<54:58,  1.71s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1711/3636 [49:08<54:58,  1.71s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1712/3636 [49:08<54:56,  1.71s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1712/3636 [49:10<54:56,  1.71s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1713/3636 [49:10<54:54,  1.71s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1713/3636 [49:12<54:54,  1.71s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1714/3636 [49:12<54:52,  1.71s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1714/3636 [49:13<54:52,  1.71s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1715/3636 [49:13<54:51,  1.71s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1715/3636 [49:15<54:51,  1.71s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1716/3636 [49:15<54:50,  1.71s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1716/3636 [49:17<54:50,  1.71s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1717/3636 [49:17<54:47,  1.71s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1717/3636 [49:18<54:47,  1.71s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1718/3636 [49:18<54:46,  1.71s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1718/3636 [49:20<54:46,  1.71s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1719/3636 [49:20<54:45,  1.71s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1719/3636 [49:22<54:45,  1.71s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1720/3636 [49:22<54:44,  1.71s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1720/3636 [49:24<54:44,  1.71s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1721/3636 [49:24<54:45,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1721/3636 [49:25<54:45,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1722/3636 [49:25<54:44,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1722/3636 [49:27<54:44,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1723/3636 [49:27<54:42,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1723/3636 [49:29<54:42,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1724/3636 [49:29<54:42,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1724/3636 [49:30<54:42,  1.72s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1725/3636 [49:30<54:41,  1.72s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1725/3636 [49:32<54:41,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1726/3636 [49:32<54:40,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1726/3636 [49:34<54:40,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1727/3636 [49:34<54:38,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 1727/3636 [49:36<54:38,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1728/3636 [49:36<54:37,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1728/3636 [49:37<54:37,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1729/3636 [49:37<54:34,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1729/3636 [49:39<54:34,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1730/3636 [49:39<54:33,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1730/3636 [49:41<54:33,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1731/3636 [49:41<54:32,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1731/3636 [49:42<54:32,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1732/3636 [49:42<54:30,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1732/3636 [49:44<54:30,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1733/3636 [49:44<54:28,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1733/3636 [49:46<54:28,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1734/3636 [49:46<54:26,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1734/3636 [49:48<54:26,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1735/3636 [49:48<54:25,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1735/3636 [49:49<54:25,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1736/3636 [49:49<54:23,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1736/3636 [49:51<54:23,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1737/3636 [49:51<54:21,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1737/3636 [49:53<54:21,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1738/3636 [49:53<54:20,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1738/3636 [49:55<54:20,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1739/3636 [49:55<54:18,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1739/3636 [49:56<54:18,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1740/3636 [49:56<54:18,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1740/3636 [49:58<54:18,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1741/3636 [49:58<54:17,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1741/3636 [50:00<54:17,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1742/3636 [50:00<54:16,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1742/3636 [50:01<54:16,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1743/3636 [50:01<54:14,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1743/3636 [50:03<54:14,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1744/3636 [50:03<54:13,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1744/3636 [50:05<54:13,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1745/3636 [50:05<54:12,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1745/3636 [50:07<54:12,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1746/3636 [50:07<54:11,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1746/3636 [50:08<54:11,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1747/3636 [50:08<54:10,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1747/3636 [50:10<54:10,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1748/3636 [50:10<54:08,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1748/3636 [50:12<54:08,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1749/3636 [50:12<54:07,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1749/3636 [50:13<54:07,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1750/3636 [50:13<54:07,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1750/3636 [50:15<54:07,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1751/3636 [50:15<54:06,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1751/3636 [50:17<54:06,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1752/3636 [50:17<54:04,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1752/3636 [50:19<54:04,  1.72s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1753/3636 [50:19<54:01,  1.72s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1753/3636 [50:20<54:01,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1754/3636 [50:20<54:01,  1.72s/it, training_loss=0.255]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  48%|████▊     | 1754/3636 [50:22<54:01,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1755/3636 [50:22<53:59,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1755/3636 [50:24<53:59,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1756/3636 [50:24<53:58,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1756/3636 [50:25<53:58,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1757/3636 [50:25<53:54,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1757/3636 [50:27<53:54,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1758/3636 [50:27<53:53,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1758/3636 [50:29<53:53,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1759/3636 [50:29<53:50,  1.72s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1759/3636 [50:31<53:50,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1760/3636 [50:31<53:49,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1760/3636 [50:32<53:49,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1761/3636 [50:32<53:48,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1761/3636 [50:34<53:48,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1762/3636 [50:34<53:48,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1762/3636 [50:36<53:48,  1.72s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1763/3636 [50:36<53:46,  1.72s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1763/3636 [50:38<53:46,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1764/3636 [50:38<53:45,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1764/3636 [50:39<53:45,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1765/3636 [50:39<53:47,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1765/3636 [50:41<53:47,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1766/3636 [50:41<53:45,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1766/3636 [50:43<53:45,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1767/3636 [50:43<53:44,  1.73s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1767/3636 [50:44<53:44,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1768/3636 [50:44<53:41,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1768/3636 [50:46<53:41,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1769/3636 [50:46<53:39,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1769/3636 [50:48<53:39,  1.72s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1770/3636 [50:48<53:37,  1.72s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1770/3636 [50:50<53:37,  1.72s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1771/3636 [50:50<53:33,  1.72s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1771/3636 [50:51<53:33,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1772/3636 [50:51<53:30,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1772/3636 [50:53<53:30,  1.72s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1773/3636 [50:53<53:27,  1.72s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1773/3636 [50:55<53:27,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1774/3636 [50:55<53:26,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1774/3636 [50:57<53:26,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1775/3636 [50:57<53:26,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1775/3636 [50:58<53:26,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1776/3636 [50:58<53:25,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1776/3636 [51:00<53:25,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1777/3636 [51:00<53:22,  1.72s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1777/3636 [51:02<53:22,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1778/3636 [51:02<53:21,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1778/3636 [51:03<53:21,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1779/3636 [51:03<53:19,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1779/3636 [51:05<53:19,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1780/3636 [51:05<53:18,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1780/3636 [51:07<53:18,  1.72s/it, training_loss=0.201]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1781/3636 [51:07<53:16,  1.72s/it, training_loss=0.201]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1781/3636 [51:09<53:16,  1.72s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1782/3636 [51:09<53:15,  1.72s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1782/3636 [51:10<53:15,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1783/3636 [51:10<53:15,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1783/3636 [51:12<53:15,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1784/3636 [51:12<53:12,  1.72s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1784/3636 [51:14<53:12,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1785/3636 [51:14<53:09,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1785/3636 [51:15<53:09,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1786/3636 [51:15<53:08,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1786/3636 [51:17<53:08,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1787/3636 [51:17<53:11,  1.73s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1787/3636 [51:19<53:11,  1.73s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1788/3636 [51:19<53:08,  1.73s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1788/3636 [51:21<53:08,  1.73s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1789/3636 [51:21<53:05,  1.72s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1789/3636 [51:22<53:05,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1790/3636 [51:22<53:02,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1790/3636 [51:24<53:02,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1791/3636 [51:24<53:00,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1791/3636 [51:26<53:00,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1792/3636 [51:26<52:59,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1792/3636 [51:28<52:59,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1793/3636 [51:28<52:57,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1793/3636 [51:29<52:57,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1794/3636 [51:29<52:55,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1794/3636 [51:31<52:55,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1795/3636 [51:31<52:52,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1795/3636 [51:33<52:52,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1796/3636 [51:33<52:51,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1796/3636 [51:34<52:51,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1797/3636 [51:34<52:49,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1797/3636 [51:36<52:49,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1798/3636 [51:36<52:48,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1798/3636 [51:38<52:48,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1799/3636 [51:38<52:45,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 1799/3636 [51:40<52:45,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1800/3636 [51:40<52:41,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1800/3636 [51:41<52:41,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1801/3636 [51:41<52:39,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1801/3636 [51:43<52:39,  1.72s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1802/3636 [51:43<52:37,  1.72s/it, training_loss=0.206]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|████▉     | 1802/3636 [51:45<52:37,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1803/3636 [51:45<52:35,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1803/3636 [51:46<52:35,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1804/3636 [51:46<52:34,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1804/3636 [51:48<52:34,  1.72s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1805/3636 [51:48<52:32,  1.72s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1805/3636 [51:50<52:32,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1806/3636 [51:50<52:32,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1806/3636 [51:52<52:32,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1807/3636 [51:52<52:30,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1807/3636 [51:53<52:30,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1808/3636 [51:53<52:28,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1808/3636 [51:55<52:28,  1.72s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1809/3636 [51:55<52:27,  1.72s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1809/3636 [51:57<52:27,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1810/3636 [51:57<52:25,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1810/3636 [51:59<52:25,  1.72s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1811/3636 [51:59<52:25,  1.72s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1811/3636 [52:00<52:25,  1.72s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1812/3636 [52:00<52:22,  1.72s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1812/3636 [52:02<52:22,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1813/3636 [52:02<52:21,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1813/3636 [52:04<52:21,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1814/3636 [52:04<52:18,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1814/3636 [52:05<52:18,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1815/3636 [52:05<52:16,  1.72s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1815/3636 [52:07<52:16,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1816/3636 [52:07<52:15,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1816/3636 [52:09<52:15,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1817/3636 [52:09<52:15,  1.72s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 1817/3636 [52:11<52:15,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1818/3636 [52:11<52:13,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1818/3636 [52:12<52:13,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1819/3636 [52:12<52:11,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1819/3636 [52:14<52:11,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1820/3636 [52:14<52:10,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1820/3636 [52:16<52:10,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1821/3636 [52:16<52:07,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1821/3636 [52:18<52:07,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1822/3636 [52:18<52:04,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1822/3636 [52:19<52:04,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1823/3636 [52:19<52:03,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1823/3636 [52:21<52:03,  1.72s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1824/3636 [52:21<52:02,  1.72s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1824/3636 [52:23<52:02,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1825/3636 [52:23<52:01,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1825/3636 [52:24<52:01,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1826/3636 [52:24<51:59,  1.72s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1826/3636 [52:26<51:59,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1827/3636 [52:26<51:56,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1827/3636 [52:28<51:56,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1828/3636 [52:28<51:55,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1828/3636 [52:30<51:55,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1829/3636 [52:30<51:54,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1829/3636 [52:31<51:54,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1830/3636 [52:31<51:51,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1830/3636 [52:33<51:51,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1831/3636 [52:33<51:50,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1831/3636 [52:35<51:50,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1832/3636 [52:35<51:50,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1832/3636 [52:36<51:50,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1833/3636 [52:36<51:50,  1.73s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1833/3636 [52:38<51:50,  1.73s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1834/3636 [52:38<51:50,  1.73s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1834/3636 [52:40<51:50,  1.73s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1835/3636 [52:40<51:50,  1.73s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1835/3636 [52:42<51:50,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1836/3636 [52:42<51:47,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  50%|█████     | 1836/3636 [52:43<51:47,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1837/3636 [52:43<51:45,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1837/3636 [52:45<51:45,  1.73s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1838/3636 [52:45<51:43,  1.73s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1838/3636 [52:47<51:43,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1839/3636 [52:47<51:41,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1839/3636 [52:49<51:41,  1.73s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1840/3636 [52:49<51:39,  1.73s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1840/3636 [52:50<51:39,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1841/3636 [52:50<51:36,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1841/3636 [52:52<51:36,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1842/3636 [52:52<51:36,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1842/3636 [52:54<51:36,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1843/3636 [52:54<51:34,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1843/3636 [52:55<51:34,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1844/3636 [52:55<51:33,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1844/3636 [52:57<51:33,  1.73s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1845/3636 [52:57<51:31,  1.73s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1845/3636 [52:59<51:31,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1846/3636 [52:59<51:31,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1846/3636 [53:01<51:31,  1.73s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1847/3636 [53:01<51:29,  1.73s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1847/3636 [53:02<51:29,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1848/3636 [53:02<51:26,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1848/3636 [53:04<51:26,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1849/3636 [53:04<51:24,  1.73s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1849/3636 [53:06<51:24,  1.73s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1850/3636 [53:06<51:23,  1.73s/it, training_loss=0.220]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  51%|█████     | 1850/3636 [53:08<51:23,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1851/3636 [53:08<51:20,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1851/3636 [53:09<51:20,  1.73s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1852/3636 [53:09<51:19,  1.73s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1852/3636 [53:11<51:19,  1.73s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1853/3636 [53:11<51:18,  1.73s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1853/3636 [53:13<51:18,  1.73s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1854/3636 [53:13<51:16,  1.73s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1854/3636 [53:14<51:16,  1.73s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1855/3636 [53:14<51:14,  1.73s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1855/3636 [53:16<51:14,  1.73s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1856/3636 [53:16<51:13,  1.73s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1856/3636 [53:18<51:13,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1857/3636 [53:18<51:12,  1.73s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1857/3636 [53:20<51:12,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1858/3636 [53:20<51:11,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1858/3636 [53:21<51:11,  1.73s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1859/3636 [53:21<51:08,  1.73s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1859/3636 [53:23<51:08,  1.73s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1860/3636 [53:23<51:08,  1.73s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1860/3636 [53:25<51:08,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1861/3636 [53:25<51:06,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1861/3636 [53:27<51:06,  1.73s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1862/3636 [53:27<51:04,  1.73s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1862/3636 [53:28<51:04,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1863/3636 [53:28<51:02,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  51%|█████     | 1863/3636 [53:30<51:02,  1.73s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1864/3636 [53:30<51:00,  1.73s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1864/3636 [53:32<51:00,  1.73s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1865/3636 [53:32<50:59,  1.73s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1865/3636 [53:33<50:59,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1866/3636 [53:33<50:58,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1866/3636 [53:35<50:58,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1867/3636 [53:35<50:56,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1867/3636 [53:37<50:56,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1868/3636 [53:37<50:54,  1.73s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1868/3636 [53:39<50:54,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1869/3636 [53:39<50:52,  1.73s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1869/3636 [53:40<50:52,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1870/3636 [53:40<50:52,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1870/3636 [53:42<50:52,  1.73s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1871/3636 [53:42<50:51,  1.73s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1871/3636 [53:44<50:51,  1.73s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1872/3636 [53:44<50:49,  1.73s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 1872/3636 [53:46<50:49,  1.73s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1873/3636 [53:46<50:46,  1.73s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1873/3636 [53:47<50:46,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1874/3636 [53:47<50:44,  1.73s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1874/3636 [53:49<50:44,  1.73s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1875/3636 [53:49<50:41,  1.73s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1875/3636 [53:51<50:41,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1876/3636 [53:51<50:40,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1876/3636 [53:52<50:40,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1877/3636 [53:52<50:39,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1877/3636 [53:54<50:39,  1.73s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1878/3636 [53:54<50:37,  1.73s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1878/3636 [53:56<50:37,  1.73s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1879/3636 [53:56<50:36,  1.73s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1879/3636 [53:58<50:36,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1880/3636 [53:58<50:34,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1880/3636 [53:59<50:34,  1.73s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1881/3636 [53:59<50:32,  1.73s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1881/3636 [54:01<50:32,  1.73s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1882/3636 [54:01<50:31,  1.73s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1882/3636 [54:03<50:31,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1883/3636 [54:03<50:29,  1.73s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1883/3636 [54:05<50:29,  1.73s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1884/3636 [54:05<50:27,  1.73s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1884/3636 [54:06<50:27,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1885/3636 [54:06<50:27,  1.73s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1885/3636 [54:08<50:27,  1.73s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1886/3636 [54:08<50:25,  1.73s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1886/3636 [54:10<50:25,  1.73s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1887/3636 [54:10<50:25,  1.73s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1887/3636 [54:11<50:25,  1.73s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1888/3636 [54:11<50:22,  1.73s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1888/3636 [54:13<50:22,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1889/3636 [54:13<50:19,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1889/3636 [54:15<50:19,  1.73s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1890/3636 [54:15<50:18,  1.73s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1890/3636 [54:17<50:18,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1891/3636 [54:17<50:17,  1.73s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1891/3636 [54:18<50:17,  1.73s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1892/3636 [54:18<50:15,  1.73s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1892/3636 [54:20<50:15,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1893/3636 [54:20<50:12,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1893/3636 [54:22<50:12,  1.73s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1894/3636 [54:22<50:10,  1.73s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1894/3636 [54:24<50:10,  1.73s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1895/3636 [54:24<50:08,  1.73s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1895/3636 [54:25<50:08,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1896/3636 [54:25<50:07,  1.73s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1896/3636 [54:27<50:07,  1.73s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1897/3636 [54:27<50:03,  1.73s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1897/3636 [54:29<50:03,  1.73s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1898/3636 [54:29<50:00,  1.73s/it, training_loss=0.242]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  52%|█████▏    | 1898/3636 [54:30<50:00,  1.73s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1899/3636 [54:30<49:59,  1.73s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1899/3636 [54:32<49:59,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1900/3636 [54:32<49:59,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1900/3636 [54:34<49:59,  1.73s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1901/3636 [54:34<49:58,  1.73s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1901/3636 [54:36<49:58,  1.73s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1902/3636 [54:36<49:57,  1.73s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1902/3636 [54:37<49:57,  1.73s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1903/3636 [54:37<49:56,  1.73s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1903/3636 [54:39<49:56,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1904/3636 [54:39<49:53,  1.73s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1904/3636 [54:41<49:53,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1905/3636 [54:41<49:50,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1905/3636 [54:43<49:50,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1906/3636 [54:43<49:49,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1906/3636 [54:44<49:49,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1907/3636 [54:44<49:47,  1.73s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1907/3636 [54:46<49:47,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1908/3636 [54:46<49:45,  1.73s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 1908/3636 [54:48<49:45,  1.73s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1909/3636 [54:48<49:43,  1.73s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1909/3636 [54:49<49:43,  1.73s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1910/3636 [54:49<49:42,  1.73s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1910/3636 [54:51<49:42,  1.73s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1911/3636 [54:51<49:39,  1.73s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1911/3636 [54:53<49:39,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1912/3636 [54:53<49:39,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1912/3636 [54:55<49:39,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1913/3636 [54:55<49:38,  1.73s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1913/3636 [54:56<49:38,  1.73s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1914/3636 [54:56<49:36,  1.73s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1914/3636 [54:58<49:36,  1.73s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1915/3636 [54:58<49:34,  1.73s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1915/3636 [55:00<49:34,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1916/3636 [55:00<49:32,  1.73s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1916/3636 [55:02<49:32,  1.73s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1917/3636 [55:02<49:31,  1.73s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1917/3636 [55:03<49:31,  1.73s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1918/3636 [55:03<49:30,  1.73s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1918/3636 [55:05<49:30,  1.73s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1919/3636 [55:05<49:27,  1.73s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1919/3636 [55:07<49:27,  1.73s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1920/3636 [55:07<49:26,  1.73s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1920/3636 [55:09<49:26,  1.73s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1921/3636 [55:09<49:24,  1.73s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1921/3636 [55:10<49:24,  1.73s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1922/3636 [55:10<49:21,  1.73s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1922/3636 [55:12<49:21,  1.73s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1923/3636 [55:12<49:20,  1.73s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1923/3636 [55:14<49:20,  1.73s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1924/3636 [55:14<49:19,  1.73s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1924/3636 [55:15<49:19,  1.73s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1925/3636 [55:15<49:16,  1.73s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1925/3636 [55:17<49:16,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1926/3636 [55:17<49:15,  1.73s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1926/3636 [55:19<49:15,  1.73s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1927/3636 [55:19<49:12,  1.73s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1927/3636 [55:21<49:12,  1.73s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1928/3636 [55:21<49:10,  1.73s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1928/3636 [55:22<49:10,  1.73s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1929/3636 [55:22<49:09,  1.73s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1929/3636 [55:24<49:09,  1.73s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1930/3636 [55:24<49:05,  1.73s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1930/3636 [55:26<49:05,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1931/3636 [55:26<49:03,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1931/3636 [55:28<49:03,  1.73s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1932/3636 [55:28<49:02,  1.73s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1932/3636 [55:29<49:02,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1933/3636 [55:29<49:00,  1.73s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1933/3636 [55:31<49:00,  1.73s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1934/3636 [55:31<48:58,  1.73s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1934/3636 [55:33<48:58,  1.73s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1935/3636 [55:33<48:57,  1.73s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1935/3636 [55:34<48:57,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1936/3636 [55:34<48:55,  1.73s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1936/3636 [55:36<48:55,  1.73s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1937/3636 [55:36<48:54,  1.73s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1937/3636 [55:38<48:54,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1938/3636 [55:38<48:52,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1938/3636 [55:40<48:52,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1939/3636 [55:40<48:50,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1939/3636 [55:41<48:50,  1.73s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1940/3636 [55:41<48:49,  1.73s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1940/3636 [55:43<48:49,  1.73s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1941/3636 [55:43<48:46,  1.73s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1941/3636 [55:45<48:46,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1942/3636 [55:45<48:44,  1.73s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1942/3636 [55:47<48:44,  1.73s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1943/3636 [55:47<48:42,  1.73s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1943/3636 [55:48<48:42,  1.73s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1944/3636 [55:48<48:40,  1.73s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1944/3636 [55:50<48:40,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1945/3636 [55:50<48:38,  1.73s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 1945/3636 [55:52<48:38,  1.73s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1946/3636 [55:52<48:36,  1.73s/it, training_loss=0.292]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  54%|█████▎    | 1946/3636 [55:53<48:36,  1.73s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1947/3636 [55:53<48:33,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1947/3636 [55:55<48:33,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1948/3636 [55:55<48:30,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1948/3636 [55:57<48:30,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1949/3636 [55:57<48:28,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1949/3636 [55:59<48:28,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1950/3636 [55:59<48:25,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1950/3636 [56:00<48:25,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1951/3636 [56:00<48:23,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1951/3636 [56:02<48:23,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1952/3636 [56:02<48:21,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1952/3636 [56:04<48:21,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1953/3636 [56:04<48:20,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1953/3636 [56:05<48:20,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1954/3636 [56:05<48:18,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 1954/3636 [56:07<48:18,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1955/3636 [56:07<48:16,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1955/3636 [56:09<48:16,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1956/3636 [56:09<48:14,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1956/3636 [56:11<48:14,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1957/3636 [56:11<48:10,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1957/3636 [56:12<48:10,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1958/3636 [56:12<48:08,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1958/3636 [56:14<48:08,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1959/3636 [56:14<48:06,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1959/3636 [56:16<48:06,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1960/3636 [56:16<48:04,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1960/3636 [56:18<48:04,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1961/3636 [56:18<48:01,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1961/3636 [56:19<48:01,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1962/3636 [56:19<48:00,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1962/3636 [56:21<48:00,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1963/3636 [56:21<47:58,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1963/3636 [56:23<47:58,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1964/3636 [56:23<47:58,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1964/3636 [56:24<47:58,  1.72s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1965/3636 [56:24<47:55,  1.72s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1965/3636 [56:26<47:55,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1966/3636 [56:26<47:52,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1966/3636 [56:28<47:52,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1967/3636 [56:28<47:50,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1967/3636 [56:30<47:50,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1968/3636 [56:30<47:48,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1968/3636 [56:31<47:48,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1969/3636 [56:31<47:46,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1969/3636 [56:33<47:46,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1970/3636 [56:33<47:44,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1970/3636 [56:35<47:44,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1971/3636 [56:35<47:42,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1971/3636 [56:36<47:42,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1972/3636 [56:36<47:40,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1972/3636 [56:38<47:40,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1973/3636 [56:38<47:39,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1973/3636 [56:40<47:39,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1974/3636 [56:40<47:38,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1974/3636 [56:42<47:38,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1975/3636 [56:42<47:36,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1975/3636 [56:43<47:36,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1976/3636 [56:43<47:33,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1976/3636 [56:45<47:33,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1977/3636 [56:45<47:31,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1977/3636 [56:47<47:31,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1978/3636 [56:47<47:28,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1978/3636 [56:48<47:28,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1979/3636 [56:48<47:26,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1979/3636 [56:50<47:26,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1980/3636 [56:50<47:24,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1980/3636 [56:52<47:24,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1981/3636 [56:52<47:22,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 1981/3636 [56:54<47:22,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1982/3636 [56:54<47:21,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1982/3636 [56:55<47:21,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1983/3636 [56:55<47:19,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1983/3636 [56:57<47:19,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1984/3636 [56:57<47:17,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1984/3636 [56:59<47:17,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1985/3636 [56:59<47:16,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1985/3636 [57:00<47:16,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1986/3636 [57:00<47:15,  1.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1986/3636 [57:02<47:15,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1987/3636 [57:02<47:12,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1987/3636 [57:04<47:12,  1.72s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1988/3636 [57:04<47:10,  1.72s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1988/3636 [57:06<47:10,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1989/3636 [57:06<47:08,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1989/3636 [57:07<47:08,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1990/3636 [57:07<47:06,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1990/3636 [57:09<47:06,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1991/3636 [57:09<47:05,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1991/3636 [57:11<47:05,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1992/3636 [57:11<47:03,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1992/3636 [57:12<47:03,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1993/3636 [57:13<47:02,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1993/3636 [57:14<47:02,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1994/3636 [57:14<47:00,  1.72s/it, training_loss=0.265]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  55%|█████▍    | 1994/3636 [57:16<47:00,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1995/3636 [57:16<46:59,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1995/3636 [57:18<46:59,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1996/3636 [57:18<46:57,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1996/3636 [57:19<46:57,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1997/3636 [57:19<46:55,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1997/3636 [57:21<46:55,  1.72s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1998/3636 [57:21<46:54,  1.72s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1998/3636 [57:23<46:54,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1999/3636 [57:23<46:52,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 1999/3636 [57:25<46:52,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2000/3636 [57:25<46:52,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2000/3636 [57:26<46:52,  1.72s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2001/3636 [57:26<46:50,  1.72s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2001/3636 [57:28<46:50,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2002/3636 [57:28<46:48,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2002/3636 [57:30<46:48,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2003/3636 [57:30<46:46,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2003/3636 [57:31<46:46,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2004/3636 [57:31<46:44,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2004/3636 [57:33<46:44,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2005/3636 [57:33<46:42,  1.72s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2005/3636 [57:35<46:42,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2006/3636 [57:35<46:42,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2006/3636 [57:37<46:42,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2007/3636 [57:37<46:41,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2007/3636 [57:38<46:41,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2008/3636 [57:38<46:39,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2008/3636 [57:40<46:39,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2009/3636 [57:40<46:38,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2009/3636 [57:42<46:38,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2010/3636 [57:42<46:36,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2010/3636 [57:43<46:36,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2011/3636 [57:43<46:34,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2011/3636 [57:45<46:34,  1.72s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2012/3636 [57:45<46:34,  1.72s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2012/3636 [57:47<46:34,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2013/3636 [57:47<46:32,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2013/3636 [57:49<46:32,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2014/3636 [57:49<46:31,  1.72s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2014/3636 [57:50<46:31,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2015/3636 [57:50<46:29,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2015/3636 [57:52<46:29,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2016/3636 [57:52<46:26,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2016/3636 [57:54<46:26,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2017/3636 [57:54<46:24,  1.72s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 2017/3636 [57:55<46:24,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2018/3636 [57:55<46:21,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2018/3636 [57:57<46:21,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2019/3636 [57:57<46:20,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2019/3636 [57:59<46:20,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2020/3636 [57:59<46:18,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2020/3636 [58:01<46:18,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2021/3636 [58:01<46:16,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2021/3636 [58:02<46:16,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2022/3636 [58:02<46:13,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2022/3636 [58:04<46:13,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2023/3636 [58:04<46:12,  1.72s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2023/3636 [58:06<46:12,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2024/3636 [58:06<46:10,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2024/3636 [58:08<46:10,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2025/3636 [58:08<46:09,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2025/3636 [58:09<46:09,  1.72s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2026/3636 [58:09<46:07,  1.72s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2026/3636 [58:11<46:07,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2027/3636 [58:11<46:06,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2027/3636 [58:13<46:06,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2028/3636 [58:13<46:05,  1.72s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2028/3636 [58:14<46:05,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2029/3636 [58:14<46:04,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2029/3636 [58:16<46:04,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2030/3636 [58:16<46:02,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2030/3636 [58:18<46:02,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2031/3636 [58:18<46:00,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2031/3636 [58:20<46:00,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2032/3636 [58:20<45:58,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2032/3636 [58:21<45:58,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2033/3636 [58:21<45:58,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2033/3636 [58:23<45:58,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2034/3636 [58:23<45:56,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2034/3636 [58:25<45:56,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2035/3636 [58:25<45:53,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2035/3636 [58:26<45:53,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2036/3636 [58:26<45:51,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2036/3636 [58:28<45:51,  1.72s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2037/3636 [58:28<45:48,  1.72s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2037/3636 [58:30<45:48,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2038/3636 [58:30<45:47,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2038/3636 [58:32<45:47,  1.72s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2039/3636 [58:32<45:45,  1.72s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2039/3636 [58:33<45:45,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2040/3636 [58:33<45:44,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2040/3636 [58:35<45:44,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2041/3636 [58:35<45:44,  1.72s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2041/3636 [58:37<45:44,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2042/3636 [58:37<45:43,  1.72s/it, training_loss=0.307]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  56%|█████▌    | 2042/3636 [58:38<45:43,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2043/3636 [58:38<45:40,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2043/3636 [58:40<45:40,  1.72s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2044/3636 [58:40<45:39,  1.72s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2044/3636 [58:42<45:39,  1.72s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2045/3636 [58:42<45:37,  1.72s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 2045/3636 [58:44<45:37,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2046/3636 [58:44<45:35,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2046/3636 [58:45<45:35,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2047/3636 [58:45<45:32,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2047/3636 [58:47<45:32,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2048/3636 [58:47<45:30,  1.72s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2048/3636 [58:49<45:30,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2049/3636 [58:49<45:27,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2049/3636 [58:51<45:27,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2050/3636 [58:51<45:25,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2050/3636 [58:52<45:25,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2051/3636 [58:52<45:23,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2051/3636 [58:54<45:23,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2052/3636 [58:54<45:23,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2052/3636 [58:56<45:23,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2053/3636 [58:56<45:21,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2053/3636 [58:57<45:21,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2054/3636 [58:57<45:21,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 2054/3636 [58:59<45:21,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2055/3636 [58:59<45:18,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2055/3636 [59:01<45:18,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2056/3636 [59:01<45:16,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2056/3636 [59:03<45:16,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2057/3636 [59:03<45:13,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2057/3636 [59:04<45:13,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2058/3636 [59:04<45:11,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2058/3636 [59:06<45:11,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2059/3636 [59:06<45:10,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2059/3636 [59:08<45:10,  1.72s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2060/3636 [59:08<45:09,  1.72s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2060/3636 [59:09<45:09,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2061/3636 [59:09<45:07,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2061/3636 [59:11<45:07,  1.72s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2062/3636 [59:11<45:05,  1.72s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2062/3636 [59:13<45:05,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2063/3636 [59:13<45:04,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2063/3636 [59:15<45:04,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2064/3636 [59:15<45:02,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2064/3636 [59:16<45:02,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2065/3636 [59:16<45:00,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2065/3636 [59:18<45:00,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2066/3636 [59:18<44:59,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2066/3636 [59:20<44:59,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2067/3636 [59:20<44:58,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2067/3636 [59:21<44:58,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2068/3636 [59:21<44:57,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2068/3636 [59:23<44:57,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2069/3636 [59:23<44:54,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2069/3636 [59:25<44:54,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2070/3636 [59:25<44:52,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2070/3636 [59:27<44:52,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2071/3636 [59:27<44:50,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2071/3636 [59:28<44:50,  1.72s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2072/3636 [59:28<44:49,  1.72s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2072/3636 [59:30<44:49,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2073/3636 [59:30<44:47,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2073/3636 [59:32<44:47,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2074/3636 [59:32<44:44,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2074/3636 [59:33<44:44,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2075/3636 [59:33<44:42,  1.72s/it, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2075/3636 [59:35<44:42,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2076/3636 [59:35<44:39,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2076/3636 [59:37<44:39,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2077/3636 [59:37<44:37,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2077/3636 [59:39<44:37,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2078/3636 [59:39<44:34,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2078/3636 [59:40<44:34,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2079/3636 [59:40<44:34,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2079/3636 [59:42<44:34,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2080/3636 [59:42<44:32,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2080/3636 [59:44<44:32,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2081/3636 [59:44<44:30,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2081/3636 [59:46<44:30,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2082/3636 [59:46<44:28,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2082/3636 [59:47<44:28,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2083/3636 [59:47<44:27,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2083/3636 [59:49<44:27,  1.72s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2084/3636 [59:49<44:25,  1.72s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2084/3636 [59:51<44:25,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2085/3636 [59:51<44:24,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2085/3636 [59:52<44:24,  1.72s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2086/3636 [59:52<44:24,  1.72s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2086/3636 [59:54<44:24,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2087/3636 [59:54<44:21,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2087/3636 [59:56<44:21,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2088/3636 [59:56<44:19,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2088/3636 [59:58<44:19,  1.72s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2089/3636 [59:58<44:17,  1.72s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2089/3636 [59:59<44:17,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 2090/3636 [59:59<44:16,  1.72s/it, training_loss=0.229]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  57%|█████▋    | 2090/3636 [1:00:01<44:16,  1.72s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2091/3636 [1:00:01<44:15,  1.72s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2091/3636 [1:00:03<44:15,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2092/3636 [1:00:03<44:13,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2092/3636 [1:00:04<44:13,  1.72s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2093/3636 [1:00:04<44:12,  1.72s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2093/3636 [1:00:06<44:12,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2094/3636 [1:00:06<44:10,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2094/3636 [1:00:08<44:10,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2095/3636 [1:00:08<44:09,  1.72s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2095/3636 [1:00:10<44:09,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2096/3636 [1:00:10<44:07,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2096/3636 [1:00:11<44:07,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2097/3636 [1:00:11<44:04,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2097/3636 [1:00:13<44:04,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2098/3636 [1:00:13<44:03,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2098/3636 [1:00:15<44:03,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2099/3636 [1:00:15<44:02,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2099/3636 [1:00:16<44:02,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2100/3636 [1:00:16<44:00,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2100/3636 [1:00:18<44:00,  1.72s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2101/3636 [1:00:18<43:57,  1.72s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2101/3636 [1:00:20<43:57,  1.72s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2102/3636 [1:00:20<43:55,  1.72s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2102/3636 [1:00:22<43:55,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2103/3636 [1:00:22<43:55,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2103/3636 [1:00:23<43:55,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2104/3636 [1:00:23<43:53,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2104/3636 [1:00:25<43:53,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2105/3636 [1:00:25<43:50,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2105/3636 [1:00:27<43:50,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2106/3636 [1:00:27<43:48,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2106/3636 [1:00:28<43:48,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2107/3636 [1:00:28<43:48,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2107/3636 [1:00:30<43:48,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2108/3636 [1:00:30<43:45,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2108/3636 [1:00:32<43:45,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2109/3636 [1:00:32<43:43,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2109/3636 [1:00:34<43:43,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2110/3636 [1:00:34<43:42,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2110/3636 [1:00:35<43:42,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2111/3636 [1:00:35<43:41,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2111/3636 [1:00:37<43:41,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2112/3636 [1:00:37<43:39,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2112/3636 [1:00:39<43:39,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2113/3636 [1:00:39<43:38,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2113/3636 [1:00:41<43:38,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2114/3636 [1:00:41<43:36,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2114/3636 [1:00:42<43:36,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2115/3636 [1:00:42<43:34,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2115/3636 [1:00:44<43:34,  1.72s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2116/3636 [1:00:44<43:33,  1.72s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2116/3636 [1:00:46<43:33,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2117/3636 [1:00:46<43:30,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2117/3636 [1:00:47<43:30,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2118/3636 [1:00:47<43:29,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2118/3636 [1:00:49<43:29,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2119/3636 [1:00:49<43:27,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2119/3636 [1:00:51<43:27,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2120/3636 [1:00:51<43:25,  1.72s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2120/3636 [1:00:53<43:25,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2121/3636 [1:00:53<43:24,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2121/3636 [1:00:54<43:24,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2122/3636 [1:00:54<43:23,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2122/3636 [1:00:56<43:23,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2123/3636 [1:00:56<43:21,  1.72s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2123/3636 [1:00:58<43:21,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2124/3636 [1:00:58<43:20,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2124/3636 [1:00:59<43:20,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2125/3636 [1:00:59<43:18,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2125/3636 [1:01:01<43:18,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2126/3636 [1:01:01<43:16,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2126/3636 [1:01:03<43:16,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2127/3636 [1:01:03<43:16,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 2127/3636 [1:01:05<43:16,  1.72s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2128/3636 [1:01:05<43:15,  1.72s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2128/3636 [1:01:06<43:15,  1.72s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2129/3636 [1:01:06<43:13,  1.72s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2129/3636 [1:01:08<43:13,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2130/3636 [1:01:08<43:11,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2130/3636 [1:01:10<43:11,  1.72s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2131/3636 [1:01:10<43:10,  1.72s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2131/3636 [1:01:11<43:10,  1.72s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2132/3636 [1:01:11<43:08,  1.72s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2132/3636 [1:01:13<43:08,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2133/3636 [1:01:13<43:06,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2133/3636 [1:01:15<43:06,  1.72s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2134/3636 [1:01:15<43:04,  1.72s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2134/3636 [1:01:17<43:04,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2135/3636 [1:01:17<43:03,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2135/3636 [1:01:18<43:03,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2136/3636 [1:01:18<43:00,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 2136/3636 [1:01:20<43:00,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2137/3636 [1:01:20<42:59,  1.72s/it, training_loss=0.308]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  59%|█████▉    | 2137/3636 [1:01:22<42:59,  1.72s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2138/3636 [1:01:22<42:58,  1.72s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2138/3636 [1:01:24<42:58,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2139/3636 [1:01:24<42:56,  1.72s/it, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2139/3636 [1:01:25<42:56,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2140/3636 [1:01:25<42:55,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2140/3636 [1:01:27<42:55,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2141/3636 [1:01:27<42:54,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2141/3636 [1:01:29<42:54,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2142/3636 [1:01:29<42:54,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2142/3636 [1:01:30<42:54,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2143/3636 [1:01:30<42:52,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2143/3636 [1:01:32<42:52,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2144/3636 [1:01:32<42:50,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2144/3636 [1:01:34<42:50,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2145/3636 [1:01:34<42:49,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2145/3636 [1:01:36<42:49,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2146/3636 [1:01:36<42:47,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2146/3636 [1:01:37<42:47,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2147/3636 [1:01:37<42:46,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2147/3636 [1:01:39<42:46,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2148/3636 [1:01:39<42:44,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2148/3636 [1:01:41<42:44,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2149/3636 [1:01:41<42:43,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2149/3636 [1:01:42<42:43,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2150/3636 [1:01:42<42:41,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2150/3636 [1:01:44<42:41,  1.72s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2151/3636 [1:01:44<42:39,  1.72s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2151/3636 [1:01:46<42:39,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2152/3636 [1:01:46<42:37,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2152/3636 [1:01:48<42:37,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2153/3636 [1:01:48<42:35,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2153/3636 [1:01:49<42:35,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2154/3636 [1:01:49<42:34,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2154/3636 [1:01:51<42:34,  1.72s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2155/3636 [1:01:51<42:31,  1.72s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2155/3636 [1:01:53<42:31,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2156/3636 [1:01:53<42:30,  1.72s/it, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2156/3636 [1:01:55<42:30,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2157/3636 [1:01:55<42:29,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2157/3636 [1:01:56<42:29,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2158/3636 [1:01:56<42:28,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2158/3636 [1:01:58<42:28,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2159/3636 [1:01:58<42:27,  1.73s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2159/3636 [1:02:00<42:27,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2160/3636 [1:02:00<42:27,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2160/3636 [1:02:01<42:27,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2161/3636 [1:02:01<42:25,  1.73s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2161/3636 [1:02:03<42:25,  1.73s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2162/3636 [1:02:03<42:22,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2162/3636 [1:02:05<42:22,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2163/3636 [1:02:05<42:21,  1.73s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 2163/3636 [1:02:07<42:21,  1.73s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2164/3636 [1:02:07<42:18,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2164/3636 [1:02:08<42:18,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2165/3636 [1:02:08<42:17,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2165/3636 [1:02:10<42:17,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2166/3636 [1:02:10<42:18,  1.73s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2166/3636 [1:02:12<42:18,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2167/3636 [1:02:12<42:17,  1.73s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2167/3636 [1:02:14<42:17,  1.73s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2168/3636 [1:02:14<42:15,  1.73s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2168/3636 [1:02:15<42:15,  1.73s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2169/3636 [1:02:15<42:13,  1.73s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2169/3636 [1:02:17<42:13,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2170/3636 [1:02:17<42:10,  1.73s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2170/3636 [1:02:19<42:10,  1.73s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2171/3636 [1:02:19<42:09,  1.73s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2171/3636 [1:02:20<42:09,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2172/3636 [1:02:20<42:08,  1.73s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2172/3636 [1:02:22<42:08,  1.73s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2173/3636 [1:02:22<42:05,  1.73s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2173/3636 [1:02:24<42:05,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2174/3636 [1:02:24<42:03,  1.73s/it, training_loss=0.285]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2174/3636 [1:02:26<42:03,  1.73s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2175/3636 [1:02:26<42:01,  1.73s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2175/3636 [1:02:27<42:01,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2176/3636 [1:02:27<41:59,  1.73s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2176/3636 [1:02:29<41:59,  1.73s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2177/3636 [1:02:29<41:56,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2177/3636 [1:02:31<41:56,  1.72s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2178/3636 [1:02:31<41:55,  1.73s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2178/3636 [1:02:33<41:55,  1.73s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2179/3636 [1:02:33<41:53,  1.73s/it, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2179/3636 [1:02:34<41:53,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2180/3636 [1:02:34<41:51,  1.73s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2180/3636 [1:02:36<41:51,  1.73s/it, training_loss=0.179]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2181/3636 [1:02:36<41:50,  1.73s/it, training_loss=0.179]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 2181/3636 [1:02:38<41:50,  1.73s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2182/3636 [1:02:38<41:48,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2182/3636 [1:02:39<41:48,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2183/3636 [1:02:39<41:45,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2183/3636 [1:02:41<41:45,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2184/3636 [1:02:41<41:43,  1.72s/it, training_loss=0.302]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  60%|██████    | 2184/3636 [1:02:43<41:43,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2185/3636 [1:02:43<41:42,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2185/3636 [1:02:45<41:42,  1.72s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2186/3636 [1:02:45<41:42,  1.73s/it, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2186/3636 [1:02:46<41:42,  1.73s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2187/3636 [1:02:46<41:40,  1.73s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2187/3636 [1:02:48<41:40,  1.73s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2188/3636 [1:02:48<41:39,  1.73s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2188/3636 [1:02:50<41:39,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2189/3636 [1:02:50<41:37,  1.73s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2189/3636 [1:02:51<41:37,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2190/3636 [1:02:51<41:35,  1.73s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2190/3636 [1:02:53<41:35,  1.73s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2191/3636 [1:02:53<41:32,  1.73s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2191/3636 [1:02:55<41:32,  1.73s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2192/3636 [1:02:55<41:30,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2192/3636 [1:02:57<41:30,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2193/3636 [1:02:57<41:28,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2193/3636 [1:02:58<41:28,  1.72s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2194/3636 [1:02:58<41:25,  1.72s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2194/3636 [1:03:00<41:25,  1.72s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2195/3636 [1:03:00<41:24,  1.72s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2195/3636 [1:03:02<41:24,  1.72s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2196/3636 [1:03:02<41:22,  1.72s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2196/3636 [1:03:04<41:22,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2197/3636 [1:03:04<41:20,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2197/3636 [1:03:05<41:20,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2198/3636 [1:03:05<41:19,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2198/3636 [1:03:07<41:19,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2199/3636 [1:03:07<41:17,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  60%|██████    | 2199/3636 [1:03:09<41:17,  1.72s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2200/3636 [1:03:09<41:16,  1.72s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2200/3636 [1:03:10<41:16,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2201/3636 [1:03:10<41:14,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2201/3636 [1:03:12<41:14,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2202/3636 [1:03:12<41:13,  1.73s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2202/3636 [1:03:14<41:13,  1.73s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2203/3636 [1:03:14<41:11,  1.72s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2203/3636 [1:03:16<41:11,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2204/3636 [1:03:16<41:09,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2204/3636 [1:03:17<41:09,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2205/3636 [1:03:17<41:07,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2205/3636 [1:03:19<41:07,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2206/3636 [1:03:19<41:06,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2206/3636 [1:03:21<41:06,  1.72s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2207/3636 [1:03:21<41:03,  1.72s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2207/3636 [1:03:23<41:03,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2208/3636 [1:03:23<41:01,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2208/3636 [1:03:24<41:01,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2209/3636 [1:03:24<40:59,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2209/3636 [1:03:26<40:59,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2210/3636 [1:03:26<40:57,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2210/3636 [1:03:28<40:57,  1.72s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2211/3636 [1:03:28<40:55,  1.72s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2211/3636 [1:03:29<40:55,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2212/3636 [1:03:29<40:54,  1.72s/it, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2212/3636 [1:03:31<40:54,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2213/3636 [1:03:31<40:53,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2213/3636 [1:03:33<40:53,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2214/3636 [1:03:33<40:51,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2214/3636 [1:03:35<40:51,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2215/3636 [1:03:35<40:48,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2215/3636 [1:03:36<40:48,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2216/3636 [1:03:36<40:45,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2216/3636 [1:03:38<40:45,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2217/3636 [1:03:38<40:43,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2217/3636 [1:03:40<40:43,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2218/3636 [1:03:40<40:43,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2218/3636 [1:03:41<40:43,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2219/3636 [1:03:41<40:42,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2219/3636 [1:03:43<40:42,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2220/3636 [1:03:43<40:40,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2220/3636 [1:03:45<40:40,  1.72s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2221/3636 [1:03:45<40:38,  1.72s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2221/3636 [1:03:47<40:38,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2222/3636 [1:03:47<40:36,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2222/3636 [1:03:48<40:36,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2223/3636 [1:03:48<40:34,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2223/3636 [1:03:50<40:34,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2224/3636 [1:03:50<40:32,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2224/3636 [1:03:52<40:32,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2225/3636 [1:03:52<40:30,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2225/3636 [1:03:54<40:30,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2226/3636 [1:03:54<40:28,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2226/3636 [1:03:55<40:28,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2227/3636 [1:03:55<40:25,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  61%|██████    | 2227/3636 [1:03:57<40:25,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2228/3636 [1:03:57<40:23,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2228/3636 [1:03:59<40:23,  1.72s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2229/3636 [1:03:59<40:21,  1.72s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2229/3636 [1:04:00<40:21,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2230/3636 [1:04:00<40:19,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2230/3636 [1:04:02<40:19,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2231/3636 [1:04:02<40:17,  1.72s/it, training_loss=0.266]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  61%|██████▏   | 2231/3636 [1:04:04<40:17,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2232/3636 [1:04:04<40:15,  1.72s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2232/3636 [1:04:06<40:15,  1.72s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2233/3636 [1:04:06<40:13,  1.72s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2233/3636 [1:04:07<40:13,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2234/3636 [1:04:07<40:11,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2234/3636 [1:04:09<40:11,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2235/3636 [1:04:09<40:09,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2235/3636 [1:04:11<40:09,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2236/3636 [1:04:11<40:08,  1.72s/it, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 2236/3636 [1:04:12<40:08,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2237/3636 [1:04:12<40:05,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2237/3636 [1:04:14<40:05,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2238/3636 [1:04:14<40:03,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2238/3636 [1:04:16<40:03,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2239/3636 [1:04:16<40:02,  1.72s/it, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2239/3636 [1:04:18<40:02,  1.72s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2240/3636 [1:04:18<39:59,  1.72s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2240/3636 [1:04:19<39:59,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2241/3636 [1:04:19<39:57,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2241/3636 [1:04:21<39:57,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2242/3636 [1:04:21<39:54,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2242/3636 [1:04:23<39:54,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2243/3636 [1:04:23<39:53,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2243/3636 [1:04:24<39:53,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2244/3636 [1:04:24<39:50,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2244/3636 [1:04:26<39:50,  1.72s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2245/3636 [1:04:26<39:48,  1.72s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2245/3636 [1:04:28<39:48,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2246/3636 [1:04:28<39:46,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2246/3636 [1:04:30<39:46,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2247/3636 [1:04:30<39:45,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2247/3636 [1:04:31<39:45,  1.72s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2248/3636 [1:04:31<39:42,  1.72s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2248/3636 [1:04:33<39:42,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2249/3636 [1:04:33<39:40,  1.72s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2249/3636 [1:04:35<39:40,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2250/3636 [1:04:35<39:39,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2250/3636 [1:04:36<39:39,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2251/3636 [1:04:37<39:36,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2251/3636 [1:04:38<39:36,  1.72s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2252/3636 [1:04:38<39:35,  1.72s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2252/3636 [1:04:40<39:35,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2253/3636 [1:04:40<39:33,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2253/3636 [1:04:42<39:33,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2254/3636 [1:04:42<39:31,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2254/3636 [1:04:43<39:31,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2255/3636 [1:04:43<39:29,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2255/3636 [1:04:45<39:29,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2256/3636 [1:04:45<39:27,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2256/3636 [1:04:47<39:27,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2257/3636 [1:04:47<39:27,  1.72s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2257/3636 [1:04:49<39:27,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2258/3636 [1:04:49<39:26,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2258/3636 [1:04:50<39:26,  1.72s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2259/3636 [1:04:50<39:23,  1.72s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2259/3636 [1:04:52<39:23,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2260/3636 [1:04:52<39:21,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2260/3636 [1:04:54<39:21,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2261/3636 [1:04:54<39:19,  1.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2261/3636 [1:04:55<39:19,  1.72s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2262/3636 [1:04:55<39:19,  1.72s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2262/3636 [1:04:57<39:19,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2263/3636 [1:04:57<39:18,  1.72s/it, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2263/3636 [1:04:59<39:18,  1.72s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2264/3636 [1:04:59<39:15,  1.72s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2264/3636 [1:05:01<39:15,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2265/3636 [1:05:01<39:13,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2265/3636 [1:05:02<39:13,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2266/3636 [1:05:02<39:10,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2266/3636 [1:05:04<39:10,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2267/3636 [1:05:04<39:08,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2267/3636 [1:05:06<39:08,  1.72s/it, training_loss=0.163]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2268/3636 [1:05:06<39:07,  1.72s/it, training_loss=0.163]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2268/3636 [1:05:07<39:07,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2269/3636 [1:05:07<39:07,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2269/3636 [1:05:09<39:07,  1.72s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2270/3636 [1:05:09<39:04,  1.72s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2270/3636 [1:05:11<39:04,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2271/3636 [1:05:11<39:03,  1.72s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2271/3636 [1:05:13<39:03,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2272/3636 [1:05:13<39:01,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 2272/3636 [1:05:14<39:01,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2273/3636 [1:05:14<38:59,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2273/3636 [1:05:16<38:59,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2274/3636 [1:05:16<38:59,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2274/3636 [1:05:18<38:59,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2275/3636 [1:05:18<38:57,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2275/3636 [1:05:19<38:57,  1.72s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2276/3636 [1:05:19<38:56,  1.72s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2276/3636 [1:05:21<38:56,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2277/3636 [1:05:21<38:55,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2277/3636 [1:05:23<38:55,  1.72s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2278/3636 [1:05:23<38:54,  1.72s/it, training_loss=0.293]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  63%|██████▎   | 2278/3636 [1:05:25<38:54,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2279/3636 [1:05:25<38:51,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2279/3636 [1:05:26<38:51,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2280/3636 [1:05:26<38:49,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2280/3636 [1:05:28<38:49,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2281/3636 [1:05:28<38:48,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2281/3636 [1:05:30<38:48,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2282/3636 [1:05:30<38:46,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2282/3636 [1:05:31<38:46,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2283/3636 [1:05:31<38:44,  1.72s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2283/3636 [1:05:33<38:44,  1.72s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2284/3636 [1:05:33<38:43,  1.72s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2284/3636 [1:05:35<38:43,  1.72s/it, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2285/3636 [1:05:35<38:42,  1.72s/it, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2285/3636 [1:05:37<38:42,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2286/3636 [1:05:37<38:40,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2286/3636 [1:05:38<38:40,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2287/3636 [1:05:38<38:39,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2287/3636 [1:05:40<38:39,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2288/3636 [1:05:40<38:38,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2288/3636 [1:05:42<38:38,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2289/3636 [1:05:42<38:35,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2289/3636 [1:05:43<38:35,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2290/3636 [1:05:43<38:34,  1.72s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2290/3636 [1:05:45<38:34,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2291/3636 [1:05:45<38:32,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2291/3636 [1:05:47<38:32,  1.72s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2292/3636 [1:05:47<38:30,  1.72s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2292/3636 [1:05:49<38:30,  1.72s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2293/3636 [1:05:49<38:29,  1.72s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2293/3636 [1:05:50<38:29,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2294/3636 [1:05:50<38:27,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2294/3636 [1:05:52<38:27,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2295/3636 [1:05:52<38:24,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2295/3636 [1:05:54<38:24,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2296/3636 [1:05:54<38:23,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2296/3636 [1:05:56<38:23,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2297/3636 [1:05:56<38:21,  1.72s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2297/3636 [1:05:57<38:21,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2298/3636 [1:05:57<38:19,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2298/3636 [1:05:59<38:19,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2299/3636 [1:05:59<38:18,  1.72s/it, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2299/3636 [1:06:01<38:18,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2300/3636 [1:06:01<38:16,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2300/3636 [1:06:02<38:16,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2301/3636 [1:06:02<38:14,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2301/3636 [1:06:04<38:14,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2302/3636 [1:06:04<38:13,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2302/3636 [1:06:06<38:13,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2303/3636 [1:06:06<38:11,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2303/3636 [1:06:08<38:11,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2304/3636 [1:06:08<38:10,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2304/3636 [1:06:09<38:10,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2305/3636 [1:06:09<38:09,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2305/3636 [1:06:11<38:09,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2306/3636 [1:06:11<38:07,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2306/3636 [1:06:13<38:07,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2307/3636 [1:06:13<38:07,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2307/3636 [1:06:14<38:07,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2308/3636 [1:06:14<38:05,  1.72s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 2308/3636 [1:06:16<38:05,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2309/3636 [1:06:16<38:04,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2309/3636 [1:06:18<38:04,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2310/3636 [1:06:18<38:00,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2310/3636 [1:06:20<38:00,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2311/3636 [1:06:20<37:58,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2311/3636 [1:06:21<37:58,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2312/3636 [1:06:21<37:57,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2312/3636 [1:06:23<37:57,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2313/3636 [1:06:23<37:55,  1.72s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2313/3636 [1:06:25<37:55,  1.72s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2314/3636 [1:06:25<37:54,  1.72s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2314/3636 [1:06:26<37:54,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2315/3636 [1:06:26<37:52,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2315/3636 [1:06:28<37:52,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2316/3636 [1:06:28<37:52,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2316/3636 [1:06:30<37:52,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2317/3636 [1:06:30<37:50,  1.72s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 2317/3636 [1:06:32<37:50,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2318/3636 [1:06:32<37:48,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2318/3636 [1:06:33<37:48,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2319/3636 [1:06:33<37:46,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2319/3636 [1:06:35<37:46,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2320/3636 [1:06:35<37:45,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2320/3636 [1:06:37<37:45,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2321/3636 [1:06:37<37:43,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2321/3636 [1:06:39<37:43,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2322/3636 [1:06:39<37:40,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2322/3636 [1:06:40<37:40,  1.72s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2323/3636 [1:06:40<37:38,  1.72s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2323/3636 [1:06:42<37:38,  1.72s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2324/3636 [1:06:42<37:37,  1.72s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2324/3636 [1:06:44<37:37,  1.72s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2325/3636 [1:06:44<37:34,  1.72s/it, training_loss=0.258]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  64%|██████▍   | 2325/3636 [1:06:45<37:34,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2326/3636 [1:06:45<37:33,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2326/3636 [1:06:47<37:33,  1.72s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2327/3636 [1:06:47<37:31,  1.72s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2327/3636 [1:06:49<37:31,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2328/3636 [1:06:49<37:30,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2328/3636 [1:06:51<37:30,  1.72s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2329/3636 [1:06:51<37:28,  1.72s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2329/3636 [1:06:52<37:28,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2330/3636 [1:06:52<37:26,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2330/3636 [1:06:54<37:26,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2331/3636 [1:06:54<37:25,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2331/3636 [1:06:56<37:25,  1.72s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2332/3636 [1:06:56<37:23,  1.72s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2332/3636 [1:06:57<37:23,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2333/3636 [1:06:57<37:22,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2333/3636 [1:06:59<37:22,  1.72s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2334/3636 [1:06:59<37:20,  1.72s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2334/3636 [1:07:01<37:20,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2335/3636 [1:07:01<37:18,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2335/3636 [1:07:03<37:18,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2336/3636 [1:07:03<37:17,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2336/3636 [1:07:04<37:17,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2337/3636 [1:07:04<37:15,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2337/3636 [1:07:06<37:15,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2338/3636 [1:07:06<37:13,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2338/3636 [1:07:08<37:13,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2339/3636 [1:07:08<37:12,  1.72s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2339/3636 [1:07:10<37:12,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2340/3636 [1:07:10<37:10,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2340/3636 [1:07:11<37:10,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2341/3636 [1:07:11<37:08,  1.72s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2341/3636 [1:07:13<37:08,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2342/3636 [1:07:13<37:07,  1.72s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2342/3636 [1:07:15<37:07,  1.72s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2343/3636 [1:07:15<37:04,  1.72s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2343/3636 [1:07:16<37:04,  1.72s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2344/3636 [1:07:16<37:03,  1.72s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2344/3636 [1:07:18<37:03,  1.72s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2345/3636 [1:07:18<37:01,  1.72s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 2345/3636 [1:07:20<37:01,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2346/3636 [1:07:20<37:00,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2346/3636 [1:07:22<37:00,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2347/3636 [1:07:22<36:58,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2347/3636 [1:07:23<36:58,  1.72s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2348/3636 [1:07:23<36:56,  1.72s/it, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2348/3636 [1:07:25<36:56,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2349/3636 [1:07:25<36:54,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2349/3636 [1:07:27<36:54,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2350/3636 [1:07:27<36:53,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2350/3636 [1:07:28<36:53,  1.72s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2351/3636 [1:07:28<36:51,  1.72s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2351/3636 [1:07:30<36:51,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2352/3636 [1:07:30<36:49,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2352/3636 [1:07:32<36:49,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2353/3636 [1:07:32<36:48,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2353/3636 [1:07:34<36:48,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2354/3636 [1:07:34<36:47,  1.72s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2354/3636 [1:07:35<36:47,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2355/3636 [1:07:35<36:46,  1.72s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2355/3636 [1:07:37<36:46,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2356/3636 [1:07:37<36:44,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2356/3636 [1:07:39<36:44,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2357/3636 [1:07:39<36:41,  1.72s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2357/3636 [1:07:40<36:41,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2358/3636 [1:07:40<36:40,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2358/3636 [1:07:42<36:40,  1.72s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2359/3636 [1:07:42<36:37,  1.72s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2359/3636 [1:07:44<36:37,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2360/3636 [1:07:44<36:36,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2360/3636 [1:07:46<36:36,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2361/3636 [1:07:46<36:34,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2361/3636 [1:07:47<36:34,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2362/3636 [1:07:47<36:33,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2362/3636 [1:07:49<36:33,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2363/3636 [1:07:49<36:31,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 2363/3636 [1:07:51<36:31,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2364/3636 [1:07:51<36:29,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2364/3636 [1:07:53<36:29,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2365/3636 [1:07:53<36:27,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2365/3636 [1:07:54<36:27,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2366/3636 [1:07:54<36:25,  1.72s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2366/3636 [1:07:56<36:25,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2367/3636 [1:07:56<36:23,  1.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2367/3636 [1:07:58<36:23,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2368/3636 [1:07:58<36:22,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2368/3636 [1:07:59<36:22,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2369/3636 [1:07:59<36:20,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2369/3636 [1:08:01<36:20,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2370/3636 [1:08:01<36:17,  1.72s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2370/3636 [1:08:03<36:17,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2371/3636 [1:08:03<36:16,  1.72s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2371/3636 [1:08:05<36:16,  1.72s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2372/3636 [1:08:05<36:15,  1.72s/it, training_loss=0.267]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  65%|██████▌   | 2372/3636 [1:08:06<36:15,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2373/3636 [1:08:06<36:14,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2373/3636 [1:08:08<36:14,  1.72s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2374/3636 [1:08:08<36:13,  1.72s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2374/3636 [1:08:10<36:13,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2375/3636 [1:08:10<36:11,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2375/3636 [1:08:11<36:11,  1.72s/it, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2376/3636 [1:08:11<36:09,  1.72s/it, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2376/3636 [1:08:13<36:09,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2377/3636 [1:08:13<36:08,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2377/3636 [1:08:15<36:08,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2378/3636 [1:08:15<36:07,  1.72s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2378/3636 [1:08:17<36:07,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2379/3636 [1:08:17<36:05,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2379/3636 [1:08:18<36:05,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2380/3636 [1:08:18<36:03,  1.72s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2380/3636 [1:08:20<36:03,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2381/3636 [1:08:20<36:01,  1.72s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2381/3636 [1:08:22<36:01,  1.72s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2382/3636 [1:08:22<35:59,  1.72s/it, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2382/3636 [1:08:24<35:59,  1.72s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2383/3636 [1:08:24<35:56,  1.72s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2383/3636 [1:08:25<35:56,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2384/3636 [1:08:25<35:54,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2384/3636 [1:08:27<35:54,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2385/3636 [1:08:27<35:54,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2385/3636 [1:08:29<35:54,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2386/3636 [1:08:29<35:52,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2386/3636 [1:08:30<35:52,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2387/3636 [1:08:30<35:51,  1.72s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2387/3636 [1:08:32<35:51,  1.72s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2388/3636 [1:08:32<35:50,  1.72s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2388/3636 [1:08:34<35:50,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2389/3636 [1:08:34<35:48,  1.72s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2389/3636 [1:08:36<35:48,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2390/3636 [1:08:36<35:47,  1.72s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2390/3636 [1:08:37<35:47,  1.72s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2391/3636 [1:08:37<35:45,  1.72s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2391/3636 [1:08:39<35:45,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2392/3636 [1:08:39<35:43,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2392/3636 [1:08:41<35:43,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2393/3636 [1:08:41<35:43,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2393/3636 [1:08:42<35:43,  1.72s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2394/3636 [1:08:42<35:41,  1.72s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2394/3636 [1:08:44<35:41,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2395/3636 [1:08:44<35:38,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2395/3636 [1:08:46<35:38,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2396/3636 [1:08:46<35:36,  1.72s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2396/3636 [1:08:48<35:36,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2397/3636 [1:08:48<35:34,  1.72s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2397/3636 [1:08:49<35:34,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2398/3636 [1:08:49<35:33,  1.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2398/3636 [1:08:51<35:33,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2399/3636 [1:08:51<35:31,  1.72s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2399/3636 [1:08:53<35:31,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2400/3636 [1:08:53<35:29,  1.72s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2400/3636 [1:08:55<35:29,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2401/3636 [1:08:55<35:27,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2401/3636 [1:08:56<35:27,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2402/3636 [1:08:56<35:27,  1.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2402/3636 [1:08:58<35:27,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2403/3636 [1:08:58<35:26,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2403/3636 [1:09:00<35:26,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2404/3636 [1:09:00<35:23,  1.72s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2404/3636 [1:09:01<35:23,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2405/3636 [1:09:01<35:21,  1.72s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2405/3636 [1:09:03<35:21,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2406/3636 [1:09:03<35:19,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2406/3636 [1:09:05<35:19,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2407/3636 [1:09:05<35:18,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2407/3636 [1:09:07<35:18,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2408/3636 [1:09:07<35:16,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 2408/3636 [1:09:08<35:16,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2409/3636 [1:09:08<35:15,  1.72s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2409/3636 [1:09:10<35:15,  1.72s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2410/3636 [1:09:10<35:15,  1.73s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2410/3636 [1:09:12<35:15,  1.73s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2411/3636 [1:09:12<35:12,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2411/3636 [1:09:14<35:12,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2412/3636 [1:09:14<35:09,  1.72s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2412/3636 [1:09:15<35:09,  1.72s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2413/3636 [1:09:15<35:08,  1.72s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2413/3636 [1:09:17<35:08,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2414/3636 [1:09:17<35:06,  1.72s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2414/3636 [1:09:19<35:06,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2415/3636 [1:09:19<35:05,  1.72s/it, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2415/3636 [1:09:20<35:05,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2416/3636 [1:09:20<35:03,  1.72s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2416/3636 [1:09:22<35:03,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2417/3636 [1:09:22<35:01,  1.72s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 2417/3636 [1:09:24<35:01,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2418/3636 [1:09:24<35:00,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2418/3636 [1:09:26<35:00,  1.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2419/3636 [1:09:26<34:58,  1.72s/it, training_loss=0.264]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  67%|██████▋   | 2419/3636 [1:09:27<34:58,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2420/3636 [1:09:27<34:56,  1.72s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2420/3636 [1:09:29<34:56,  1.72s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2421/3636 [1:09:29<34:55,  1.72s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2421/3636 [1:09:31<34:55,  1.72s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2422/3636 [1:09:31<34:54,  1.73s/it, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2422/3636 [1:09:32<34:54,  1.73s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2423/3636 [1:09:32<34:50,  1.72s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2423/3636 [1:09:34<34:50,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2424/3636 [1:09:34<34:48,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2424/3636 [1:09:36<34:48,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2425/3636 [1:09:36<34:46,  1.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2425/3636 [1:09:38<34:46,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2426/3636 [1:09:38<34:44,  1.72s/it, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2426/3636 [1:09:39<34:44,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2427/3636 [1:09:39<34:43,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2427/3636 [1:09:41<34:43,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2428/3636 [1:09:41<34:41,  1.72s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2428/3636 [1:09:43<34:41,  1.72s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2429/3636 [1:09:43<34:40,  1.72s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2429/3636 [1:09:45<34:40,  1.72s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2430/3636 [1:09:45<34:39,  1.72s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2430/3636 [1:09:46<34:39,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2431/3636 [1:09:46<34:37,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2431/3636 [1:09:48<34:37,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2432/3636 [1:09:48<34:35,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2432/3636 [1:09:50<34:35,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2433/3636 [1:09:50<34:33,  1.72s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2433/3636 [1:09:51<34:33,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2434/3636 [1:09:51<34:32,  1.72s/it, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2434/3636 [1:09:53<34:32,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2435/3636 [1:09:53<34:30,  1.72s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2435/3636 [1:09:55<34:30,  1.72s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2436/3636 [1:09:55<34:29,  1.72s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2436/3636 [1:09:57<34:29,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2437/3636 [1:09:57<34:27,  1.72s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2437/3636 [1:09:58<34:27,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2438/3636 [1:09:58<34:25,  1.72s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2438/3636 [1:10:00<34:25,  1.72s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2439/3636 [1:10:00<34:22,  1.72s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2439/3636 [1:10:02<34:22,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2440/3636 [1:10:02<34:21,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2440/3636 [1:10:03<34:21,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2441/3636 [1:10:03<34:18,  1.72s/it, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2441/3636 [1:10:05<34:18,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2442/3636 [1:10:05<34:16,  1.72s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2442/3636 [1:10:07<34:16,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2443/3636 [1:10:07<34:14,  1.72s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2443/3636 [1:10:09<34:14,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2444/3636 [1:10:09<34:12,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2444/3636 [1:10:10<34:12,  1.72s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2445/3636 [1:10:10<34:11,  1.72s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2445/3636 [1:10:12<34:11,  1.72s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2446/3636 [1:10:12<34:09,  1.72s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2446/3636 [1:10:14<34:09,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2447/3636 [1:10:14<34:07,  1.72s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2447/3636 [1:10:16<34:07,  1.72s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2448/3636 [1:10:16<34:06,  1.72s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2448/3636 [1:10:17<34:06,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2449/3636 [1:10:17<34:04,  1.72s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2449/3636 [1:10:19<34:04,  1.72s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2450/3636 [1:10:19<34:02,  1.72s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2450/3636 [1:10:21<34:02,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2451/3636 [1:10:21<34:00,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2451/3636 [1:10:22<34:00,  1.72s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2452/3636 [1:10:22<33:59,  1.72s/it, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2452/3636 [1:10:24<33:59,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2453/3636 [1:10:24<33:58,  1.72s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2453/3636 [1:10:26<33:58,  1.72s/it, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2454/3636 [1:10:26<33:57,  1.72s/it, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 2454/3636 [1:10:28<33:57,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2455/3636 [1:10:28<33:55,  1.72s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2455/3636 [1:10:29<33:55,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2456/3636 [1:10:29<33:53,  1.72s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2456/3636 [1:10:31<33:53,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2457/3636 [1:10:31<33:51,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2457/3636 [1:10:33<33:51,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2458/3636 [1:10:33<33:50,  1.72s/it, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2458/3636 [1:10:35<33:50,  1.72s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2459/3636 [1:10:35<33:48,  1.72s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2459/3636 [1:10:36<33:48,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2460/3636 [1:10:36<33:45,  1.72s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2460/3636 [1:10:38<33:45,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2461/3636 [1:10:38<33:43,  1.72s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2461/3636 [1:10:40<33:43,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2462/3636 [1:10:40<33:41,  1.72s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2462/3636 [1:10:41<33:41,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2463/3636 [1:10:41<33:40,  1.72s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2463/3636 [1:10:43<33:40,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2464/3636 [1:10:43<33:39,  1.72s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2464/3636 [1:10:45<33:39,  1.72s/it, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2465/3636 [1:10:45<33:38,  1.72s/it, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2465/3636 [1:10:47<33:38,  1.72s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2466/3636 [1:10:47<33:37,  1.72s/it, training_loss=0.238]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  68%|██████▊   | 2466/3636 [1:10:48<33:37,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2467/3636 [1:10:48<33:34,  1.72s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2467/3636 [1:10:50<33:34,  1.72s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2468/3636 [1:10:50<33:32,  1.72s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2468/3636 [1:10:52<33:32,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2469/3636 [1:10:52<33:31,  1.72s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2469/3636 [1:10:53<33:31,  1.72s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2470/3636 [1:10:53<33:30,  1.72s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2470/3636 [1:10:55<33:30,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2471/3636 [1:10:55<33:28,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2471/3636 [1:10:57<33:28,  1.72s/it, training_loss=0.174]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2472/3636 [1:10:57<33:25,  1.72s/it, training_loss=0.174]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2472/3636 [1:10:59<33:25,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2473/3636 [1:10:59<33:24,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2473/3636 [1:11:00<33:24,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2474/3636 [1:11:00<33:22,  1.72s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2474/3636 [1:11:02<33:22,  1.72s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2475/3636 [1:11:02<33:22,  1.72s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2475/3636 [1:11:04<33:22,  1.72s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2476/3636 [1:11:04<33:19,  1.72s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2476/3636 [1:11:06<33:19,  1.72s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2477/3636 [1:11:06<33:18,  1.72s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2477/3636 [1:11:07<33:18,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2478/3636 [1:11:07<33:15,  1.72s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2478/3636 [1:11:09<33:15,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2479/3636 [1:11:09<33:13,  1.72s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2479/3636 [1:11:11<33:13,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2480/3636 [1:11:11<33:13,  1.72s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2480/3636 [1:11:12<33:13,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2481/3636 [1:11:12<33:11,  1.72s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2481/3636 [1:11:14<33:11,  1.72s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2482/3636 [1:11:14<33:09,  1.72s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2482/3636 [1:11:16<33:09,  1.72s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2483/3636 [1:11:16<33:07,  1.72s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2483/3636 [1:11:18<33:07,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2484/3636 [1:11:18<33:05,  1.72s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2484/3636 [1:11:19<33:05,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2485/3636 [1:11:19<33:04,  1.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2485/3636 [1:11:21<33:04,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2486/3636 [1:11:21<33:02,  1.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2486/3636 [1:11:23<33:02,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2487/3636 [1:11:23<32:59,  1.72s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2487/3636 [1:11:24<32:59,  1.72s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2488/3636 [1:11:24<32:57,  1.72s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 2488/3636 [1:11:26<32:57,  1.72s/it, training_loss=0.235]"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'modelsCleaned/finetuned_lvBERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    \n",
    "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    \n",
    "    print('Classification report:')\n",
    "    print(classification_report(true_vals, preds_flat))\n",
    "    print('Confusion matrix:')\n",
    "    print(pd.DataFrame(confusion_matrix(true_vals, preds_flat),\n",
    "            index = [['actual', 'actual', 'actual'], ['neutral', 'positive', 'negative']],\n",
    "            columns = [['predicted', 'predicted', 'predicted'], ['neutral', 'positive', 'negative']]))\n",
    "    print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c271f1a9",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c271f1a9",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b344990",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 32,
     "id": "1b344990",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  44%|████▍     | 361/819 [03:18<04:11,  1.82it/s]"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('modelsCleaned/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "preds_flat = np.argmax(predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212b3ba",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9212b3ba",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.82     11554\n",
      "           1       0.76      0.77      0.77      7799\n",
      "           2       0.74      0.86      0.80      6844\n",
      "\n",
      "    accuracy                           0.80     26197\n",
      "   macro avg       0.79      0.80      0.79     26197\n",
      "weighted avg       0.80      0.80      0.80     26197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_vals, preds_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd2f0b6",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9fd2f0b6",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">actual</th>\n",
       "      <th>neutral</th>\n",
       "      <td>8934</td>\n",
       "      <td>1403</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>945</td>\n",
       "      <td>6006</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>488</td>\n",
       "      <td>452</td>\n",
       "      <td>5904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted                  \n",
       "                  neutral positive negative\n",
       "actual neutral       8934     1403     1217\n",
       "       positive       945     6006      848\n",
       "       negative       488      452     5904"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(true_vals, preds_flat),\n",
    "        index = [['actual', 'actual', 'actual'], ['neutral', 'positive', 'negative']],\n",
    "        columns = [['predicted', 'predicted', 'predicted'], ['neutral', 'positive', 'negative']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98b91c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6c98b91c",
     "kernelId": "7809c95f-5ff7-4d47-8195-fa782814c82b"
    }
   },
   "outputs": [],
   "source": [
    "unkTokens = [('️', 6950), ('😂', 6584), ('😭', 4354), ('…', 3449), ('🤣', 2423), ('❤', 2236), ('🏾', 2207), ('🏽', 1932), ('🙏', 1883), ('🔥', 1249), ('🏻', 1242), ('✨', 1213), ('🏼', 1209), ('🤷', 1165), ('–', 1057), ('🤦', 1025), ('🥺', 1018), ('😩', 993), ('🥰', 869), ('🤔', 846), ('🥴', 823), ('👏', 820), ('💯', 816), ('😍', 789), ('🙄', 718), ('🇺', 670), ('🙌', 664), ('💙', 623), ('🇸', 612), ('“Es', 596), ('💀', 573), ('👀', 561), ('—', 556), ('“', 539), ('😅', 530), ('💜', 527), ('💕', 519), ('😊', 482), ('👍', 455), ('💪', 454), ('😘', 445), ('😔', 428), ('💔', 422), ('😒', 417), ('🚨', 412), ('🙃', 403), ('🏿', 390), ('🚀', 387), ('😎', 377), ('‼', 375), ('😉', 361), ('🎄', 356), ('😁', 351), ('🖤', 335), ('😌', 332), ('😢', 328), ('🎶', 317), ('🎉', 307), ('🤗', 300), ('😆', 295), ('✊', 282), ('✌', 280), ('💛', 279), ('🥳', 278), ('😤', 276), ('😳', 275), ('🌟', 274), ('🤬', 267), ('👌', 261), ('👇', 261), ('🤩', 257), ('😬', 256), ('💖', 253), ('😡', 249), ('☺', 245), ('💋', 244), ('🌹', 244), ('⠀', 243), ('🤍', 242), ('🗣', 240), ('😫', 238), ('💚', 226), ('❄', 219), ('💗', 207), ('😈', 204), ('🙂', 197), ('😞', 195), ('😂,', 190), ('”', 190), ('😷', 188), ('🇷', 188), ('🤯', 188), ('😀', 185), ('“vai', 181), ('⃣', 181), ('💰', 177), ('😭,', 176), ('😴', 175), ('😏', 172), ('🤞', 171)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
