{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2616b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a84c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da5ece",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47471ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../../labeledTweets/allLabeledTweets.csv')\n",
    "df = df[['id', 'message', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da84e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newLine =\"\\\\n|\\\\r\"\n",
    "urls = '(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'\n",
    "numbers = '\\d+((\\.|\\-)\\d+)?'\n",
    "mentions = '\\B\\@([\\w\\-]+)'\n",
    "hashtag = '#'\n",
    "whitespaces = '\\s+'\n",
    "leadTrailWhitespace = '^\\s+|\\s+?$'\n",
    "\n",
    "df['clean_message'] = df['message']\n",
    "df['clean_message'] = df['clean_message'].str.replace(newLine,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(urls,' URL ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(mentions,' MENTION ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(numbers,' NMBR ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(hashtag,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(whitespaces,' ',regex=True)\n",
    "df['clean_message'] = df['clean_message'].str.replace(leadTrailWhitespace,'',regex=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc0d24",
   "metadata": {},
   "source": [
    "# Train, validate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051783f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "df.groupby(['label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6440d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aaa8f7",
   "metadata": {},
   "source": [
    "## Balance training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6200f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.data_type=='train']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b30934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = [df[df.data_type=='train'].clean_message, df[df.data_type=='train'].label]\n",
    "df_train = pd.concat(df_train, axis=1, keys=[\"clean_message\", \"label\"])\n",
    "\n",
    "df_0 = df_train[df_train['label']==0]\n",
    "df_1 = df_train[df_train['label']==1]\n",
    "df_2 = df_train[df_train['label']==2]\n",
    "\n",
    "df_0_downsampled = df_0.sample(df_1.shape[0], random_state=42)\n",
    "df_2_downsampled = df_2.sample(df_1.shape[0], random_state=42)\n",
    "\n",
    "df_train = pd.concat([df_0_downsampled, df_2_downsampled, df_1])\n",
    "\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52587bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle rows\n",
    "import sklearn\n",
    "\n",
    "df_train = sklearn.utils.shuffle(df_train, random_state=0)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843c4ae",
   "metadata": {},
   "source": [
    "# Tokenizer \"bert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b43559",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504acea3",
   "metadata": {},
   "source": [
    "### Find max length for tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b28671",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "for txt in list(df.clean_message.values):\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "    \n",
    "sns.displot(token_lens)\n",
    "plt.xlim([0, 200])\n",
    "plt.xlabel('Token count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e882ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 125"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6402cf",
   "metadata": {},
   "source": [
    "### Encode messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb945e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df_train[\"clean_message\"].values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].clean_message.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df_train.label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b69f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dataset_train, './datasetsLowercase/dataset_train.pt')\n",
    "# torch.save(dataset_val, './datasetsLowercase/dataset_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062b659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = torch.load('./datasetsLowercase/dataset_train.pt')\n",
    "# dataset_val = torch.load('./datasetsLowercase/dataset_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bfadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11af821",
   "metadata": {},
   "source": [
    "# Model \"bert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a7ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\",\n",
    "                                                      num_labels=3,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16189453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d95dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf40782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to measure weighted F1\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ccb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model. Returns average validation loss, predictions, true values\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader_val, desc='Validating', leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b38c59d",
   "metadata": {},
   "source": [
    "# Evaluate model trained on PNN dataset on LV Twitter validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f955b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('modelsCleaned-pnn/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c453e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "\n",
    "print('F1 score:')\n",
    "print(f1_score_func(predictions, true_vals))\n",
    "print(classification_report(true_vals, preds_flat))\n",
    "pd.DataFrame(confusion_matrix(true_vals, preds_flat),\n",
    "        index = [['actual', 'actual', 'actual'], ['neutral', 'positive', 'negative']],\n",
    "        columns = [['predicted', 'predicted', 'predicted'], ['neutral', 'positive', 'negative']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f7396",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_func(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ef371",
   "metadata": {},
   "source": [
    "# Train on Latvian Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'modelsCleanedTwttrPNN/finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    \n",
    "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    \n",
    "    print('Classification report:')\n",
    "    print(classification_report(true_vals, preds_flat))\n",
    "    print('Confusion matrix:')\n",
    "    print(pd.DataFrame(confusion_matrix(true_vals, preds_flat),\n",
    "            index = [['actual', 'actual', 'actual'], ['neutral', 'positive', 'negative']],\n",
    "            columns = [['predicted', 'predicted', 'predicted'], ['neutral', 'positive', 'negative']]))\n",
    "    print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c271f1a9",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b344990",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('modelsCleaned/finetuned_BERT_epoch_X.model', map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "preds_flat = np.argmax(predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_vals, preds_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd2f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(true_vals, preds_flat),\n",
    "        index = [['actual', 'actual', 'actual'], ['neutral', 'positive', 'negative']],\n",
    "        columns = [['predicted', 'predicted', 'predicted'], ['neutral', 'positive', 'negative']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38twttr",
   "language": "python",
   "name": "venv38twttr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
